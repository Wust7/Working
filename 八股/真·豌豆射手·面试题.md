自我介绍

* **面试官您好，我叫吴思特来自湖北黄冈，本科就读于长江大学，21年二战以数学满分的成绩考入中国地质大学，之后在四至七月份在华为实习了三个月左右当时主要负责华为管家扩展屏相关业务的开发与bug修复，之后来到地大参与了一些科研项目，比如目前还在做的水环境大数据管理平台，该项目是一个国家自然科学联合重点基金项目，其中的后端开发与数据库设计主要由我完成，并且我的毕业论文《多源水质监测与预警》也将作为预测模块的算法模型来开展研究，然后已经交付的项目有南宁市地质灾害风险调查数据录入系统等项目。由于是专业硕士，所以在发展方向上更加侧重技术相关，因此平时主要使用的技术是SpringBoot+MyBatis+MySQL的一个技术框架。希望能在贵公司找一份实习工作，可以参与到实际业务代码编写上库，或者JVM调优，或者服务上线问题排查，或者从中间件处理请求到服务器返回请求这个过程中的性能优化，或者bug修复等工作。我的自我介绍结束，谢谢面试官！**

# 每日必看（⭐⭐⭐）

* 绩点：3.85（88.5分）

## 1.自定义注解（项目中使用到的）

* 定义注解：**该注解目的增强接口方法，对接口方法的入参，返回参数等进行监控**

```java
//自定义注解
@Target(ElementType.METHOD)//标识该注解作用于方法上
@Retention(RetentionPolicy.RUNTIME)//Retention用于修饰注解。其中RUNTIME表示注解运行时也存在
public @interface MethodAnnotation {//@interface标识为自定义注解
}
```

* 定义切面类:**一般使用Around环绕通知进行功能增强**
  * 涉及到的IOC思想：**使用@Component注解表示该切面类由Spring IOC容器实例化并管理，无需手动创建，使用的时候只需要关注业务代码，对象的创建和使用交给IOC**。（相关的注解有@Component、@Controller、@Service、@Repository；@Autowired、@Qualifier、@Resource；@Bean）
  * 涉及到的AOP思想：**通过@Aspect注解设置一个切面类，该切面类可以将与业务无关的代码封装起来从而达到增强业务逻辑**。切面中常用的注解是@Around环绕通知，可以对控制方法入参、执行、返回结果等各方面细节进行控制。然后也可以使用@Pointcut注解来设置Advice切入点，@Before对方法执行前进行增强，@After对方法执行后进行增强。

```java
@Aspect//标识该类为切面类
@Component//表示由Spring IOC对当前对象实例化并管理
@Slf4j//打印日志信息
public class MethodAspect {
    //@Around 环绕通知，最强大的通知类型，可以控制方法入参、执行、返回结果等各方面细节
    @Around("@annotation(com.cug.ghentrysystem.annotation.MethodAnnotation)")
    public Object methodExporter(ProceedingJoinPoint joinPoint) throws Throwable {
        long start = new Date().getTime();
        //执行目标方法，获取方法返回值
        Object proceed = joinPoint.proceed();
        long end = new Date().getTime();
        //日志输出
        log.info("execution:{}ms", (start-end));
        return proceed;
    }
    
    //定义切入点,在切入点执行Advice
    @Pointcut("@annotation(com.cug.ghentrysystem.annotation.MethodAnnotation)")
    public void pcAspect(){}

    //在方法被调用之前执行增强
    @Before("pcAspect()")
    public void beforeAspect(){
    }

    //在方法被调用之后执行增强
    @After("pcAspect()")
    public void aterAspect(){
    }
}
```

## 2.多线程创建方式

* 多线程创建方式

```java
//1.MyThread继承Thread，new MyThread().start就可以启动线程
public class MyThread extends Thread{
    @Override
    public void run() {
        System.out.println("MyThread...");
    }
}
//使用方式
new MyThread().start();//启动线程

//2.MyRunnable实现Runnable,Thread中放入MyRunnable就可以启动线程了
public class MyRunnable implements Runnable{
    @Override
    public void run() {
        System.out.println("MyRunnable...");
    }
}
//使用方式
new Thread(new MyRunnable()).start();

//3.MyCallable实现Callable，指定call方法返回类型，并重写call方法。使用的时候只需要将MyCallable放入FutureTask中，然后将FutureTask传入Thread就可以开始启动线程了，该方法与其他创建方式不同的是可以通过FutureTask.get()阻塞式拿到call方法的返回结果
public class MyCallable implements Callable<Integer>{

    @Override
    public Integer call() throws Exception {
        System.out.println("MyCallable...");
        return 123;
    }
}
//使用方式
FutureTask<Integer> futureTask = new FutureTask<>(new MyCallable());
new Thread(futureTask).start();
Integer integer = futureTask.get();
System.out.println(integer);

//4.创建线程池，通过executor.execute(myRunnable)来使用线程池
ThreadPoolExecutor executor = new ThreadPoolExecutor(
        CORE_POOL_SIZE,
        MAX_POOL_SIZE,
        KEEP_ALIVE_TIME,
        TimeUnit.SECONDS,
        new ArrayBlockingQueue<>(QUEUE_CAPACITY),
        new ThreadPoolExecutor.CallerRunsPolicy());
//使用线程池
executor.execute(myRunnable);
//终止线程池
executor.shutdown();
```

## 3.线程池使用

* 由于项目中主要成果查询功能需要查询许多表，导致该接口返回数据实在是太慢，所以通过两个方案来加快查询速度，其中一个就是使用线程池创建多线程的思想做的，该方法效果明显，将多个查表操作同步进行，然后通过CompletableFuture.allOf().get()方法阻塞式等待多个查表操作运行完，然后再进行后面的数据封装。

```java
public static ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(
        6,
        8,
        100,
        TimeUnit.MILLISECONDS,
        new ArrayBlockingQueue<>(10),
        Thread::new,//threadFactory
        new ThreadPoolExecutor.CallerRunsPolicy()//拒绝策略
);
CompletableFuture<Integer> res1 = CompletableFuture.supplyAsync(() -> {
    System.out.println("使用线程");
    return 123;
},poolExecutor);
CompletableFuture<Integer> res2 = CompletableFuture.supplyAsync(() -> {
    System.out.println("使用线程");
    return 123;
},poolExecutor);//不需要返回值的话使用runAsync()
CompletableFuture.allOf(res1,res2).get();//阻塞式等待上面两个线程都运行完
System.out.println(res1.get()+","+res2.get());
```

## 4.SQL语句

```mysql
##删除数据库表中数据，但不删表
delete from user;

##查询不同的值 distinct
select distinct name from user;

##限制查询 limit
select * from user limit 5;##查询前五行
select * from user limit 1，5;##查询包括第二行，总共五行数据

## 依据多个字段进行排序 order by
select * from user order by age desc,name asc;## 先依据age进行降序排列，若age相同则依据name进行升序排列

## 分组 group by
select name,sum(salary) from student group by name;## 通过名字分组，求工资的和
-- 找到salary最高的两个人和对应salary的总和
select name,sum(salary) as salarySum from student group by name order by salarySum desc limit 2;

# having用于对汇总的group by进行过滤
-- 找到不同人salary总和大于20的人与总和值，并降序排列
select name,sum(salary) as salarySum from student group by name having salarySum>20 order by salarySum desc;


# 子查询：将一个 select 查询（子查询）的结果作为另一个 SQL 语句（主查询）的数据来源或者判断条件
SELECT cust_name, cust_contact
FROM customers
WHERE cust_id IN (SELECT cust_id
                  FROM orders
                  WHERE order_num IN (SELECT order_num
                                      FROM orderitems
                                      WHERE prod_id = 'RGAN01'));
# in 在什么里面，between 在某个取值范围内(包括两端)，and 左右条件都满足，or左右条件满足一个就行 ，not 否定一个条件，and优先级高于or
SELECT * FROM products WHERE prod_price NOT BETWEEN 3 AND 5;
SELECT * FROM products WHERE prod_price in (1,2,3);

select device_id,gender,age,university from user_profile where age is not null;# 年龄不为空

# 模糊匹配 like  ，字符串中可以设置%表示任意字符出现任意次，_表示任何字符出现一个
SELECT prod_id, prod_name, prod_price
FROM products
WHERE prod_name LIKE '_bean bag%';

# 连接 join on
# inner join 取两表相同部分
# join....on
select c.cust_name, o.order_num
from Customers c
inner join Orders o
on c.cust_id = o.cust_id # 条件相同时可以用using（cust_id）
order by c.cust_name;

# SQL 先根据 ON 生成一张临时表，然后再根据 WHERE 对临时表进行筛选
# 隐式内连接
select c.cust_name, o.order_num
from Customers c, Orders o
where c.cust_id = o.cust_id
order by c.cust_name;
# 显式内连接
select c.cust_name, o.order_num
from Customers c inner join Orders o
using(cust_id)
order by c.cust_name;

# union 组合
# JOIN 中连接表的列可能不同，但在 UNION 中，所有查询的列数和列顺序必须相同。
# UNION 将查询之后的行放在一起（垂直放置），但 JOIN 将查询之后的列放在一起（水平放置），即它构成一个笛卡尔积
SELECT column_name(s) FROM table1
UNION ALL # 加ALL表示允许重复值
SELECT column_name(s) FROM table2;

# count(1),count(*),count(列名)区别：count(1)与count(*)基本差不多，count(*)和count(列名)区别主要是count(*)统计所有记录数，包含null的记录，而count(字段)会统计该字段出现次数，忽略字段为null的情况

round(1.23,1)# 返回保留一位小数

# 实战
select
    university,
    difficult_level,
    round(count(qpd.question_id)/count(distinct qpd.device_id),4) as avg_answer_cnt# round(x,3)保留3
from question_practice_detail as qpd

left join user_profile as up # 以左表为主，汇总到左表
on qpd.device_id=up.device_id

left join question_detail as qd
on qpd.question_id = qd.question_id # qpd.question_id来自于up

group by university,difficult_level; # 先后顺序很重要

# case end
select 
    device_id,
    gender,
    case 
        when age<20 then '20岁以下'
        when age<=24 and age>=20 then '20-24岁'
        when age >24 then '25岁及以上'
        else '其他'
    end as age_cut

from user_profile

# 日期
select
    day (date) as day,
    count(question_id) as question_cnt
from question_practice_detail
where year (date) = 2021 and month (date) = 8
group by date;

# substring_index
select substring_index(profile,',',-1) gender ,count(*) number
from user_submit
group by gender;

#if
select
    up.device_id,
    '复旦大学' as university,
    count(question_id) as question_cnt,
    sum(if(qpd.result = 'right', 1, 0)) as right_question_cnt
from
    user_profile as up
    left join question_practice_detail as qpd on up.device_id = qpd.device_id
    and month(qpd.date) = 8
where up.university = "复旦大学"
group by up.device_id;
```

## 5.OpenFeign原理

![image-20230419104738193](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230419104738193.png)

* **流程**：OpenFeign属于SpringCloud的一部分，在使用OpenFeign进行远程通信时，生产者使用@EnableDiscoveryClient将服务注册到Nacos，然后消费者定义FeignClient消费服务接口，同时在消费者启动类上添加@EnableDiscoveryClient去nacos中发现服务，并且添加@EnableFeignClients开启远程调用功能。从而实现消费者可以通过nacos发现生成者的服务，进而使用该服务。由于OpenFeign内部集成了Ribbon，所以当生产者注册了多个服务到nacos中，负载均衡器将获取服务集合，通过chooseServer方法选择一个健康实例返回，将返回的Server替换URL中的服务名，从而实现远程调用
* **OpenFeign底层原理**：
  * 通过 @EnableFeignCleints 注解启动 Feign Starter 组件
  * Feign Starter 在项目启动过程中注册全局配置，扫描包下所有的 @FeignClient 接口类，并进行注册 IOC 容器
  * @FeignClient 接口类被注入时，通过 `FactoryBean#getObject` 返回动态代理类
  * 接口被调用时被动态代理类逻辑拦截，将 @FeignClient 请求信息通过编码器生成 Request
  * 交由 Ribbon 进行负载均衡，挑选出一个健康的 Server 实例
  * 继而通过 Client 携带 Request 调用远端服务返回请求响应
  * 通过解码器生成 Response 返回客户端，将信息流解析成为接口返回数据



## 6.Redis持久化

* **为什么Redis要持久化？**Redis 的读写操作都是在内存中，但**当 Redis 重启后，内存中的数据就会丢失**，因此Redis 实现了数据持久化机制来保证数据不会丢失，这个机制会把数据存储到**磁盘**，这样在 **Redis 重启就能够从磁盘中恢复原有的数据**。数据持久化方式有AOF日志、RDB快照、混合持久化方式。
  * **AOF日志**： 是**将每一条写操作命令以追加的方式写入到AOF日志**中， Redis 重启时会读取该文件记录的命令来进行数据恢复。**当AOF日志文件过大时将触发AOF重写机制**。
  * **RDB快照**：因为 **AOF 日志记录的是操作命令，不是实际的数据，所以用 AOF 方法做故障恢复时，需要把日志都执行一遍**，一旦 AOF 日志非常多，会造成 恢复缓慢。因此出现了**RDB快照**，它会**记录某一个瞬间的内存数据，在恢复数据时直接将 RDB 文件读入内存就可以**。
  * **混合持久化方式**：由于的**RDB 优点是数据恢复速度快，但是快照的频率不好把握**。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。**AOF 优点是丢失数据少，但是数据恢复不快**。为了集成了两者的优点， Redis 4.0 提出了**混合使用 AOF 日志和内存快照**。在写数据时，AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。
* **AOF重写机制**：**当AOF文件的大小超过所设定的阈值时，Redis会启动AOF重写机制，来压缩AOF文件**。**在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到新的 AOF 文件，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件**。如执行了set name a和set name b，在进行AOF重写时会在日志中记录set name b，而set name a会作为历史数据不用记录。



## 7.Redis为什么快？

* 由于Redis是**基于内存实现的，不需要去磁盘中读写数据**
* Redis 采用**单线程模型可以避免多线程之间的竞争**，**省去了多线程切换带来的时间和性能上的开销**，而且也不会导致死锁问题
* **Redis是基于IO多路复用的，它可以让单个线程高效地处理多个连接请求，而 Redis 只需要用epoll 作为 I/O 多路复用技术的实现。并且，Redis 自身的事件处理模型将epoll 中的连接、读写、关闭都转换为事件，不会在网络 I/O 上占用过多时间**。

## 8.缓存雪崩

* 场景：Redis中缓存的数据**大面积同时失效**，导致大量请求直接到数据库，压垮数据库
* 解决方案：
  * 将缓存过期时间**设置为一个时间段内的不同时间**，使其不会大面积同时过期
  * 将缓存**设置为不过期，然后通过后台服务来更新缓存数据**

## 9.缓存击穿

* 场景：大量请求访问缓存中**某个热点过期数据**，导致大量请求直达MySQL，导致服务崩溃
* 解决方法：
  * **不给热点数据设置过期时间**，由后台异步更新缓存，或者**在热点数据准备要过期前**，提前通知后台线程更新缓存以及重新设置过期时间
  * **使用redission.getLock获取分布式锁，让并行访问变串行**，当第一个线程查询完后，缓存被更新，其他线程可以依次获取锁来访问数据，但是所有线程串行，可能会降低性能，因此可以使用redission.tryLock(time,TimeUnit）来设置等待一段时间，若等待过程中获得了锁那么就直接往后执行，否则等完time时间后直接往下执行，由于第一个线程进来操作time时间后会将缓存更新好，因此其他线程集体等待这么长时间后会直接跳过分布式锁向下执行，从而将串行变并行，但时间time很难估计，因此能不能使用还得看具体业务场景。

## 10.缓存穿透

* 场景：查询**根本不存在的数据**，使得查询redis缓存是空，查询数据库也是空， 导致所有请求都会转到MySQL数据库，使其负载过大，甚至宕机。
* 解决方案：
  * 业务层**提前做参数检验**，对于不合理的参数及时return结束
  * **存储层未命 中，仍然将空值存入缓存层**
  * 将**所有存在的key提前存入布隆过滤器**，在访问缓存之前，**先通过过滤器拦截**，若请求的是不存在的key，则直接返回空值



## 11.如何保证数据库与缓存双写一致性？

* 可以使用**延时双删**来保证双写一致性，**先删除缓存再更新数据库，休眠一会再次删除缓存**。这个休眠时间等于读业务逻辑数据的耗时加上几百毫秒，**目的是为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据**。但是**延时双删的第二步的删除缓存可能失败**，导致双写不一致。因此可以使用**删除缓存重试机制**，在延时双删第二步删除操作中，若**删除失败则把要删除的key放到消息队列中，从而消费消息队列中要删除的key**。但是**删除缓存重试机制会引入业务代码入侵问题**，因此可以**将归档日志binlog日志采集发送到MQ队列**中，然后**使用ACK机制来异步删除缓存**。
* 
* 一般情况采用先**更新数据库，再删除缓存**的方案，但是每次更新数据的时候，缓存的数据会被删除，这样会对缓存的命中率带来影响，因此对于**缓存命中率有很高的要求，可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况**。但由于两个更新操作是独立的，所以当两个线程并发更新缓存时由于写入顺序不同会造成数据不一致。因此可以加分布式锁来保证同一时间只允许一个请求更新缓存来保证数据一致性。

* **（使用分布式锁解决）发生概率非常小**：在高并发场景下，A线程去数据库读数据为10然后B线程去数据库中写该数据为11，同时删除缓存中该数据，此时A线程读到的数据10将会写入缓存，缓存中数据变为10，但实际上数据库中数据为11，因而导致缓存与数据库双写不一致。此时也可以使用redission.getLock获取分布式锁来将并行操作该缓存数据变为串行，但会影响系统性能。因此对于大部分读多写少的场景可以使用读写锁解决，redission.getReadWriteLock获取读写锁，然后通过readLock获取读锁，writeLock获取写锁。对于都是读任务的线程可以并行执行，同时读写锁是互斥的。在并发读时，每次获取读锁会让并发读次数加一，释放锁时次数减一，当减为0时读锁释放。

## 13.execute与submit区别

- **execute只能提交Runnable类型的任务，无返回值**。**submit既可以提交Runnable类型的任务，也可以提交Callable类型的任务**，**会有一个类型为Future的返回值，但当任务类型为Runnable时，返回值为null**。
- **execute在执行任务时，如果遇到异常会直接抛出**，而**submit不会直接抛出，只有在使用Future的get方法获取返回值时，才会抛出异常**。

## 14.内存泄漏的排查

* **内存泄漏**是指在程序运行的过程中，因为某些原因导致**不需要使用的对象仍占用JVM内存空间并且这块内存还无法被回收**，导致出现**程序占用的内存越来越大**、**以及频繁的Full GC**。
* **内存泄漏的排查**：
  * **通过top命令查看内存占用情况**
  * 通过**shift+m**命令查看占用内存高的进程pid
  * 通过**jmap -histo** 打印进程所有的对象也可以将这些对象信息保存到文件中，打开文件初步判断哪个类产生的对象多；（存储命令：jmap -histo pid >log.txt，下载命令：sz log.txt）
  * 通过**jmap -heap**查看**新生代和老年代**的使用情况
  * 通过**jmap命令导出dump文件，通过JvisualVM分析文件**
  * 通过观察**若发现老年代逐步增长，FullGC出现卡顿，年轻代的内存一直居高不下，或者出现频繁得FullGC，那么极有可能是内存泄漏**
  * 一般情况定位到问题后找到对应的代码进行优化就可以，可以从**循环引用、内存对象泄漏没有被销毁、动态分配内存以后未释放、长期持有某个对象引用、资源未及时关闭**。

## 15.CPU100%怎么排查

* 导致CPU飙高的原因一般是**CPU上下文切换过多**，对于CPU来说，**同一时刻下每个CPU核心只能运行一个线程，如果有多个线程要执行**，**CPU只能通过上下文切换的方式来执行不同的线程**。**上下文切换**需要**保存运行线程的执行状态，让处于等待中的线程执行**，较多的上下文切换会占据大量CPU资源，从而使得cpu无法去执行用户进程中的指令，导致响应速度下降，CPU飙升。因此可以通过**top命令**，找到CPU使用率较高的进程，然后使用**Shift+H**找到进程中CPU消耗过高的线程。**如果CPU使用率过高的线程一直是同一个**，说明程序中存在**线程长期占用CPU没有释放**的情况，这种情况直接**使用jmap获得线程的Dump日志**，定位到线程日志后就可以找到问题的代码。如果**CPU使用率过高的线程id不断变化**，说明**线程创建过多，需要挑选几个线程id，通过jstack去线程dump日志中排查**。**如果定位的程序是正常的，有可能是在CPU飙高的那一刻，用户访问量较大，导致系统资源不够**。

## 16.JVM调优

* 对于JVM调优而言，绝大多数情况使用官方建议的参数就可以，比如年轻代比老年代=1:2，可以使用-XX:NewRatio=2来设置，eden:survior=8:1可以使用

  -XX:SurvivorRatio=8来设置等等，参数基本不需要调优，出现问题大多数情况都是代码编写的问题，修复对应的代码就行。那么现在的问题变成了定位那部分代码编写有问题了。具体的**排查步骤**是：

  * 首先使用top命令显示进程资源使用情况，使用top -Hp pid显示进程中线程占用情况，使用jstack pid命令查看进程的堆栈信息，然后使用jstat -gc pid查看进程当前的gc情况，使用jmap -heap pid显示堆详细信息，使用 jmap -histox:live pid显示堆中对象统计信息，同时也可以在JVM中添加一些参数比如PrintGCDetails等来丰富GC日志输出，通过这些可以粗略判断那部分代码可能出问题了
  * 然后使用jmap相关命令保存快照dump文件，通过JvisualVM可视化分析GC情况，**若出现内存使用率大于70%，或者老年代使用率大于70%，或者平均GC停顿时间大于1秒，或者平均每次Full GC的时间小于24小时等情况**极有可能是某部分代码出现问题了，排查出问题解决掉就ok了。
  * 同时也可以使用ps -ef | grep java 查看JVM参数配置，针对参数配置不合理的进行参数调整，通过循环对比调整前后优化效果找到最优参数。
  * 总之JVM调优的目标是追求GC低停顿低频率，低内存占用，高吞吐量的。

* 案例：

## 16.TCP协议一定能保证100%正确传输吗？

* 不一定
* 原因：数据在传输过程中是以**二进制数据进行传输**的，**二进制数据中包括数据和校验位**。而**校验位是通过指定算法如循环冗余校验CRC算法对原始数据进行计算得到的校验值，接收方接收到数据时采用相同的校验算法对原始数据进行计算，然后将计算得到的结果与校验值比较看是否一致，若一致则表示数据传输正确，否则不正确，丢弃该数据**。因此在传输过程中可能存在**数据出错了，同时校验位恰巧也出错**，但是通过指定算法计算数据时发现计算结果与错误的校验位一致，所以会认为错误的数据是正确的，导致发送数据与接收数据不一致。



## 17.MySQL事务

- 事务由MySQL的引擎实现，而常见的引擎是InnoDB，它是支持事务的，事务必须遵循四大特性四大特性：
  - **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成
  - **一致性（Consistency）**：事物前后的数据总量不变
  - **隔离性（Isolation）**：事务与事务之间相互不影响
  - **持久性（Durability）**：事务一旦提交发生的改变不可逆

* 那么InnoDB通过什么保证事务四个基本特性：

  * **原子性**：由**undolog回滚日志**来保证，它记录了需要回滚的日志信息，回滚时撤销已执行的sql
  * **一致性**：由**其他三大特性**共同保证，是事务的目的

  * **隔离性**：由**MVCC或锁机制**保证
  * **持久性**：由**redolog重做日志**保证，mysql修改数据时redolog会记录操作，宕机时可根据redo log恢复

* 由于MySQL存在同时处理多个事务的情况，因此可能出现脏读、不可重复读、幻读等**并发问题**

  * **脏读**：事务A读取到事务B还未提交的修改后数据，一旦事务B发生回滚，那么事务A读取到的数据就是脏数据，这个也就是脏读。

    ![image-20230222191916786](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222191916786.png)

    

  * **不可重复读**（Unrepeatable read）：一个事务内多次读取同一个数据，前后读取到的数据不一样的情况

    ![image-20230222192328013](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222192328013.png)

  * **幻读**（Phantom read）：一个事务内多次查询某个符合条件的记录数量，出现前后两次查询到的记录数不一致的情况。

    ![image-20230222192222338](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222192222338.png)

* 由于存在这些并发问题，因此提出了四种**隔离级别**来规避它们

  * **读未提交（Read-Uncommit）**：允许读取尚未提交的数据变更

  * **读已提交（Read-commit）**：    一个事务提交之后，它做的变更才能被其他事务看到

  * **可重复读(Repeatable-Read)(InnoDB默认)**：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。

  * **可串行化（serializable）**：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行

    ![image-20230224165723346](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230224165723346.png)

* **MySQL默认的隔离级别是可重复读，但它存在幻读的问题，解决办法是**：

  * **针对快照读**：**通过 MVCC多版本并发控制来解决幻读的**，实现的方式是开始事务后，在执行第一个查询语句时，会创建一个 Read View，**后续的查询语句利用这个 Read View在 undo log 版本链中找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的**
  * **针对当前读**：**通过 next-key lock（记录锁+间隙锁）来解决幻读**，比如在执行 **select ... for update** 语句的时候，会加上 next-key lock，如果其他事务会在 **next-key lock** 锁范围内插入一条记录，那么该插入操作就会被阻塞，从而避免了幻读

* 但是InnoDB中MVCC**并不能完全解决幻读**：

  * **当事务A查询并不存在的数据记录时，查询结果为空，此时事务B进行插入操作**，事务A再次查询时发现查询到事务B插入的数据。
  * 当事务A以快照读方式读取数据后，事务B插入符合条件数据，事务A再以当前读方式读取，此时出现幻想，读取到事务B插入数据。
  * 解决办法：针对该类问题，在**开启事务后马上执行select...for update这类当前读语句，给记录加上next-key lock**

## 18.手写HashMAp和ConcurrentHashMap



## 19.BeanDefinition

## 20.线程池加反射实现任务提交

## 21.Redis与MySQL的区别（关系型与非关系型）

# 项目

## 水环境大数据管理平台

* 项目介绍：水环境大数据管理平台是我们地大与深圳市政府合作的国家重点基金项目，该项目的目的是依据深圳市地质结构数据、水库河流数据、地下水数据、气候相关数据以及近海沿岸数据进行为期四年开发，然后我主要负责其中的水资源模块和雨洪模块后端开发、相关数据库搭建以及水质预测模型设计。**由于该项目后期需要交付给深圳市政府的，服务访问人数可能很多，并且该项目由不同组负责，后期存在项目合并等问题，所以采用微服务的方式让这个大服务分成几个可以单独运行的小服务，并且对于需要服务通信的模块，可以通过SpringCloud的open-feign来实现，同时通过nacos统一注册发现并管理这些服务**。
* 后端搭建分为common，gateway，rain，resource四个模块，其中**common模块主要负责定义分页工具类、统一返回参数以及其它常量类型，如状态码常量、分页常量等**
* **gateway模块则负责接收所有客户端请求**，然后通过Configuration注解**编写统一跨域处理配置类进行跨域处理**，同时**在application.yml中编写对应的路由规则让不同请求转发到不同服务上**。同时**启动类配置@EnableDiscoveryClient注解开启注册发现**的功能，在**bootstrap.properties中配置配置中心相关信息**。
* 对于水资源模块和雨洪模块都采用相同的方式开启注册发现与配置中心，同时在**每个模块中配置了全局异常处理类**，该类**通过注解RestControllerAdvice标记需要异常处理的包，在类中方法上添加注解ExceptionHandler并指定不同方法对应处理的异常类型，同时在类上添加注解@Slf4j来打印日志错误信息**
* **业务处理流程**是首先gateway收到前端发送过来的请求，然后转发到对应服务的controller层，然后controller层负责与service层进行交互，service层负责真正的业务逻辑处理，同时service层会与dao层进行交互。dao层主要负责与数据库进行交互。service层处理好业务后将数据返回给controller层，controller层负责将数据打包成统一返回参数，返回给前端。同时像**水资源模块还存在远程调用雨洪模块的功能，远程调用通过springcloud的open-feign来提供服务，只需要在feign接口上指定注解@FeignClient，并指定好需要远程调用的接口请求路径就可以实现了**。





## 地质灾害风险调查数据录入系统

* 项目介绍：地址灾害风险调查数据录入系统主要是设计一个包含表格、图像以及地质文件等信息的录入系统，该项目难点主要是大文件上传、主要成果查询接口设计、特殊接口设计。
* 针对**大文件上传**问题采用分片上传，前端通过Blob.slice方法将大文件分片然后采用多线程分片上传，然后服务端接收到请求首先检验该文件是否上传过，若未上传则所有分片通过RandomAccessFile类进行合并，然后将合并好的文件名及路径存入数据库对应位置，同时将该文件放入指定文件夹。若上传过则检查所有分片是否上传完成，若完成则直接**秒传**，若未完成则进行**断点续传**，将还未上传的分片上传，并合并文件。
* 还有一个是**主要成果查询接口**的设计，由于该接口需要查询滑坡、泥石流、地裂缝、地面塌陷、测绘点等十几张表数据，并且还涉及到大量数据计算，因此查询极其缓慢，因此选择**并发+redis缓存**的思想进行解决。
  * 由于查询不同表是相互独立的，因此选用**并发**的思想进行解决，首先创建线程池，设置好相关参数，其中拒绝策略选用CallsRunPolicy。然后使用CompleteFuture.supplyAsync()异步执行不同线程查询数据库。然后使用CompleteFuture.allOf(...).get()阻塞式等待并发线程结束，然后拿到数据进行相关计算与拼装。
  * 同时**考虑到地质灾害出现频率极低相关查询表更新并不频繁**，所以选择**采用redis缓存技术来解决数据读取缓慢**的问题，若redis缓存中有，就直接读取数据，若没有就调用对应方法查询数据库将结果返回并存入redis缓存中。通过StringRedisTemplate进行数据写入与读取，写入value值以Json的形式存入，读取时通过Json的解析方法进行数据转换。
* 针对**需求通过属性名和属性值查找匹配数据的问题**，**使用${}匹配属性名、#{}匹配属性值来设置SQL**，对于可能存在的***SQL注入***通过提前检验属性名中是否存在特殊符号来防止SQL注入
* 日志使用自定义的LogUtils以及springboot自带的日志功能，只需要指定日志显示级别info或者warn或者error就行，我一般使用error。

# 计算机基础

## 计网

### 1.TCP如何保证可靠性？(⭐)

* **超时重传** : 当**发送方发送数据之后，启动一个定时器**，等待接收端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为已丢失并进行重传
* **流量控制** : **发送方如果疯狂地向接收方发送数据，接收方会将处理不过来的数据存入缓冲区，如果缓冲区满了就会将其他处理不了的数据丢掉**，造成了资源的浪费。因此TCP提供了流量控制手段，在**每一次的ACK回复的时候会带上可用窗口大小，让发送方根据接收方的实际接收能力控制发送的数据量**，**当可用窗口大小为0时，发送方会开启一个定时任务，每隔一段时间去询问接收方，直到可用窗口大于0**。**流量控制主要依据接收方可用窗口大小。**
* **拥塞控制** : **发送方维护一个拥塞窗口，作用是用来估算链路的拥塞程度的，当网络中没有拥塞时拥塞窗口值可以增大一些，当网络出现拥塞时就减小拥塞窗口大小，防止过多数据包注入网络，同时提高链路数据传输率。拥塞控制主要依据链路拥塞情况来调整发送方的数据发送量**。
* **序号与确认序号**：序号是防止数据包分段后乱序，确认序号是防止数据包丢失。

### 2.TCP/IP网络模型(⭐)

![image-20230313160936076](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230313160936076.png)

![image-20230313163616218](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230313163616218.png)

* **应用层**：**专注于为用户提供功能，不关心数据如何传输。应用层运行在操作系统用户态，传输层及以下运行在内核态**

* **传输层**：传输层关心的是**当前进程要与哪个进程交互**，因此会给数据包添加上一个TCP头部，其中包含着**源端口号与目的端口号**，浏览器监听的端口是随机生成的，web服务器监听的端口HTTP默认是**80**，HTTPS默认是**443**。同时对于超过一个MSS大小的数据将会进行分段，因此TCP头部还包括**分段序号**，防止包乱序。同时为防止丢包问题，还有确认序号。由于需要进行TCP三次握手、四次挥手，因此TCP头部还保存有**状态位**，来记录SYN、ACK、FIN等状态。为了标记当前设备数据处理能力还添加了**窗口大小**来进行流量控制、拥塞控制等。

* **网络层**：网络层主要关心数据该发往哪个子网的哪台主机上，因此会在数据包上添加IP头部，其中包含源IP地址与目的IP地址，由于客户端可能存在多个网卡，因此**源IP地址**需要通过查目的IP地址与**路由表**中子网掩码进行按位与操作来查询匹配的网卡，从而就能确定源IP地址。**目的IP地址**通过DNS域名解析得到。目的IP地址与子网掩码按位与得到**网络号**，IP地址与取反后的子网掩码按位与得到**主机号**，从而可以确定数据去到哪个子网哪个主机上。并且添加上IP头部后的数据包长度不能超过一个MTU大小，MTU默认是**1500字节**
  * **源地址**：客户端输出数据的IP地址。客户端可能存在多个网卡，因此会有多个IP地址，因此需要通过路由表规则来选择哪个网卡作为源地址IP。
    * 具体规则是：Web服务器IP与路由表中第一条目的子网掩码做与运算若得到的结果与第一条目的地址一致则选择该网卡的IP地址作为源地址IP，此时网关地址就是路由器IP地址，否则的话按上面规则依次与剩下条目做相同操作。而最后一条目的地址与子网掩码都为0.0.0.0，这表示默认网关

* **网络接口层**：网络接口层主要关心该由哪个路由器转发到目的地，因此会添加MAC头部，来确定数据发送方MAC地址，接收方MAC地址。**发送方MAC地址**是在网卡生产时就写入ROM中的，所以直接读取就行。**接收方MAC地址**获取方式是**首先前往路由表中将目的IP地址与子网掩码按位与来确定路由IP地址，然后根据路由IP地址在ARP缓存中查询接收方MAC地址，若有就返回，若没有就在以太网中以广播的形式询问路由P地址的MAC地址是多少**。


### 3.输入网址到网页显示，期间将发生什么？(⭐)

* 第一步是**浏览器对URL进行解析，生成发送给web服务器的HTTP消息。由于HTTP消息需要委托操作系统发送给web服务器所以需要知道域名对应IP地址**。

* 第二步去**DNS(域名系统)服务器**查询请求域名对应的IP地址。具体操作：

  * 客户端会发送DNS请求给本地DNS，询问域名IP为多少。若本地DNS缓存中找到该域名对应IP地址则直接返回，若没有则本地DNS发送请求询问**根域名解析器**，根域名解析器并不会直接进行域名解析而是会返回顶级域名服务器地址给本地DNS。本地DNS会向该**顶级域名服务器**发送DNS请求，顶级域名服务器也不会直接进行解析而是会返回权威DNS服务器的地址。此时本地DNS接收到**权威DNS服务器**地址后向该服务器发送域名解析请求，从而**本地DNS服务器得到IP地址，将其存入缓存并返给客户端**。
  * ![image-20230321195010477](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230321195010477.png)

* 第三步：拿到域名IP后就可以将HTTP消息的传输工作交给OS的**协议栈**

  * **应用程序（浏览器）通过调用Socket库来委托协议栈工作**
  * 协议栈中TCP和UDP传输协议会执行收发数据的操作
  * IP协议则是控制将网络包发送给对方的操作，包括ICMP和ARP协议。其中ICMP协议用于告知网络包传输过程中产生的错误以及各种控制信息，ARP用于根据IP地址查询相应的以太网MAC地址
  * 网卡驱动程序负责控制网卡硬件
  * 物理硬件网卡负责实际收发操作

  ![image-20230310095119387](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230310095119387.png)

### 7.网卡

![image-20230310150108521](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230310150108521.png)

* 网卡是真正发送数据的地方，通过网卡驱动程序将数字信号转换为电信号，然后通过网线发送出去。网卡驱动获取网络包后，会将其复制到网卡内的缓存中并在头部添加上报头和起始帧分界符以及尾部添加用于检测错误的帧校验序列（FCS）。其中起始帧分界符是用来标识包起始位置的标记，FCS用来检查包传输过程是否有损坏

### 8.交换机

![image-20230313110356441](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230313110356441.png)

* 交换机接收到电信号，然后将电信号转换为数字信号，通过数据包末尾的FCS校验错误，若没问题就放入缓存区。交换机的端口不核对接收方MAC地址而是直接接收所有包并存入缓存区中，原因是交换机没有MAC地址。
* 将包放入缓存区后将查询该包的接收方MAC地址是否已经在交换机的MAC地址表中有记录了。若有则根据端口号，将数据通过交换电路把数据包发送到相应的端口。若没有则将包转发到除了源端口之外的所有端口，只有相应的接收者才能接收包，当接收者接收到数据后会返回响应包，此时交换机就可以将它的MAC地址写入MAC地址表中。MAC地址表中主要有两个信息一个是设备MAC地址，一个是设备连接在交换机的哪个端口上面
* 若接受方MAC地址是广播地址，那么交换机会将包发送到除源端口之外的所有端口。MAC 地址中的 `FF:FF:FF:FF:FF:FF`，IP 地址中的 `255.255.255.255`



### 9.路由器

![image-20230310210356510](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230310210356510.png)

* 包接收操作：路由器接收到交换机发送过来的电信号，将电信号转换为数字信号并对末尾FCS进行错误校验，若没问题则检查MAC头部中的接收方MAC地址是不是发送给自己的包，若是就放入缓冲区，否则丢包。完成接受操作后路由器将去掉包开头的MAC头部。
* 确定输出端口：**首先查询路由表判断转发目标，通过IP头部中接收方IP地址与路由表中子网掩码依次进行与操作直到结果与对应目标地址相同，此时就确定了转发目标**
* 发送操作：根据路由表网关列判断接收方地址，若网关是一个IP地址则表示还未到达终点将该IP地址作为目标地址。若网关为空，则表示已抵达终点，将IP头部接收方IP地址作为目的地址。知道IP地址后通过ARP协议查询ARP缓存若查到则直接返回IP地址对应接收方MAC地址，若找不到则发送ARP查询请求，将查询结果作为接收方MAC地址。而发送方MAC地址填写路由器输出端口MAC地址。**因此可以发现源IP和目标IP始终不变，一致在变的是MAC地址**

### 10.服务器与客户端

* 数据包抵达服务器时，服务器将进行层层校验，若成功通过校验将被放入缓存然后返回一个ACK，否则就丢弃。TCP头部包含端口号，HTTP的服务器正在监听该端口，因此服务器将数据包发送到该HTTP进程，同时将请求的数据信息封装到HTTP响应报文中，并添加相应的TCP、IP、MAC头部，而源地址与目的地址对换。然后将数据发送给客户端同样进行层层校验，然后客户端就拿到数据了，此时客户端将离开，因此向服务器发送TCP四次挥手，从而断开连接

### 11.TCP与UDP的区别（重点在于是否可靠）(⭐)

![image-20230311150655973](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230311150655973.png)

* 由于**TCP在传输数据时需要保证数据的可靠传输，而UDP则相对较简单只负责发送数据**，所以在TCP与UDP设计时：
* TCP是**面向连接**的服务，在传送数据之前必须先建立连接，数据传送结束后释放连接，UDP是不需要建立连接的。
* TCP是可靠传输在传输数据时会有三次握手建立连接，同时数据传输时存在确认、窗口、重传、拥塞控制机制，而UDP传输数据时不需要接收方给出任何确认，因此是不可靠的
* 由于TCP建立连接需要三次握手，因此需要通过状态存储发送消息的状态，而UDP则不需要
* 由于TCP通过众多手段保证可靠传输因此传输效率肯定低于UDP，同时TCP仅支持点对点通信，UDP支持一对多，多对多，一对一、多对一通信



### 12.TCP与UDP如何选择

* **TCP 用于对传输准确性要求特别高的场景**，比如**文件传输、发送和接收邮件、远程登录**等

* **UDP 一般用于即时通信**，比如： **语音、 视频 、直播**等等。这些场景对传输数据的准确性要求不是特别高，比如你看视频即使少个一两帧，实际给人的感觉区别也不大。

  



### 13.HTTP是什么？

* HTTP全名是超文本传输协议，是计算机世界里专门在两点间传输文字、图片音视频等超文本数据的约定与规范。

* HTTP 协议是基于 TCP协议，发送 HTTP 请求之前首先要 3 次握手建立 TCP 连接。目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样的话建立的长连接就可以在多次请求中被复用了。

* HTTP 协议是**”无状态”的协议，它无法记录客户端用户的状态，一般我们都是通过 Session 来记录用户的状态**

  

### 14.HTTP基于TCP还是UDP？

* HTTP3.0之前是基于TCP协议的，而HTTP3.0将弃用TCP，改用基于UDP的QUIC协议。目的是来解决HTTP/2中存在的队头阻塞问题。HTTP/2在单个TCP连接上使用多路复用，受到 TCP 拥塞控制的影响，少量的丢包就可能导致整个 TCP 连接上的所有流被阻塞



### 15.HTTP常见状态码

![image-20230311160311452](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230311160311452.png)

### 16.HTTP常见字段

* Host：客户端发送请求时，用来指定服务器的域名
* Content-Length：表明本次回应数据长度。可以解决”粘包“问题
* Connection：常用于客户端设置Keep-Alive要求服务器使用HTTP长连接机制，也就是只要任意一端没有明确断开连接，就保持TCP连接状态
* Content-Type：用于服务器回应，告诉客户端本次数据格式
* Content-Encoding：说明服务器返回数据的压缩格式



### 17.GET和POST区别(⭐)

* GET的语义是**从服务器获取指定的静态文本、页面、图片视频等资源**。**请求参数一般是写在URL中，参数类型只能是ASCII字符**，**同时浏览器对URL长度有限制**（项目中遇到过）
* POST是**根据请求报文body对指定资源做出处理**，**POST请求携带数据的位置一般写在报文body中**，body中的数据格式由客户端与服务端协商好，body大小无限制



### 18.使用TCP、UDP的协议有哪些？

* **运行于 TCP 协议之上的协议** ：
  * **HTTP 协议** ：超文本传输协议（HTTP，HyperText Transfer Protocol)主要是为 Web 浏览器与 Web 服务器之间的通信而设计的。当我们使用浏览器浏览网页的时候，我们网页就是通过 HTTP 请求进行加载的。
  * **HTTPS 协议** ：更安全的超文本传输协议(HTTPS,Hypertext Transfer Protocol Secure)，身披 SSL 外衣的 HTTP 协议
  * **FTP 协议**：文件传输协议 FTP（File Transfer Protocol），提供文件传输服务，**基于 TCP** 实现可靠的传输。使用 FTP 传输文件的好处是可以屏蔽操作系统和文件存储方式。
  * **SMTP 协议**：简单邮件传输协议（SMTP，Simple Mail Transfer Protocol）的缩写，**基于 TCP 协议**，用来发送电子邮件。
  * **POP3/IMAP 协议**： POP3 和 IMAP 两者都是负责邮件接收的协议。
  * **SSH 协议** : SSH（ Secure Shell）是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH 建立在可靠的传输协议 TCP 之上。

* **运行于 UDP 协议之上的协议** ：
  * **DHCP 协议**：动态主机配置协议，动态配置 IP 地址
  * **DNS** ： **域名系统（DNS，Domain Name System）将人类可读的域名 (例如，www.baidu.com) 转换为机器可读的 IP 地址 (例如，220.181.38.148)。** 我们可以将其理解为专为互联网设计的电话薄。实际上 DNS 同时支持 UDP 和 TCP 协议。

### 19.cookie和session的区别

* session是一种可以维持在服务器端的数据存储技术，它存储在服务端，一般配合cookie使用。目前使用的应用层协议基本都是基于HTTP和HTTPS，它们本身是无状态的，只负责请求和响应，告诉服务器我需要什么，服务器返回给我相应的资源。 如果没有额外处理的话， 服务器是不知道你是谁，更无法根据你是谁给你展现和你相关的内容了。**用户第一次向服务器发请求时，服务端会生成一个sessionid，服务端将生成的sessionid返回给客户端，通过set-cookie，客户端将sessionid保存在cookie中，客户端再次访问服务端时会携带这个id，当服务端接收到客户端的请求时，会先检查是否存在id，没有就会创建，有就直接用**

* cookie是网页浏览器用来保存用户信息的文件，可以保存比如用户是谁，购物车有哪些商品等。

* 区别：
  * cookie数据存在在用户浏览器端，session存放在服务器端
  * session更安全，可以分析放在本地的cookie进行cookie欺骗
  * 性能使用程度不同，session会一定时间保存在服务器上，当访问增多时，会比较占服务器的性能，考虑到服务器性能方面，应该使用cookie
  * 单个cookie数据保存不能超过4K，很多浏览器限制一个站点只能保存20个cookie，session存储在服务端，没有限制
  * 一般可以考虑将用户登录信息放在session中，其他信息可以考虑放在cookie中



### 20.HTTP 1.0 和 HTTP 1.1 有什么区别？

* HTTP1.0采用**短连接而HTTP1.1支持长连接**。1.1相较于1.0**新增了大量的状态]码，更多的缓存控制策略**。1.1在请求头引入range头域**允许只请求资源的某一部分，使得充分利用带宽和连接**。**同时在请求头引入host字段**



### 21.HTTP是不保存用户状态的协议, 如何保存用户状态?

* 使用Session机制在服务端记录用户状态，通过在Cookie中附加一个SessionID来跟踪用户。若Cookie被禁用则直接利用URL将SessionID附加到URL路径后面



### 22.URI和URL

* URI(Uniform Resource **Identifier**) 是**统一资源标志符**，可以唯一标识一个资源。
* URL(Uniform Resource Locator) 是**统一资源定位符**，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了**如何定位这个资源**。



### 23.OSI七层模型为什么没有被广泛使用

* 由于OSI专家缺乏实际经验完成OSI标准时缺乏商业驱动力
* OSI的协议实现起来过分复杂且允许效率低
* OSI制定标准周期太长，导致基于TCP/IP的互联网先进入市场
* OSI的层次划分不太合理

![image-20230313154400815](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230313154400815.png) 

### 24.电子邮件发送过程？

* 通过 **SMTP** 协议，将写好的邮件交给163邮箱服务器。163邮箱服务器发现发送邮件的邮箱是qq邮箱，然后它使用 SMTP协议将邮件转发到 qq邮箱服务器。qq邮箱服务器接收邮件之后就通知对应用户来收邮件，然后用户就通过 **POP3/IMAP** 协议将邮件取出

  ![image-20230313164927740](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230313164927740.png)

### 25.HTTP与HTTPS区别（重点在于安全）(⭐)

* HTTP 信息是**明文传输的，存在安全风险**的问题。HTTPS 在 HTTP 和TCP 网络层之间**加入了 SSL/TLS 安全协议**，使得报文能够加密传输。
* HTTP 连接**在 TCP 三次握手之后便可进行 HTTP 的报文传输**。为了安全性 HTTPS 在 TCP 三次握手之后，还需进行 **SSL/TLS 的握手**过程，才可进行加密报文传输。
* 默认端口不一样，**HTTP 是 80，HTTPS 是 443**。HTTP 的 **URL 前缀是 `http://`，HTTPS 的 URL 前缀是 `https://`**。
* **为了保证服务器的身份是可信的，HTTPS 协议还需向 CA（证书权威机构）申请数字证书**
* 由于安全性问题，HTTPS将会耗费更多服务器资源



### 26.HTTPS如何建立连接？

* HTTPS建立连接具体流程：
  * 首先**进行TCP三次握手建立连接，然后进行TLS四次握手**，如基于RSA（密钥协商算法）的TLS握手过程。
  * 第一次握手是**客户端向服务端发起加密通信请求，携带客户端支持的TLS协议版本，生成的随机数A，密码套件信息**
  * 第二次握手是服务端收到客户端请求后，**向客户端发出响应，携带确认TLS版本号、服务端生成随机数B、确认的密码套件列表、服务器数字证书信息**
  * 第三次握手**客户端收到服务器回应后首先通过浏览器或OS中的CA公钥确认服务器数字证书的真实性**，若没问题，则从**数字证书中取出服务器公钥**，然后**使用它进行非对称加密**。同时向服务器发送信息，包括一个随机数C、加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信、客户端握手结束通知。同时客户端会根据产生的随机数ABC以及协商好的加密算法生成本次通话的会话密钥。
  * 第四次握手服务端收到客户端的信息后，进行非对称加密中的解密拿到数据信息，也会依据随机数ABC以及协商好的加密算法生成会话秘钥，同时也会向客户端发送信息包含加密通信算法改变通知，服务器握手结束通知。



### 27.TCP三次握手(⭐)

TCP传输数据之前要先三次握手建立连接：

* 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。

* 然后客户端主动发起连接 `SYN`，之后处于 `SYN-SENT` 状态。

* 服务端收到发起的连接，返回 `SYN`，并且 `ACK` 客户端的 `SYN`，之后处于 `SYN-RCVD` 状态。

* 客户端收到服务端发送的 `SYN` 和 `ACK` 之后，发送对 `SYN` 确认的 `ACK`，之后处于 `established` 状态，因为它一发一收成功了。

* 服务端收到 `ACK` 的 `ACK` 之后，处于 `established` 状态，因为它也一发一收了。

* 所以**三次握手目的是保证双方都有发送和接收的能力**，其中**第一个SYN的发送与第一个ACK回复是确认客户端发送和接受都正常，第二个SYN发送与第二个ACK回复确保服务端发送和接收都正常**

* ![image-20230310110141829](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230310110141829.png)

* **为什么不二次握手**(⭐)

  ![image-20230314163542963](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230314163542963.png)



### 28.TCP四次挥手-断开连接(⭐)

* **第一次挥手** ：客户端发送一个 FIN（SEQ=X）报文到服务端，告诉服务端我要关闭连接了。然后，客户端进入 **FIN-WAIT-1** 状态。若客户端端一段时间内没有收到ACK应答报文，则继续发送FIN报文给服务端。

* **第二次挥手** ：服务器收到FIN报文后，发送ACK （SEQ=X+1）报文到客户端**告诉客户端我知道你要关闭连接了 ，不要再发送FIN请求了**。

* **第三次挥手** ：等服务端数据处理完后，并发送 FIN (SEQ=y)报文到客户端，**告诉客户端我处理完毕可以关闭连接了**，然后，服务端进入**LAST-ACK**状态。

* **第四次挥手** ：客户端收到FIN报文后进入**TIME-WAIT**状态，并发送 ACK (SEQ=y+1)报文到服务端，告诉服务端你可以关闭了，若服务端没有收到该报文，则会继续发送FIN报文到客户端，直到服务端在收到 ACK (SEQ=y+1)标志的数据包后进入 CLOSE 状态。此时，如果客户端等待 **2MSL** （**一个发送和一个回复所需的最大时间**）后依然没有收到回复，就证明服务端已正常关闭，随后，客户端也可以关闭连接了

![image-20230314165812619](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230314165812619.png)



### 29.syn-cookie的作用(⭐)

* syn-cookie是用来**抵御syn攻击**的，而syn攻击是发很多第一次连接**syn为1的报文**，服务器收到每个syn会为其创建一个TCP连接放在半连接队列中，而这个队列的大小是有限制的，如果队列满了，**服务器只能丢弃新的请求，从而正常的请求无法完成**，syn-cookie开启后，就可以**不使用半连接队列建立TCP连接**，而是**在服务器收到syn请求后，会根据当前的状态建立一个cookie**，**放在syn+ack报文中发出，当第三次握手时客户端发送请求也会带上这个cookie值，服务端接收到后会取出验证，如果合法就建立成功，加入全连接队列中**

### 30.TCP的粘包和拆包(⭐)

* **粘包问题**是因为**要发送的数据小于发送缓冲区的大小**，**使得多个数据包在同一缓冲区中，TCP 将写入缓冲区的多个数据一次性发送出去了，将会发生粘包**。或者**接收端应用层没有及时读取接收缓冲区中的数据，将发生粘包**；
* **拆包问题**是因为要**发送的数据大于发送缓冲区剩余空间大小**，**将会进行拆包或者待发送数据大于 MSS，TCP 在传输前将进行拆包。**

## OS

### 1.系统调用(⭐)

* 首先需要介绍下用户态与内核态，**运行在用户态的进程直接可以读取用户程序的数据**，而**运行在内核态的进程几乎可以访问计算机任何资源**，因此运行的用户程序中，凡是与**内核态级别资源相关的操作，如设备管理、文件管理、进程控制等的操作**，**都必须通过系统调用的方式向操作系统提出服务请求**，**并由操作系统代为完成**。
* 系统调用按功能分类：
  - **设备管理**。完成设备的请求或释放，以及设备启动等功能。
  - **文件管理**。完成文件的读、写、创建及删除等功能。
  - **进程控制**。完成进程的创建、撤销、阻塞及唤醒等功能。
  - **进程通信**。完成进程之间的消息传递或信号传递等功能。
  - **内存管理**。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能

### 2.线程与进程的区别(⭐)

* 线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。

* 各进程是独立的，而线程间可能存在相互影响。

* 线程执行开销小，而进程执行开销大。

* 进程的堆和方法区是线程共享的，其中方法区在JDK1.8以后由永久代改为元空间，存储在本地内存。

  

![image-20230315132019353](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230315132019353.png)



### 3.**进程**有哪几种状态(⭐)

* **创建状态(new)** ：进程正在被创建
* **就绪状态(ready)** ：**进程获得了除处理器之外的一切所需资源，一旦得到CPU即可运行**。
* **运行状态(running)** ：进程正在处理器上运行

* **阻塞状态(waiting)** ：**进程正在等待某一事件而暂停运行进入阻塞状态**。
* **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。



![image-20230315133238434](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230315133238434.png)



### 4.进程间通信方式

* **匿名管道(Pipes)** ：用于**具有亲缘关系的父子进程间或者兄弟进程之间的通信**，存在于**内存文件**中。
* **有名管道(Named Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。所以提出了有名管道。有名管道严格遵循**先进先出**。有名管道以**磁盘文件**的方式存在，可以实现**本机任意两个进程通信**。但管道通信方式**效率低不适合进程间频繁地数据交换**
* **信号(Signal)** ：**用于通知接收进程某个事件已经发生**；
* **消息队列(Message Queuing)** ：消息队列是消息的**链表**,具有特定的格式,存放在**内存**中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道不同的是消息队列存放在内存中，**只有在内核重启或者显式地删除一个消息队列时，该消息队列才会被真正的删除**。消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。**
* **信号量(Semaphores)** ：信号量是一个计数器，**用于多进程对共享数据的访问**，信号量的意图在于进程间**同步**。
* **共享内存(Shared memory)** ：**使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程对共享内存中数据的更新**。
* **套接字(Sockets)** : 主要**用于客户端和服务器之间进行网络通信**。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程

### 5.线程间的同步方式

* **互斥量(Mutex)**：采用**互斥对象机制**，**只有拥有互斥对象的线程才有访问公共资源的权限**。**因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问**。比如synchronized 和 Lock 。
* **信号量(Semaphore)** ：它**允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量**。
* **事件(Event)** :Wait/Notify：通过**通知方式来保持多线程同步**，还可以方便的实现**多线程优先级的比较操作**



### 6.进程的调度算法

* **先到先服务(FCFS)** : 从就绪队列中选择一个**最先进入该队列**的进程为它分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
* **短作业优先(SJF)的调度算法** : 从就绪队列中选出一个**估计运行时间最短**的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。
* **时间片轮转调度算法** :又称 RR(Round robin)调度。**每个进程被分配一个时间片，运行完后进入阻塞状态**。 最公平的调度算法。
* **优先级调度** ：**计算每个任务优先级，首先执行优先级最高的进程，相同优先级的进程以 FCFS 方式执行。**可以根据内存要求，时间要求或任何其他资源要求来确定优先级
* **多级反馈队列调度算法** ：**同时考虑优先级和时间，既能使高优先级的作业得到响应又能使短作业迅速完成**。



### 7.死锁(⭐)

* 死锁是**多个线程或进程同时被阻塞，它们在等待某个资源的释放**。**如A进程等待的资源正在被B进程占用，B进程需要的资源正在被A进程占用，形成的这种循环等待叫做死锁。**

* 四个必要条件：

  * **互斥**：**多个线程不能同时使用同一个资源**。
  * **请求与保持**：**进程或线程在请求另一个资源的同时，自身占有的资源保持不放**

  * **不可剥夺**：**其他线程不能强行剥夺该线程占有的资源**。

  * **循环等待**：A进程等待的资源正在被B进程占用，B进程需要的资源正在被A进程占用

* 上述四个条件有一个不满足就不会发生死锁，但四个都满足不一定发生死锁

* **避免死锁**只需要破坏死锁四个必要条件即可

  * **互斥条件是互斥锁的基本约束不能破坏**。 
  * **破坏请求与保持的话可以规定首次执行时一次性申请所有资源**。
  * **破坏不可剥夺的话可以规定，占用部分资源的线程在申请其他的资源的时候如果申请不到，就主动释放自己占有的资源**
  * **破坏循环等待的话可以通过按序申请资源来预防死锁**

  

### 8.内存管理

* 内存管理主要**负责内存的分配与回收，以及逻辑地址转换为相应的物理地址**等功能。内存管理机制有，**块式管理、页式管理、段式管理**。其中**块式管理**是**将内存分为固定大小的几个块，每个块中只包含一个进程，因此块式管理是连续分配管理方式，不会产生内存碎片**。**页式管理**是**把主存分为大小相等且固定的页，划分力度更小，提高了内存利用率**，但页式管理其中的页并无任何实际意义。 **段式管理**则把**主存分为一段段的，段是有实际意义的，每个段定义了一组逻辑信息，如主程序段、子程序段 等**。 **段式管理通过段表对应逻辑地址和物理地址**。



### 9.

### 10.缺页中断(⭐)

* 如果**需执行的指令或访问的数据尚未在内存**，则产生一个缺页中断让当前进程进入阻塞状态然后处理器通知操作系统将相应的页面从磁盘加载到内存，然后继续执行程序；

### 11.虚拟内存(⭐)

* 虚拟内存是用来确保每个程序拥有自己的地址空间，地址空间被分成多个块，每一块都有连续的地址空间。同时物理空间也分成多个块，块大小和虚拟地址空间的块大小一致，操作系统会自动将虚拟地址空间映射到物理地址空间，程序只需关注虚拟内存，请求的是虚拟内存，真正使用却是物理内存。同时使用虚拟内存空间可以远远大于物理内存空间，并且多个虚拟内存可以指向同一个物理地址。

### 12.DMA技术

* 由于在没有DMA技术之前，整个数据传输过程都需要CPU来搬运数据，不能做其他事情，因此出现了DMA技术，即**直接内存访问技术**。原理是**在进行数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务**
* ![image-20230425102559800](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230425102559800.png)

### 13.零拷贝(⭐)

* **传统IO操作**是用户应用进程调用read函数，向操作系统发起IO调用，**上下文从用户态转为内核态**，然后操作系统通过**DMA控制器将数据从磁盘中拷贝到内核缓冲区**，然后**CPU将内核缓冲区数据拷贝到用户应用缓冲区**，此时**上下文从内核态切换为用户态**，用户应用进程通过write方法发起IO调用，此时**上下文从用户态转换为内核态**，CPU将**用户缓冲区数据拷贝到socket缓冲区**，然后DMA控制器将**数据从socket缓冲区拷贝到网卡设备**，**上下文从内核态切换为用户态**。
* 可以发现传统IO包括四次上下文切换，四次数据拷贝

![image-20230408111045928](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230408111045928.png)

* **零拷贝**：使用sendfile+DMA scatter/gather来实现，当用户进程发起sendfile系统调用时，**上下文从用户态转换为内核态**，DMA控制器把**数据从磁盘中拷贝到内核缓冲区**，同时**CPU将内核缓冲区的文件描述符信息发送到socket缓冲区**，**DMA控制器根据文件描述符信息**，直接把**数据从内核缓冲区拷贝到网卡**，然后**上下文从内核态切换为用户态**，sendfile调用返回。该过程仅有两次上下文切换，两次数据拷贝，**全程没有CPU来搬运数据，所有的数据搬运都由DMA来完成**

* ![image-20230408153727315](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230408153727315.png)

* **DMA技术**  ：**在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务**

* 具体Java实现（Kafka使用的就是该方法）

* ```java
  public class test {
      public static void main(String[] args) {
          try{
              FileChannel readChannel = FileChannel.open(Paths.get("./a.txt"), StandardOpenOption.READ);
              long len= readChannel.size();
              long position=readChannel.position();
              FileChannel writeChannel = FileChannel.open(Paths.get("./b.txt"), StandardOpenOption.WRITE, StandardOpenOption.CREATE);
              readChannel.transferTo(position,len,writeChannel);
              readChannel.close();
              writeChannel.close();
          }catch (Exception e){
              e.printStackTrace();
          }
      }
  }
  ```

### 14.PageCache  磁盘高速缓存 （内核缓冲区）

* 内核缓冲区就是PageCache，由于内存读写速度较快但磁盘读写速度较慢同时依据程序运行的局部性原理，所以**使用PageCache来缓存最近被访问的数据**，当空间不足时淘汰最久未被访问的缓存。因此在读取数据时优先读取PageCache中的数据，若命中就直接返回，否则去磁盘中读取然后缓存到PageCache中。若需要传输某个大文件，由于**PageCache长期被大文件占据导致热点小文件无法充分使用PageCache**，使得PageCache使用性能降低，因此针对大文件传输不能使用零拷贝 。

### 15.IO多路复用中epoll(⭐)

* epoll 在内核里使用**红黑树来跟踪进程所有待检测的文件描述字**，把需要监控的 socket 通过 `epoll_ctl()` 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 `O(logn)`。而 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
* epoll 使用**事件驱动**的机制，内核里**维护了一个链表来记录就绪事件**，当某个 socket 有事件发生时，通过**回调函数**内核会将其加入到这个就绪事件列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率

![image-20230425200719518](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230425200719518.png)



### 16.边缘触发（ET）和水平触发（LT）

* **边缘触发（ET）**：当被监控的   Socket描述符上有可读时间发生时，服务器端只会从epoll_wait中苏醒一次，即使进程没有调用read函数从内核读取数据，也仅仅只苏醒一次，因此需要保证内核缓冲区中数据读取完。
* **水平触发（LT）**：当被监控的Socket描述符上有可读事件发生时，服务端不停地从epoll_wait中苏醒，直到内核缓冲区数据被read函数读完才结束。因此水平触发不需要一次执行就读取完，若一次没读取完下次还会检查该Socket的状态，可以继续读取。
* **select/poll只能水平触发，epoll默认水平触发，但也可以根据场景选用边缘触发**。



### 17.什么是一致性哈希？(⭐)

* 由于单台机器的并发量和数据量都有限，所以对于**高并发场景一般使用多台服务器构成集群来对外提供服务**，当多用户访问不同服务器时，若这些服务器存储的数据是相同的，那么**按照不同服务器数据处理能力来进行请求分配**，但对于数据分片的分布式系统而言，**不同服务器存储的数据是不同的，因此需要计算不同请求应该访问那台服务器**。
* 若直接使用**哈希算法确定请求访问的服务器**的话，那么对于**服务器节点数量发生改变**的情况，必须进行**数据迁移**，但数据迁移的成本太高，极端情况所有数据都要迁移
* 因此选用一致性哈希算法来解决节点数量改变的情况，**一致性哈希算法同样采用先根据key求hash，再对hash取模的思想，但一致性哈希算法是对2^32^进行取模运算，也就是计算结果会出现在0~2^32^的哈希环上**。当查询某个key时，先对其进行hash然后取模，然后**顺时针找到第一个服务器节点就可以在这个节点中获取需要的数据**了。当服务器节点数发生改变时，**只影响其顺时针后继节点，其他节点不影响**。**同时一致性哈希算法并不保证节点能够在哈希环上分布均匀**，因此可能**导致某个节点负载过大**，或者某个节点宕机后其相邻节点将会受到过大影响，从而**引发连锁式雪崩问题**。

![image-20230425220311292](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230425220311292.png)

* 因此可以**将虚拟节点分散映射到哈希环上，并将虚拟节点映射到实际节点**，从而当节点变化时，会有不同节点分担系统的变化，使得系统更加稳定。同时还可以**根据不同节点硬件性能进行不同权重数量的虚拟节点设计**。

# Java基础

## 基础

### 1.面向对象三大特性

* 封装：将一个对象的属性隐藏在对象内部，然后提供一些方法供外界访问。
* 继承：使用已存在的类作为父类创建子类，子类将拥有父类全部属性和方法，但无法访问私有方法和私有属性，同时子类可以拥有自己的属性和方法。
* 多态：一个对象具有多种形态，具体表现为子类以父类的身份出现，但执行时还是以自己的方式实现，总的来说就是编译看左边运行看右边。子类以父类的身份出现需要向上转型，这由JVM实现，是安全的。

### 2.接口和抽象类(⭐)

* 共同点：**都不能被实例化，都能有抽象方法、默认实现方法**
* 不同点：**接口主要用于对类的行为进行约束，抽象类主要为了提高代码复用性**。**一个类可以实现多个接口但只能继承一个类**。**接口中的成员变量必须是public static final，不能被修改且必须有初始值，而抽象类成员变量默认为default可以重新定义也可以重新赋值。**

### 3.浅拷贝、深拷贝、引用拷贝

![image-20230308204119982](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230308204119982.png)

* 浅拷贝：会在堆上创建一个新对象，如果被拷贝对象内部是引用类型的话，浅拷贝会直接复制内部对象的引用地址

* 深拷贝：完全复制整个对象包括对象内部信息
* 引用拷贝：不同的引用指向同一个对象，不会在堆上生成新对象。

### 4.为什么重写equals必须重写hasCode

* 首先hasCode的作用是获取对象哈希码，哈希码的作用是确定该对象在哈希表中的索引位置，而equals的作用是判断两个对象是不是相等的
* 当把对象放入HashSet中时，会首先计算哈希码然后确定对象加入的位置，若其中已经存在相同哈希码的对象，再通过equals方法来判断两个对象是否真相等，若相等，则加入不成功，若不相等则散列到其他位置。因此可以通过该方法大大减少equals比较次数，提高执行速度。
* 由于重写的equals方法判断对象相等相对较复杂，因此通过使用hasCode来减少equals的执行次数能提高程序执行速度。
* 而重写equals时必须重写hasCode的根本原因是**基于先通过hasCode再通过equals来判断对象相等的，若没有重写hasCode的话继承自Object的哈桑Code方法是比较对象地址是不是相等的，因此可能使得两个相同对象哈希码不相等，导致判断错误。**



### 5.String、StringBuffer、StringBuilder

* String是**不可变的，线程安全的**，存储对象使用char数组，并且用private final修饰，当String对象发生修改时，重新创建String对象，然后指向新String对象。Java9开始String底层实现由char数组改为byte数组，原因是当字符串中包含汉字没有超过单字节编码可表示范围内的字符时使用byte数组能节省一半内存空间，若超过单字节编码范围则byte数组与char数组占用内存一样
* **字符串中的"+"和"+="**是java仅有的运算符重载，底层实现仍然是使用StringBuilder来进行拼接的，因此在循环中使用String的重载运算符时，每次循环都将声明一个StringBuilder来进行拼接所以循环中最好别用字符串相加的方法。String类型的变量和常量在执行"+"运算时有所不同，对于常量表达式会使用常量折叠的原则将表达式求出来作为常量嵌在最终代码中，常量的要求时在编译期间就能确定值的，而引用值则在编译期间无法确定
* **String的equals与Object的equals区别**
  * String的equals比较的是值是否相等，而Object的equals比较的是对象内存地址是否相等

* **字符串常量池**的作用是为了避免字符串重复创建。如String a= "abc";String b="abc";那么首先执行String a="abc";会判断字符串常量池中是否有字符串对象"abc"的引用，若有就直接返回对应的引用，若没有就在堆中创建对象"abc"，同时在字符串常量池中添加字符串对象"abc"的引用，然后执行String b="abc";会直接返回字符串对象"abc"的引用。
* **String的intern方法**是一个native方法，作用是将指定的字符串对象的引用保存到字符串常量池，若字符串常量池有对应引用则直接返回该引用，若没有则在字符串常量池创建一个指向该字符串对象的引用并返回。
* **String不可变的原因**是字符串的数组被final修饰且私有，并且String类没有提供修改该字符串的方法。同时String类被final修饰导致其不能被继承

* StringBuffer是**线程安全的，适用于多线程操作的 大量字符串**
* StringBuilder是**线程不安全的，适用于单线程操作的大量字符串**

### 6. ArrayList 与 LinkedList ?(⭐)

* **都不保证线程安全**
* ArrayList底层是**使用Object数组存储**，在添加元素的时候**默认添加到列表末尾**，时间复杂度为O(1)，若**指定位置添加或删除则时间复杂度为O(n)**，因为需要数据移动。并且**ArrayList的底层数组是动态扩容的**，**扩容机制是当创建ArrayList的时，默认大小为空，添加第一个元素时大小变为10，当添加11个元素时数组扩大1.5倍，以此类推**。
* LinkedList采用**双向链表存储**，因此**头尾插入或删除时间复杂度为O(1)**,而**指定位置插入或删除就需要遍历到指定位置，因此时间复杂度为O(n)**
* **由于ArrayList底层是数组所以支持快速随机访问，而LinkedList底层是链表所以不支持快速随机访问**



### 7.Hashtable、HashSet、TreeMap、HashMap、ConCurrentHashMap(⭐⭐)

* **Hashtable **是**线程安全的**，**内部方法基本都被synchronized修饰**，由于是线程安全的，所以**效率比HashMap低**，同时**不允许有空的键或值**，底层数据结构采用**数组加链表**的方式存储

* **HashSet** 底层是**基于HashMap实现**的，因此属于自己的源码很少，与HashMap最大的不同是**HashMap存储的是键值对，而HashSet存储的是元素**。HashSet的存储机制是当对象要加入HashSet，首先会计算其哈希码，然后根据哈希码确定元素索引位置，若当前位置存在元素则判断该元素与要存入元素的哈希值以及key是否相同，若相同则直接覆盖，否则采用拉链法解决

* **TreeMap** 与HashMap都继承自AbstractMap，但TreeMap还实现了NavigableMap与SortedMap，NavigableMap让TreeMap拥有对集合内元素的搜索能力，SortedMap让TreeMap拥有对集合元素根据键排序的能力

* **HashMap** 主要用来**存放键值对，是非线程安全的**。可以**存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个**。**底层实现1.7之前**是 **数组+链表** 。1.8之后采用**数组+链表+红黑树**的方式存储元素，**当链表长度大于默认阈值 8时，且当前数组的长度小于 64，则先进行数组扩容，而不是转换为红黑树，并且在扩容过程中所有元素都会重新hash计算新的索引位置**。当**链表长度大于默认阈值8且数组长度大于等于64时将链表转化为红黑树，之后若HashMap中数据总数大于数组长度乘以负载因子 时首先进行扩容，负载因子默认是0.75**。同时在new HashMap<>();**初始化时调用HashMap构造方法设置HashMap长度，该操作只会设置threshold的大小为2的幂，并不会真正申请内存空间，只有在开始put对象时，才会申请threshold大小的空间。空间大小之所以必须是2的幂，是因为在根据hash值计算索引位置时采用的方式是（n-1）与hash值求与运算，若n不为2的幂的话计算索引位置将不对，该操作比直接取余要快。**

  * 退化条件1：在扩容时如果拆分树，树元素个数小于等于6会退化为链表

  * 退化条件2：在remove树节点时，首先检查在remove之前root、root.left、root.right、root.left.left是否有一个为空，若有则退化为链表

![image-20230318195711419](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230318195711419.png)

![image-20230327153237541](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230327153237541.png)

* **ConCurrentHashMap** **1.7**以前采用**Segment 数组 + HashEntry 数组 + 链表**的形式存储数据，使用分段锁让每个Segment同时只能一个线程操作。Segment 数组由很多个 `Segment` 组成，而每一个 `Segment` 是一个HashEntry数组，每个数组内部可以进行扩容。但是 `Segment` 的个数一旦**初始化就不能改变**，默认 `Segment` 的个数是 16 个。1.8开始使用Node数组+链表或红黑树存储数据，当链表达到一定长度将转化为红黑树，在冲突小于一定数量时会退回为链表。同时使用synchronized加CAS的机制保证每个Node节点同时只能一个线程操作。

  

### 8.代理模式

* 代理模式就是**使用代理对象来代替对真实对象的访问**，这样就可以在不修改原目标对象的前提下，增强目标对象的功能，比如在目标对象的某个方法执行前后可以增加一些自定义的操作。**代理模式可以分为静态代理和动态代理，**静态代理是对目标对象的每个方法的增强都是手动完成的，非常不灵活。**因此引入动态代理，动态代理不需要针对每个目标类都单独创建一个代理类。动态代理又分为JDK动态代理和CGLIB动态代理，**JDK动态代理是对于实现了接口的被代理类进行操作的，通过自定义InvocationHandler并重写invoke方法，在invoke方法中调用被代理类的原生方法并自定义一些处理逻辑。同时定义一个工厂来生产代理类对象，其中通过调用 Proxy.newProxyInstance方法创建代理对象。由于JDK动态代理最致命的问题是只能代理实现了接口的类，因此出现了**CGLIB动态代理**来避免该问题。CGLIB动态代理原理是自定义MethodInterceptor并重写intercept方法，该方法用于增强被代理类的方法，然后通过Enhancer的create方法创建代理类。但是在实际应用中若目标对象实现了接口，则采用JDK动态代理，否则采用CGLIB动态代理

  

### 9.常见IO模型(⭐)

* **BIO（Blocking I/O）同步阻塞** 应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间,客户端连接数量不高的情况下，是没问题的。但对于百万级别连接时速度非常慢

![image-20230322203920875](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230322203920875.png)



* **NIO (Non-blocking/New I/O)**  

  * 有人认为NIO是同步非阻塞 IO ，应用程序会以轮询的方式一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间，轮询是非常消耗CPU资源的。
  * ![image-20230322205954027](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230322205954027.png)

* **IO多路复用**
  * 核心思想是让单个线程去监视多个连接，一旦某个连接就绪，也就是触发了读/写事件就通知应用程序，去获取这个就绪的连接进行读写操作。也就是在应用程序里面可以使用单个线程同时处理多个客户端连接，在对系统资源消耗较少的情况下提升服务端的链接处理数量。客户端请求到服务端后，此时客户端在传输数据过程中，为了避免Server端在read客户端数据过程中阻塞，服务端会把该请求注册到Selector复路器上，服务端此时不需要等待，只需要启动一个线程，通过selector.select()阻塞轮询复路器上就绪的channel即可，也就是说，如果某个客户端连接数据传输完成，那么select()方法会返回就绪的channel，然后执行相关的处理就可以了。**IO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗**。NIO有一个多路复用器，只需要一个线程就可以管理多个客户端连接。
  * ![image-20230322210512536](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230322210512536.png)

* **AIO(Asynchronous I/O)** 异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。
* ![image-20230322210904267](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230322210904267.png)



### 10.java和c++区别

* Java先将代码编译成字节码，字节码通过解释器解释成机器码，c++只经过一次编译，直接在编译过程中形成了机器码

* c++的执行速度比java快，但是java通过jvm实现了跨平台，可移植性强

* c++有指针，java没有

* c++支持多继承，java只支持单继承

* c++开发需要自己去管理内存，java有jvm，但是也会出现oom和内存泄漏问题

### 11.基本数据类型(⭐)

* 一个字节的byte
* 两个字节的short、char
* 四个字节的int、float
* 8个字节的long、double
* boolean占一位

### 12.过滤器（Filter）与拦截器（Interceptor）(⭐)

* **过滤器** 是基于Servlet容器，主要用于处理请求字符编码、跨域等问题
* **拦截器** 是SpringMVC中基于动态代理的方法，自定义拦截器需实现HandlerInterceptor ，并重写内部方法preHandle、postHandle和afterCompletion方法。使用时再继承WebMvcConfigurer的配置类中重写addInterceptors方法来设置哪些请求需要被拦截，哪些不需要被拦截。
* 相同点：
  * 拦截器与过滤器都是体现了AOP的思想，对方法实现增强，都可以拦截请求方法。
  * 拦截器和过滤器都可以通过Order注解设定执行顺序
* 不同点：
  * 过滤器属于Servlet级别，Interceptor是SpringMVC中实现的，由Spring容器进行管理。
  * **过滤器和拦截器的执行顺序不同：先执行过滤器然后执行拦截器**

### 13.Exception与Error的区别

* 共同点：在 Java 中，所有的异常都有一个共同的祖先 `java.lang` 包中的 `Throwable` 类
* 不同点：
  - **Exception** :程序本身可以处理的异常，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 **Checked Exception** (受检查异常，必须处理) 和 **Unchecked Exception** (不受检查异常，可以不处理)。
    - **受检查异常**：Java 代码在编译过程中，如果受检查异常没有被 `catch`或者`throws` 关键字处理的话，就没办法通过编译。除了`RuntimeException`及其子类以外，其他的`Exception`类及其子类都属于受检查异常 。常见的受检查异常有：IO 相关的异常、`ClassNotFoundException`、`SQLException`...
    - **不受检查异常** ，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。`RuntimeException` 及其子类都统称为非受检查异常
      - `NullPointerException`(空指针错误)
      - `IllegalArgumentException`(参数错误比如方法入参类型错误)
      - `NumberFormatException`（字符串转换为数字格式错误，`IllegalArgumentException`的子类）
      - `ArrayIndexOutOfBoundsException`（数组越界错误）
      - `ClassCastException`（类型转换错误）
      - `ArithmeticException`（算术错误）
      - `SecurityException` （安全错误比如权限不够）
      - `UnsupportedOperationException`(不支持的操作错误比如重复创建同一用户)

- **Error**：`Error` 属于程序无法处理的错误 ，我们没办法通过 `catch` 来进行捕获不建议通过`catch`捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止

### 14.try-catch-finally 如何使用

* `try`块：用于捕获异常。其后可接零个或多个 `catch` 块，如果没有 `catch` 块，则必须跟一个 `finally` 块。 

* `catch`块：用于处理 try 捕获到的异常。

* `finally` 块：无论是否捕获或处理异常，`finally` 块里的语句都会被执行。当在 `try` 块或 `catch` 块中遇到 `return` 语句时，`finally` 语句块将在方法返回之前被执行。**不要在 finally 语句块中使用 return!** 当 try 语句和 finally 语句中都有 return 语句时，**try 语句块中的 return 语句会被忽略。这是因为 try 语句中的 return 返回值会先被暂存在一个本地变量中，当执行到 finally 语句中的 return 之后，这个本地变量的值就变为了 finally 语句中的 return 返回值**

### 15.finally 中的代码一定会执行吗

* 不一定，存在三种情况使得finally代码不会执行
* 第一种：finally之前，虚拟机被终止运行

```java
try {
    System.out.println("Try to do something");
    throw new RuntimeException("RuntimeException");
} catch (Exception e) {
    System.out.println("Catch Exception -> " + e.getMessage());
    // 终止当前正在运行的Java虚拟机
    System.exit(1);
} finally {
    System.out.println("Finally");
}
```

* 第二种：程序所在线程死亡
* 第三种：关闭CPU

### 16.try-with-resources与try-catch-finally的区别

* 面对**必须要关闭的资源**，优先使用**try-with-resources**而不是`try-finally`。

  * 好处：代码更简短，更清晰，产生的异常对更有用。
  * 更容易编写必须要关闭的资源的代码，若采用`try-finally`则几乎做不到这点

  ```java
  try (BufferedInputStream bin = new BufferedInputStream(new FileInputStream(new File("test.txt")));BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(new File("out.txt")))) {
      int b;
      while ((b = bin.read()) != -1) {
          bout.write(b);
      }
  }
  catch (IOException e) {
      e.printStackTrace();
  }
  ```

  



## JUC

### 1.**进程**(⭐)

*  进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。一个进程包含多个**线程**。

*  与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**
*  **程序计数器私有**主要是为了**线程切换后能恢复到正确的执行位置**
*  虚拟机栈和本地方法栈是线程私有为了**保证线程中的局部变量不被别的线程访问到**
*  区别：
   * **基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响**
   * **线程执行开销小，但不利于资源的管理和保护；而进程正相反**

### 2.为什么使用多线程？

* 线程是轻量级进程，**线程间的切换和调度成本远远小于进程**。多核CPU时代意味着多个线程可以同时运行，大大减小了线程上下文切换开销。对于高并发场景而言，多线程并发能提高系统整体并发性能。同时多线程带来了一些问题，如死锁、线程不安全等问题

### 3.**线程上下文切换**与进程上下文切换

* **线程切换**：意味着需要保存当前线程的上下文信息，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。

* **进程上下文切换**：进程是由操作系统内核调度和管理的，切换发生在操作系统内核，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源，然后把这些信息存放在进程控制块PCB中，切换时，也是通过PCB还原

  切换场景：进程被分配的时间片用完了，进程的资源不足了，sleep()函数，中断

### 4.

### 5.sleep()与wait()方法对比

* 共同点：都是让当前线程暂时放弃CPU的使用权，进入阻塞状态。进入该阻塞状态的线程都可以被interrupt打断唤醒
* 不同点：
  * sleep()是Thread类的静态本地方法，wait()是Object类的成员方法，每个对象都有，同时wait方法必须配合锁使用否则报错
  * 执行带参的sleep和wait的线程都会等待相应毫秒后醒来，带参wait和不带参wait可以被notify唤醒，不带参wait如果不唤醒就一直等下去
  * wait方法的调用必须先获取wait对象的锁，而sleep则不需要。同时wait方法执行后会释放对象锁，而sleep方法如果在synchronized代码块执行，并不会释放对象锁



* **注：**不能直接调用Thread类的run()，因为new Thread()的时候线程进入新建状态，当调用start()的时候会进入就绪状态，获得时间片时就可以运行了，然后自动执行run方法。但是直接调用run()方法会将该调用方法当作一个普通方法执行，并不是多线程方式执行。

### 6.**悲观锁** 与 **乐观锁** 

* 悲观锁：共享资源每次只给一个线程使用，其他线程阻塞，用完后再把资源转让给其他线程。适用于多写场景，避免频繁失败和重试

* 乐观锁：共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候需要通过CAS算法，验证对应的资源是否被其它线程修改。适用于多读场景，避免频繁加锁影响性能，大大提升了系统的吞吐量
  * 版本号机制 ： 在数据表中加一个数据版本号，表示数据被修改次数。当数据被修改成功时版本号会加一，当线程获得版本号与最后提交修改的版本号一致时才会修改成功，否则失败。
  * CAS算法：用 一个预期值和要更新的变量值进行比较，如果相等则进行更新操作。原子操作。涉及三个操作数要更新的变量值V、预期值E以及拟写入的新值N。会存在ABA问题（变量值在当前线程要进行修改的过程中，已经被A->B->A）。CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销

### 7.volatile

* 告诉编译器，该变量为共享且不稳定的，每次使用都需要到主存中读取,同时能**防止 JVM 的指令重排序**。volatile能保证数据的**可见性**但**不能保证数据的原子性**，synchronized两者都能保证。**线程的可见性就是,当一个线程对共享变量的值修改后,能够被其他线程看到**

### 8.synchronized

* synchronized可以保证被它修饰的方法或代码块在任意时刻只能有一个线程执行。synchronized可以修饰实例方法，代码块，静态方法。由于静态方法归类所有，被类的所有实例共享，因此给静态方法加锁相当于给类加锁。同时**构造方法不能使用 synchronized 关键字修饰**

### 9.ThreadLocal类(⭐⭐)

* 每个线程都有一个自己的ThreadLocalMap，其中存放的是Entry，而Entry中存放的是ThreadLocal为键，Value为值的键值对，每个线程往ThreadLocal里set值时，都是往自己的ThreardLocalMap里面存，get时通过ThreadLocal获取值，从而实现了线程安全。
* **内存泄漏**
  * Entry中存放的是key-value，其中key继承了weakReference也就是键是弱引用，而在创建 Entry对象的时，Entry是强引用。其中弱引用的对象会在每次GC时被回收，而强引用只要存在哪怕内存空间不足也都不会被回收。而 ThreadLocal没有被外部强引用，则GC后会被回收，所以此时就会出现key为空的情况。如果不加处理value永远无法被回收，就会出现内存泄漏问题。所以在使用完ThreadLocal后及时调用remove方法释放内存。
* **ThreadLocal.set()原理**
  * 调用ThreadLocal的set方法，首先会判断当前线程是否存在ThreadLocalMap，若不存在则新建，若存在则在ThreadLocalMap中set数据，ThreadLocal为键，value为值
  * ![image-20230317160932813](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230317160932813.png)




* **ThreadLocal中解决哈希冲突的原理**
  * 先根据key计算索引地址，在数组中找到对应的索引位置插入，若当前位置为空，则直接插入当前元素，
  * 若当前位置非空且key值与当前元素key值相同则直接更新该Entry的Value值
  * 若当前位置非空，且key值不同则继续向后遍历，若在向后遍历过程中未发现key相同的Entry以及key过期的Entry，则一直遍历到Entry为空的位置，则将当前元素放入在该位置，若在向后遍历过程中遇到key相同的则直接更新该Entry的Value值，若在遍历过程中遇到key过期的Entry将会探测式清理过期数据，然后找到一个合适的位置填入当前元素。

```java
public class ThreadLocalTest {
    private static ThreadLocal<String>local = new ThreadLocal<>();
    private static ThreadLocal<String>local2 = new ThreadLocal<>();
    static void print(String s){
        System.out.println(s+":"+local.get());
        System.out.println(s+":"+local2.get());
        local.remove();
    }

    public static void main(String[] args) throws InterruptedException {
        new Thread(new Runnable() {
            @Override
            public void run() {
                ThreadLocalTest.local.set("local_A");
                ThreadLocalTest.local2.set("local_A2");
                print("A");
                System.out.println("清除后："+local.get());
            }
        },"A").start();
        Thread.sleep(1000);

        new Thread(new Runnable() {
            @Override
            public void run() {
                ThreadLocalTest.local.set("local_B");
                print("B");
                System.out.println("清除后："+local.get());
            }
        },"B").start();
    }
}
```



### 10.线程池(⭐⭐)

* 池化技术：为了减少每次获取资源的消耗，提高对资源的利用率

* 线程池：使用线程池可以让多个不相关联的任务同时执行,降低资源消耗，提高响应速度，提高资源可管控性，如果不使用线程池，有可能会造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。其中有几个重要参数，比如

  * **核心线程数**： 工作队列未达到队列容量时，最大可以同时运行的线程数量。
  * **最大线程数**：工作队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数
  * **工作队列**：新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中
  * **饱和策略**：饱和策略包括，AbortPolicy直接抛出异常，拒绝新任务的处理，这个是默认的策略；CallerRunsPolicy调用执行自己的线程运行任务；DiscardPolicy是不处理新任务，直接丢掉；DiscardOldestPolicy丢掉最早的未处理任务请求

* 线程池流程：

  * 当一个新任务到来时，如果当前正在使用的线程数小于核心线程数，那么就新建一个线程来执行任务。
  * 如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到工作队列里等待。
  * 如果工作队列已经满了，但是当前运行的线程数是小于最大线程数的，就新建一个非核心线程来执行任务。
  * 如果当前运行的线程数已经等于最大线程数并且工作队列是满的，那么当前任务会采用饱和策略进行处理，默认的是AbortPolicy，就是直接抛出异常并拒绝该任务。

  ```java
  public class TestThreadPoolExecutor {
      static class MyTask implements Runnable{
          private final String name;
          private final long duration;//任务执行时间
  
          public MyTask(String name) {
              this(name,0);
          }
  
          public MyTask(String name, long duration) {
              this.name = name;
              this.duration = duration;
          }
  
          @Override
          public void run() {
              try{
                  System.out.println(Thread.currentThread().getName()+" running:"+this.name);
                  Thread.sleep(duration);
              }catch (InterruptedException e){
                  e.printStackTrace();
              }
          }
      }
      public static void main(String[] args) {
          AtomicInteger c = new AtomicInteger(1);//计数器
          ArrayBlockingQueue<Runnable> queue = new ArrayBlockingQueue<>(2);
          ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(
                  2,
                  3,
                  0,
                  TimeUnit.MILLISECONDS,
                  queue,
                  r -> new Thread(r, "myThread" + c.getAndIncrement()),//threadFactory给线程取名字
                  new ThreadPoolExecutor.CallerRunsPolicy()//拒绝策略
          );
  
          showstate(queue,poolExecutor);
          poolExecutor.submit(new MyTask("1",3600000));
          showstate(queue,poolExecutor);
          poolExecutor.submit(new MyTask("2",3600000));
          showstate(queue,poolExecutor);
          poolExecutor.submit(new MyTask("3"));
          showstate(queue,poolExecutor);
          poolExecutor.submit(new MyTask("4"));
          showstate(queue,poolExecutor);
          poolExecutor.submit(new MyTask("5"));
          showstate(queue,poolExecutor);
          poolExecutor.submit(new MyTask("6"));
          showstate(queue,poolExecutor);
  
      }
  
      private static void showstate(ArrayBlockingQueue<Runnable> queue, ThreadPoolExecutor poolExecutor) {
          System.out.println("pool size:"+poolExecutor.getPoolSize()+ ", queue:"+Arrays.toString(queue.toArray()));
      }
  }
  ```

  

* **如何设定线程池大小？(⭐)**

  * **CPU 密集型任务(CPU 核心数+1)：** 这种任务消耗的主要是 **CPU 资源**。**比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响**。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的**一个线程就可以充分利用 CPU 的空闲时间**。
  * **I/O 密集型任务(2倍CPU 核心数)：** **系统会用大部分的时间来处理 I/O 交互，而线程在处理 I/O 的时间段内不会占用 CPU **，这时就可以将 **CPU 交出给其它线程**使用,因此尽量多配置一些线程所以是二倍的CPU核心数。



### 11.AQS 抽象队列同步器(⭐)

* AQS：当一个线程请求某个资源时，如果资源空闲，就将该资源分配给线程并将共享资源状态设置为锁定状态。如果被请求资源被占用，那么就使用CLH队列锁机制将获取不到资源的线程放入双向队列CLH中。当共享资源空闲后，从CLH队列中选出线程获得该资源，该挑选过程分为抢占和非抢占。并且AQS有两个重要的子类Semaphore和CountDownLatch。

* **Semaphore**（PV）：默认构造 AQS 的 `state` 值为 `permits`，即许可证的数量，只有拿到许可证的线程才能执行。

  * 当调用**acquire**()表示线程尝试获取许可证，若state>=0则可以获取成功，获取成功后采用CAS操作修改state的值减一。若state<0则表示许可证数量不足，此时会创建一个Node节点加入阻塞队列，挂起当前线程。
  * 当调用**realease**()表示释放许可证，同时使用CAS操作修改state的值加一。释放成功后会唤醒阻塞队列中的一个线程，被唤醒的线程会重新尝试去修改state的值，若state>=0则可以获取许可证，否则重新加入阻塞队列

* **CountDownLatch** 默认构造 AQS 的 `state` 值为 `count`。允许 `count` 个线程阻塞在一个地方，直至所有线程的任务都执行完毕。该count值只有在构造方法中初始化一次，之后没有任何机制给他再次设置值。

  * 当线程调用**countDown**（）方法时会以CAS的操作来减少state，直到为0。当调用**await**（）方法时，若state不为0那就证明任务还没执行完毕，所以就会一直阻塞，并且会以自旋CAS的方式判断state是否为0，若为0则说明任务执行完毕，释放所有线程，执行await后的语句。

  * **CountDownLatch应用场景**：

  ```java
  protected boolean tryReleaseShared(int releases) {
      // Decrement count; signal when transition to zero
      for (;;) {
          int c = getState();
          if (c == 0)
              return false;
          int nextc = c-1;
          if (compareAndSetState(c, nextc))
              return nextc == 0;
      }
  }
  ```

  

### 12.JMM（Java内存模型）(⭐)

* **java内存模型**是**java并发编程的一套规范**，包括对于并发编程三大特性的规范，如**原子性**表示所有操作要么全部执行要么全部不执行，**可见性表示当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。比如线程1与线程2需要进行通信的话，线程1需要将自己在本地内存中修改过的共享变量副本同步到主内存中，然后线程2到主内存中读取对应的共享变量的值**。还包括**指令重排序的规范**，指令重排序指的是系统执行代码的顺序不一定是按照书写顺序执行，首先进行编译器级别的重排，然后进行处理器级别的 指令并行重排 ，最后进行内存系统重排。同时对于某些代码必须顺序执行，如加锁必须在解锁前，分布式系统中为了判断这种事件发生的先后顺序，定义了一种**happens-before规则**，而这种规则是为了保证程序进行重排序后的运行结果不会被改变。

  * 编译器优化重排：编译器（包括JVM、JIT编译器等）在不改变单线程程序语义前提下，重新安排语句执行顺序
  * 指令并行重排：指的是采用指令并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

  

* 主内存：所有线程创建的实例对象都放在主内存中，无论该实例对象是成员变量还是方法的本地变量

* 本地内存：每个线程都有一个私有的本地内存来存储共享变量的副本，每个线程只能访问自己的本地内存，本地内存存储了主内存的共享变量副本

* JVM内存区域和JMM的区别：

  * **JVM内存结构与Java虚拟机的运行时区域有关，定义了JVM在运行时如何分区存储程序数据。**
  * **Java内存模型和并发程序有关，JMM主要抽象了线程和主内存之间的关系，规定了Java源代码到CPU可执行指令的规范**

  ![image-20230328160829937](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230328160829937.png)

### 13.并发编程三大特性

* 原子性：一个操作或多个操作要么全部执行要么全部不执行。可以通过synchronized、Lock实现
* 可见性：当一个线程对共享变量进行修改时，其他线程可以立马看到修改后的最新值
* 有序性：由于指令重排序，导致代码的执行顺序并非是代码编写顺序，但是这种重排序还是要满足happens-before规则。可以通过volatile禁止指令重排序



### 14.join()

* join是把指定的线程加入到当前线程，只有指定线程完成后才能进行当前线程。当前线程.join(指定线程)



### 15.创建线程的方法

* 继承Thread类，然后重写run方法
* 实现Runnable接口，同时实现run方法，使用的时候只需要创建一个Thread对象，传入实现类的对象，然后调用start方法就可以使用了。也可以使用匿名内部类或者lambda表达式来创建Thread对象
* 实现Callable<T>接口，同时实现call方法，使用的时候只需要FutureTask传入该实现类得到任务对象，然后将该任务对象放入Thread中就可以获得相应的线程，同时可以使用任务对象.get方法阻塞式拿到允许结果。
* 使用ThreadPoolExecutor线程池创建对象



## JVM（Java虚拟机）

![image-20230222101403699](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222101403699.png)

### 1.虚拟机参数

* ```bash
  -xss256k(用于设置栈内存大小)
  
  -xms2G 堆内存最小为2G
  -xmx5G 堆内存最大为5G
  
  -XX:NewSize=256m 新生代最小内存
  -XX:MaxNewSize=1024m 新生代最大内存
  -Xmn256m 新生代内存大小256m
  -XX:NewRatio=1 新生代与老年代内存比值为1
  
  -XX:PermSize=N #方法区 (永久代) 初始大小
  -XX:MaxPermSize=N #方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen
  
  -XX:MetaspaceSize=N #设置 Metaspace 的初始（和最小大小）
  -XX:MaxMetaspaceSize=N #设置 Metaspace 的最大大小，如果不指定大小的话，随着更多类的创建，虚拟机会耗尽所有可用的系统内存。
  
  ## 设置垃圾收集器
  -XX:+UseSerialGC
  -XX:+UseParallelGC
  -XX:+UseParNewGC
  -XX:+UseG1GC
  ```

  

  ![image-20230319110307517](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230319110307517.png)

### 2.虚拟机栈

* 存储：**方法、局部变量、运行数据**，**8 种基本类型的变量+对象的引用变量+实例方法都是在栈里面分配内存**
* **栈管运行，堆管存储**
* 栈由一个个栈帧组成，当一个线程执行完毕，栈帧会依据先进后出原则弹出栈
* **不存在垃圾回收。只要程序运行结束，栈的空间自然就会释放了。栈的生命周期和所处的线程是一致的**

### 3.本地方法栈

* 存储：**native方法**

* 与虚拟机栈作用类似，但是虚拟机栈为虚拟机java方法服务，而本地方法栈为native方法服务。

### 4.程序计数器

* 存储：字节码行号指示器
* 标记程序运行位置，（内存区域唯一一个不会出现OOM的区域）

### 	5.堆

* 存储：**所有创建的对象和数组**
* 是所有线程共享的一块区域，在虚拟机启动时创建。目的是存放对象实例，几乎所有的对象实例以及数组都在堆中分配内存

* 字符串常量池:为了避免字符串的重复创建
* 字符串常量池从方法区移入堆中原因：方法区的GC回收效率低，只有出现整堆收集的时候才会GC，将字符串常量池移入堆中可以更加高效及时回收字符串内存

### 6.方法区

* 1.7以前永久代、1.8及以后元空间

* 存储：**静态变量、常量、运行时常量、虚拟机加载的字节码数据**
* 当虚拟机需要使用类时，它需要读取并解析Class文件获取相关信息，而这个相关信息就会存入方法区
* 元空间替代永久代原因：永久代有jvm本身设置的固定大小上限，无法进行调整，而元空间则是使用直接内存，受本机可用内存限制，虽然元空间仍可能溢出，但出现概率比元空间小。元空间存放类的元数据，加载多少类的元数据由系统可用空间来控制，因此能加载更多类

### **7.Java对象创建过程(⭐)**

* 当JVM遇到一条new指令时，首先会进行**类加载检查**，检查该指令参数是否能在常量池定位到它的引用，并检查该类是否被加载过，若没有则执行类加载过程。然后为新生对象**分配内存**，该对象所需的内存大小在类加载完成后便可确定。**分配方式**有 **“指针碰撞”** 和 **“空闲列表”** 两种，其中指针碰撞适合堆内存规整的情况如Serial、ParNew，而空闲列表则适合堆内存不规整的情况如CMS。同时在分配内存时可能存在并发问题，可以通过CAS+失败重试的方式保证线程安全。内存分配完成后需要对分配到的内存空间都**初始化为零头**，该操作保证了对象可以不赋初值就能直接使用。然后需要对**对象头**进行必要设置，如该对象属于哪个类的实例、对象的哈希码等信息。最后再执行初始化init方法，创建出一个真正的Java对象

- 指针碰撞 ： 
  - 适用场合 ：堆内存规整（即没有内存碎片）的情况下。
  - 原理 ：用过的内存全部整合到一边，没有用过的内存放在另一边，中间有一个分界指针，只需要向着没用过的内存方向将该指针移动对象内存大小位置即可
- 空闲列表 ： 
  - 适用场合 ： 堆内存不规整的情况下。
  - 原理 ：虚拟机会维护一个列表，该列表中会记录哪些内存块是可用的，在分配的时候，找一块儿足够大的内存块儿来划分给对象实例，最后更新列表记录

### 8.垃圾回收机制（GC）(⭐)

* **基本流程**：当一个对象需要放入内存中时，若Eden放的下就直接放，若Eden放不下对象时，会触发一次MinorGC，将Eden中还存货的对象放入to区，然后交换from区和to区，当下一次Eden区再放不下对象时，触发一次MinorGC将Eden区与From区存活对象放在To区，其他对象回收，此时再次交换From区与To区名称。当幸存区对象**熬过最多15次GC或者幸存区内存不足或者大对象**，将会晋级升老年代。当即使进行一次MinorGC仍然无法存进对象时，触发FullGC对整个堆垃圾回收，耗时较长。将对象放入老年代时将触发空间分配担保机制，来保证老年代存在的连续空间能容纳新生代所有对象
* ![image-20230217200018280](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230217200018280.png)
* 死亡对象判断方法：对堆进行GC前第一步就要判断哪些对象已经死亡（不能再被任何途径使用的对象）
  * 引用计数法：给对象中添加一个**引用**计数器，当一个地方引用时，计数器加一，当引用失效时，计数器减一。任何时候计数器为0时表示对象不可用。该方法不常用的原因：很难解决对象之间的**循环引用问题** 
  * **可达性分析算法**：通过一系列GC Roots的对象作为起点，从起点开始向下搜索，节点所走过的路径称为**引用链**。当一个对象到GC Roots没有任何引用链相连时，则证明该对象不可用，需要被回收。
  * **哪些对象可以作为 GC Roots 呢？**
    - **虚拟机栈中引用的对象**
    - **本地方法栈中引用的对象**
    - **方法区中引用的对象**
    - **所有被同步锁持有的对象**

### 9.垃圾收集算法(⭐)

* 标记-清除算法：首先标记所有不需要回收的对象，标记完成后统一回收所有没有被标记的对象。缺陷：效率问题，空间问题（标记清除后会产生大量**不连续的碎片**）
* 标记-复制算法：将内存分为大小相同的两块，每次使用其中一块，将还存活的对象复制到另一块去，然后再把空间一次清理掉。多用于新生代
* 标记-整理算法：让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。

* 为什么要分为新生代和老年代？
  * 当前垃圾收集算法采用分代收集算法，将堆分为新生代和老年代，其中新生代有大量对象死去，所以使用标记-复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代对象存货几率较高，而且没有额外的空间对其进行分配担保，所以使用标记-整理或标记清除进行垃圾回收。

### 10.垃圾收集器(⭐)

![image-20230222101852999](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222101852999.png)

* Serial收集器：串行单线程收集器。会使用一条垃圾收集线程去完成垃圾收集工作，在垃圾收集时暂停其他所有工作线程（STW）。新生代采用**标记-复制**，老年代采用**标记-整理**。优点：简单高效，不存在线程交互因此收集效率高，适用于运行在Client模式下的虚拟机

* Serial Old收集器：老年代版本的Serial收集器。用途：JDK1.5及以前的版本中与Parallel Scavenge收集器搭配使用；作为CMS收集器的后备方案

* ParNew收集器：多线程收集器。相当于多线程版本的Serial收集器，垃圾回收算法一样。适用于Server模式下的虚拟机，只有ParNew和Serial能与CMS收集器配合使用

* **Parallel Scavenge收集器**：使用标记复制算法的多线程收集器。与ParNew的最大区别是Parallel Scavenge**提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，Parallel Scavenge配合自适应策略，可以把内存管理优化交给虚拟机去完成**。关注点：高效率使用CPU即吞吐量。新生代：标记复制，老年代：标记整理

* **Parallel Old收集器**：老年代的Parallel Scanvenge收集器。在注重吞吐量和CPU资源的情况下，可以选用Parallel Scanvenge新生代+Parallel Old老年代

* **CMS**(⭐)（Concurrent Mark Sweep）收集器：是**追求最短回收停顿时间的老年代收集器**，使用**标记清除**算法回收垃圾。优点是并发收集、低停顿。缺点是**对CPU资源敏感，无法处理浮动垃圾，由于使用标记清除算法因此会产生大量空间碎片**。具体步骤是首先进行**初始标记，STW**（暂停所有其他线程），记录下直接与GC Roots 相连的对象，速度很快。然后**并发标记，不会STW**，追踪GC Roots整个链路，从GC Roots的直接关联对象开始遍历整个对象引用链路，该过程耗时较长但不需要停顿用户线程。然后再**重新标记，STW**，该阶段主要是**对在并发标记阶段中被系统程序运行变动过的少数对象进行标记**，速度很快。最后进行**并发清除，不会STW**，清除判断死亡的对象，该过程耗时长，但该阶段可以与用户线程并发执行。

* **G1收集器**(⭐)： 是一款面向服务器的垃圾收集器,主要**针对配备多核CPU及大容量内存**的机器。 以极高概率满足 GC **停顿时间**要求的同时,还具备**高吞吐量**性能特征。**G1收集器会将内存区域划分成不同Region，如eden Region、survivor Region、old Region**以及**存放大对象的humongous Region**。收集步骤可以分为**初始标记** STW、**并发标记** 不会STW、**最终标记** STW、**筛选回收** STW，该阶段与CMS不同。同时G1收集器还在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region，该操作保证了在有限时间内G1收集器尽可能高的收集效率，这也是为什么要叫Garbage-First的原因。在回收过程中整体是**基于标记整理来实现的，局部是通过标记复制实现**的

* G1收集器中大对象：G1认为只要大小**超过一个分区容量一半的对象**即可判定为大对象，分区大小可以设置

* ## ![image-20230219170046723](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230219170046723.png)

### 11.引用类型总结

* 强引用：必不可少。垃圾回收器绝不会回收它，即使内存不足宁愿使程序终止并抛出异常也不会回收
* 软引用：可有可无。如果内存足够，垃圾回收器就不会回收它，当内存空间不足时，就会回收这部分对象的引用。只要没有被回收都可以被引用
* 弱引用：可有可无。生命周期更短，当垃圾回收器扫描到所管辖区域只具有弱引用的对象，无论当前空间是否足够都会回收它。不过垃圾回收器是一个优先级很低的线程，不一定能发现那些只具有弱引用的对象
* 虚引用：形同虚设。如果一个对象仅持有虚引用，那么他就和没有引用一样，在任何时候都有可能被回收。主要用于**跟踪对象被垃圾回收的活动**
* 注：由于软引用、弱引用、虚引用的对象都有可能被回收，因此他们都可以（虚引用是**必须**）与引用队列联合，当垃圾回收发生时通过将引用加入到引用队列中，使得程序可以通过判断引用队列是否有引用来了解被引用对象是否将要被垃圾回收。程序发现某个引用加入引用队列，那么可以在被回收之前采取措施。



### 12.如何判断一个常量是废弃常量？

* 运行时常量池主要回收的是废弃的常量。如果当前字符串常量池中存在字符串"abc"，当前没有任何String对象引用该字符串常量的话，就说明常量"abc"是废弃常量，如果此时发生垃圾回收且有必要的话，字符串"abc"就会被清除常量池

### 13.如何判断一个类是无用的类？

* 方法区主要回收的是无用的类。无用的类判断条件：**该类的所有实例被回收，加载该类的ClassLoader已经被回收，该类对应得java.lang.Class对象没有任何地方被引用，无法在任何地方通过反射访问该类的方法。满足无用的类所有条件的无用类可以被回收但不必然**

### 14.类的生命周期

* 加载：将 **class 文件加载到内存**，将静态数据结构转化成方法区中运行时的数据结构，在堆中生成一个代表这个类的 java.lang.Class 对象作为数据访问的入口并将其放入元空间，该阶段程序员可以**通过自定义类加载器来实现加载**。
* 验证：验证Class文件的字节流中包含的信息是否符合《Java虚拟机规范》的全部约束，保证虚拟机安全
* 准备：**类变量赋默认初始值**，int为0，long为0L，boolean为false，引用类型为null，常量赋正式值
* 解析：把**符号引用翻译为直接引用**
* 初始化：**给类变量赋值**（当new一个类的对象，访问一个类的静态属性，修改一个类的静态属性，调用一个类的静态方法，用反射API对一个类进行调用，初始化当前类，其父类也会被初始化。。。以上都会出发初始化）
* 使用：**使用这个类**
* 卸载：卸载条件
  * 该类所有的实例都已经被GC，也就是JVM中不存在该Class的任何实例
  * 加载该类的ClassLoader已经被GC
  * 该类的java.lang.Class对象没有在任何地方被引用，如不能在任何地方通过反射访问该类的方法

![image-20230219173155280](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230219173155280.png)



### **15.双亲委派模型** 

* **原理**：当一个类文件要被加载时，会自底向上检查类是否被加载过，首先在Application ClassLoader中查看是否被加载过，若加载过则无需再加载了，如果没有就拿到父加载器Extension ClassLoader，同样查看是否被加载，若被加载过，则无需再加载，若没有就同样拿到父加载器Bootstrap ClassLoader，若被加载过则无需加载，若没有加载过将开始自顶向下尝试加载，寻找可以加载该类的类加载器，如果类加载器都找不到对应的类则会抛出ClassNotFoundException异常。由于JVM在加载相同类 ，不同加载器加载出来的类是两个不同的类，因此通过双亲委派的方式确定该类由那个加载器加载，防止类的重复加载，保证了Java核心API不会被篡改。
* ![image-20230221105442688](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230221105442688.png)
* 如果不想使用双亲委派模型？
  * 如果我们不想打破双亲委派模型，就重写 `ClassLoader` 类中的 `findClass()` 方法，无法被父类加载器加载的类最终会被该方法加载。
  * 如果想打破双亲委派模型则需要重写 `loadClass()` 方法
* 为什么tomcat需要破坏双亲委派模型？
  * Tomcat是web容器，那么一个web容器可能需要部署多个应用程序,部署在同一个tomcat上的两个web应用所使用的不同java类库要相互隔离，相同java类库要互相共享，同时还需保证Tomcat服务器自身的安全不受部署的Web应用程序影响，以及需要支持JSP页面的热部署和热加载
* 加载一个类采用Class.forName()与ClassLoader有什么区别？
  * **Class.forName得到的class是已经初始化完成的，而ClassLoader.loaderClass得到的class是还没有初始化的**
* **Java代码如何运行起来？**
  * Java文件经过编译后变成.class字节码文件，字节码文件通过类加载器被搬运到JVM虚拟机中，也就是创建了一个进程，JVM会找App的主程序入口，执行main方法

### 16.方法区内存溢出的原因？

* 类加载器泄漏：当应用程序使用自定义类加载器时，如果这些类没有被正确的回收，就会导致元空间内存泄漏，这种情况下，元空间的类的数量会不断增加，直至元空间的最大容量，导致元空间内存溢出
* java类动态加载，如果程序需要动态生成大量的类，例如使用动态代理或发射，就会导致元空间内存不足
* 元数据过多，静态字段，方法信息等过多，元空间大小设置不当



### 17.进程切换与线程切换

* 进程是由操作系统内核调度和管理的，切换发生在操作系统内核，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源，然后把这些信息存放在进程控制块PCB中，切换时，也是通过PCB还原

  切换场景：进程被分配的时间片用完了，进程的资源不足了，sleep()函数，中断



* 保护线程的私有信息，虚拟机栈，程序计数器，本地方法栈等信息



### 

# 数据库

## MySQL

### 1.事务基本特性

* 事务：满足ACID特性的一组操作，可以通过Commit提交一个事务，也可以使用Rollback进行回滚
* A原子性：一个事务的操作要么全部成功要么全部失败
* C一致性：事物前后的数据总量不变
* I隔离性：事务与事务之间相互不影响
* D持久性：事务一旦提交发生的改变不可逆

### 2.存储引擎Myisam和InnoDB的区别(⭐)

* InnoDB支持**事务、外键、行级锁**，MyIsam都不支持
* InnoDB是**聚簇索引**，MyIsam是**非聚簇索引**
* InnoDB支持**自增和MVCC模式的读写**，MyIsam不支持
* InnoDB**支持数据库异常崩溃后的安全恢复**，MyIsam不支持

### 3.了解哪些锁？(⭐)

* **意向锁**：通过**意向锁**快速判断数据行是否可以加锁 ，意向锁是由数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加锁之前，InnoDB会获取该数据行所在数据表的对应意向锁。

* 基于**粒度划分**：

  * **表级锁**：对整张表加锁，粒度大，实现简单，资源消耗较少，加锁快。但触发锁冲突的概率最高，高并发下效率极低

  * **行级锁**：对行加锁，粒度小并发度高，但加锁开销大，加锁慢，会出现死锁

  * **间隙锁**：间隙锁，锁住表的一个区间，间隙锁之间不会冲突只在可重复读下才生效

* 基于**属性划分**：

  * **共享锁**：又称读锁，一个事务为表加了读锁，其它事务只能加读锁，不能加写锁

  * **排他锁**：又称写锁，一个事务加写锁之后，其他事务不能再加任何锁，避免脏读问题   

### 4.事务靠什么保证

* 原子性：由undolog日志保证，他记录了需要回滚的日志信息，回滚时撤销已执行的sql

* 一致性：由其他三大特性共同保证，是事务的目的

* 隔离性：由MVCC保证
* 持久性：由redolog日志和内存保证，mysql修改数据时内存和redolog会记录操作，宕机时可恢复

### 5.事务的隔离级别(⭐)

* 读未提交（Read-Uncommit）：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

* 读已提交（Read-commit）：    允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生

* 可重复读(Repeatable-Read)(InnoDB默认)：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。

* 可串行化（serializable）：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

  ![image-20230224165723346](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230224165723346.png)

### 6.并发事务控制方式(⭐)

* 并发事务控制方式分为锁和MVCC。锁可以看作是悲观控制的模式，MVCC可以看作是乐观控制的模式
* **锁**是通过读写锁显示控制共享资源。**读锁又叫共享锁（S锁）**，事务在读取记录的时候获取共享锁，允许多个事务同时获取。**写锁又叫排他锁**，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条记录加任何类型的锁。
* **MVCC**是多版本并发控制，对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。MVCC的实现主要依赖于隐藏字段、read view 、undo log，其中隐藏字段和read view用于判断当前版本数据可见性，undo log用于记录某行数据的多个版本数据。

### 7.并发事务带来了哪些问题？

* **脏读**：一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚，导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据，这也就是脏读的由来。

  ![image-20230222191916786](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222191916786.png)

* **不可重复读**（Unrepeatable read）：指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读

  ![image-20230222192328013](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222192328013.png)

* **幻读**（Phantom read）：发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

  ![image-20230222192222338](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222192222338.png)

* **丢失修改**（Lost to modify）：在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改

![image-20230222193958294](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230222193958294.png)

* **不可重复读与幻读区别** ：
  * 不可重复读针对的是某一行数据发生修改，而幻读针对的是数据总数发生新增

### 8.什么是快照读和当前读

* **快照读** 读取的是当前数据的可见版本，可能是历史版本。如果读取的记录正在执行 修改或删除 操作，读取操作不会因此去等待记录上 排他锁的释放，而是会去读取行的一个快照。

* **当前读**读取的是数据的最新版本，并且当前读返回的记录都会上锁，保证其他事务不会并发修改这条记录。

### 9.InnoDB 引擎对MVCC的实现

* MVCC是多版本并发控制，实现依赖于**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 隐藏字段和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的隐藏字段找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改。

### 10.MySQL三大日志

* binlog（归档日志）：会记录所有涉及更新数据的逻辑操作，并且是顺序写

* redo log（重做日志）：让mysql拥有崩溃恢复能力。比如MySQL实例挂了或宕机了，重启时InnoDB存储引擎会使用redo log恢复数据，保证了数据的持久性和完整性

* undo log（回滚日志）：所有事务进行的修改都会记录到回滚日志上。当发生异常时需要对已执行的操作进行回滚，回滚机制就是通过回滚日志实现的

### 11.MySQL如何存储IP地址？

* 通过Inet_aton()方法把ip转为无符号整型，使用inet_ntoa()方法将整型的ip转为地址，性能好占用空间小

### 12.索引

* 索引是一种用于快速查询和检索数据的数据结构，相当于字典的目录。MySQL索引底层数据结构为B+树
* 优点：当数据量较大时使用索引可以大大加快数据的检索速度。通过创建唯一性索引，可以保证数据库表每一行数据的唯一性
* 缺点：创建索引和维护索引需要耗费许多时间，索引的存储会占用部分内存空间

### 13.MySQL有哪些索引

* 主键索引：一张表只能有一个主键索引，主键索引列不能有空值和重复值

* 唯一索引：唯一索引不能有相同值，但允许为空

* 普通索引：允许出现重复值

* 组合索引：对多个字段建立一个联合索引，减少索引开销，遵循最左匹配原则

* 全文索引：myisam引擎支持，通过建立倒排索引提升检索效率

### 14.聚簇索引和非聚簇索引的区别

* 聚簇索引的B+树叶子节点存放的是主键和数据，而非聚簇索引B+树叶子节点存放的是主键。因此聚簇索引的优点是查询速度快，对主键的排序查询和范围查找效率更高，缺点是更新代价大，而非聚簇索引优点是更新代价更小，缺点是可能存在二次查询。

### 15.MySQL如何做慢SQL优化(⭐)

* 首先开启慢查询日志，通过set global long_query_time等于阈值来将超过阈值的sql记录到慢查询日志当中，然后在这些慢sql语句前面添加explain来查看执行计划。优化措施有：

  * 分析sql语句，是否加载了不需要的数据列


  * 分析sql执行计划，字段有没有索引，索引是否失效，是否用对索引


  * 使用复杂查询时，尽量使用**关联查询**来代替子查询，并且最好使用**内连接**


  * 分页查询时，如果偏移量太大，比如要查询一百万条数据后的十条记录，可以使用主键+子查询的方式，避免进行全表扫描


  * 在写update语句时，where条件要添加使用索引，否则会锁会从行锁升级为表锁


  * 分析数据表中数据是否太大，是不是要分库分表

### 16.为什么要用内连接而不用外连接？

* 用外连接的话连接顺序是固定死的，比如left join，它必须先对左表进行全表扫描，然后一条条到右表去匹配；而内连接的话mysql会根据查询优化器去判断用哪个表做驱动。

### 17.MySQL整个查询的过程(⭐)

* 首先客户端将发送请求与服务器的连接器进行TCP三次握手，建立连接，并检验客户端的用户名和密码，读取用户权限，此时读取到的权限是后面所有权限判断都基于此时读取到的权限，即使中途权限被修改了，只要不重新建立连接也是使用该权限
* 连接器完成工作后，客户端就可以向MySQL发送sql语句了，然后会解析sql语句第一个字段是否为select，若是将会查询缓存，缓存中存储的数据是sql语句为键，查询结果为值。若命中缓存则直接返回Value值，否则继续执行。可以看出该操作很鸡肋，当数据库有更新操作时，缓存会被清空，因此8.0版本后删除了查询缓存这个功能。
* 然后再就进入解析器工作，主要包括两部分一部分是词法分析，识别sql语句中关键字构建SQL语法树，另一部分是语法分析，判断sql语句是否满足MySQL语法
* 最后执行sql过程又分为三个阶段，一是预处理器阶段，将检查语句中表或字段是否存在，并把select*替换为表上所有列，二是优化器阶段，确定sql的执行计划，三是执行器阶段，根据执行计划执行sql查询语句，从存储引擎读取记录返回给客户端

![image-20230224101010856](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230224101010856.png)

### 18.哪些情况索引会失效

* where条件中有or，除非所有查询条件都有索引，否则失效

* 模糊查询用%开头，索引失效

* 索引列参与计算，索引失效

* 违背最左匹配原则，索引失效

* 索引字段发生类型转换，索引失效

### 19.索引优化方法

* 主要有前缀索引优化方法、覆盖索引优化方法，并且主键索引最好自增，防止索引失效

* 前缀索引优化方法：由于有的字符串太长，所以可以减小索引字段的大小，减少索引占用的存储空间，提升查询效率。

* 覆盖索引优化方法：如果查询的字段都能在索引的b+树找到，就不需要回表操作了

* 主键自增的好处是不会涉及数据移动，相当于数据按照页的顺序一页页写，每页中一行行写，不需要移动数据，如果使用非主键递增，会出现数据页面，甚至出现页的分裂，出现内存碎片，影响效率。并且索引最好设置为not null：
  * 索引列存在null会查询优化器在做索引选择时变得更加复杂，更加难优化，如在count时会省略索引为null的值
  * null是一个没有意义的值，它会占用空间，InnoDB允许字段为空，至少会有一个字节的空间存储null值



### 20.Mysql内连接、左连接、右连接的区别

* 内连接取两表交集部分，左连接取左表全部右表匹配部分，右连接取右表全部左表匹配部分



### 21.explain

* 在sql语句前面加上explain，将输出这条sql语句的执行计划，输出结果中的key表示的就是执行过程中使用到的索引，如果key为空表示没有使用索引即全表扫描



### 22.where和having的区别？

* `where`：过滤过滤指定的行，后面不能加聚合函数（分组函数）。`where` 在`group by` 前。

* `having`：过滤分组，一般都是和 `group by` 连用，不能单独使用。`having` 在 `group by` 之后。

  

### 23.char和varchar的区别

char是不可变的，最大长度为255，varchar是可变的字符串，最大长度为2^16

### 24.InnoDB 什么情况下会产生死锁

* 事务1已经获取数据A的写锁，想要去获取数据B的写锁，然后事务2获取了B的写锁，想要去获取A的写锁，相互等待形成死锁。
  mysql解决死锁的机制有两个：1.等待， 直到超时 2.发起死锁检测，主动回滚一条事务
* 死锁检测的原理是构建一个以事务为顶点、 锁为边的有向图， 判断有向图是否存在环， 存在即有死锁。

### 25.MySQL 删除自增 id，随后重启 MySQL 服务，再插入数据，自增 id 会从几开始？

* innodb 引擎：
  MySQL8.0前，下次自增会取表中最大 id + 1。原理是最大id会记录在内存中，重启之后会重新读取表中最大的id
  MySQL8.0后，仍从删除数据 id 后算起。原理是它将最大id记录在redolog里了

* myisam：自增的 id 都从删除数据 id 后算起。原理是它将最大id记录到数据文件里了

### 26.MySQL插入百万级的数据如何优化？

* **一次sql插入多条数据，**可以减少写redolog日志和binlog日志的io次数（sql是有长度限制的，但可以调整）

* 保证数据**按照索引进行有序插入**

* 可以分表后**多线程插入**

### 27.如何解决幻读(⭐)

* 使用串行化的隔离级别可以解决幻读问题，但是一般不建议，因为这样性能会大大下降

* MySQL默认的隔离级别是可重复读，在这个隔离级别下，很大程度解决了幻读问题，但是没有完全解决
  * 针对**快照读**：通过MVCC解决了快照读幻读问题，因为可重复读模式下，只会在事务开启时生成一个read_view,后续其他事务插入和从删除是不可见的，避免了幻读问题
  * 针对**当前读**：通过临键锁next-key lock来实现的，临键锁是记录锁加间隙锁，当执行select  or update时，会加上临键锁，如果有其他事务在临键锁范围内增删数据会被阻塞，避免了幻读问题



### 28.分库分表(⭐⭐)

* 分库：分为垂直分库与水平分库，其中垂直分库是将单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库，适用于数据列过多的情况。水平分库是将同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题，适用于数据行过多的情况。
* 分表：分为垂直分表和水平分表，**垂直分表** 是对数据表列的拆分，把一张列比较多的表拆分为多张表。**水平分表** 是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。

* 常见分片算法：主要是数据被水平分片之后，数据究竟该存放在哪个表的问题。
  * **哈希分片** ：求指定 key（比如 id） 的哈希，然后根据哈希值确定数据应被放置在哪个表中。哈希分片比较适合随机读写的场景
  * **范围分片** ：按照特性的范围区间来分配数据。范围分片适合需要经常进行范围查找的场景
  * **地理位置分片** ：根据地理位置（如城市、地域）来分配数据。
  * **融合算法** ：灵活组合多种分片算法，比如将哈希分片和范围分片组合

### 29.分库分表带来的问题

* **join 操作** ： 同一个数据库中的表分布在了不同的数据库中，导致无法使用 join 操作。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。

* **事务问题** ：同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。

* **分布式 id** ：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。需要引入分布式 id 来解决该问题。



### 30.分库分表后，数据怎么迁移呢？

* **停机迁移**，写个脚本将老库的数据写到新库中。如在凌晨 一两点，系统使用的人数非常少的时候，挂一个公告说系统要维护升级预计 1 小时。然后，写一个脚本将老库的数据都同步到新库中。
* 针对不能停机迁移的场景使用**双写方案**，具体原理是对老库进行更新操作，同时将数据写入新库，如果在操作过程中数据不存在于新库，则直接插入新库，由于这个操作只是让老库被更新数据写入了新库，但未保证老库所有数据准确无误写入新库，因此还需要写个脚本将老库数据与新库数据进行比对，新库没有的直接插入，新库有但老库没有的则直接删除，反复上面操作。



### 31.

### 32.为什么MySQL采用B+树作为索引？(⭐)

* 因为MySQL的数据持久化是将索引和记录保存在磁盘上的，这样即使断电了数据也不会丢失，但是磁盘访问速度非常慢，因此选择的数据结构应尽可能执行少量磁盘I/O操作就能完成查询工作，同时还应该支持范围查询。像数组链表这些数据结构，如果在存入时不排序那么查询时间复杂度是O（n），若排序的话，排序过程与查询过程都要耗费大量时间，因此就需要用到非线性且天然适合二分查找的数据结构。但像二分查找树的话，它们高度较高，在极端情况下树会退化为链表，查询时间复杂度还是O（n），同时在多次执行插入操作后树会越来越高，直接影响性能，且不支持范围查询。平衡二叉树虽然高度不会像二分查找树增加的快但本质上也是二叉树，每个节点只有两个子节点，因此当节点很多时树还是很高。所以再从多叉树中选，B树的话主要问题是范围查询太慢，范围查询需要进行大量回溯，并且索引和记录存在每个节点中。而B+树就与众不同，它将索引与记录存在叶子节点，而非叶子节点存储的是索引，这样以来B+树相较于B树而言就更加矮胖查询底层节点IO次数更少，并且B+树的插入和删除效率更高，同时叶子节点之间构成一个有序链表可以很好的进行范围查询。
* ![image-20230329103004305](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230329103004305.png)



### 33.Mysql高性能优化

* 将关联的字段放在一个表中，避免表的关联
* 不要在表中设置预留字段
* 不要在数据库中存文件
* 禁止在数据库上做压力测试
* 尽可能将字段设置为not null

* 每个InnoDB设置一个主键，主键建议设置自增

* 禁止使用select *

* 充分利用数据库上的索引，避免出现索引失效的情况

* 超过100w的数据批量写，需要分批



### 34.这四种隔离级别具体是如何实现的呢？

- 「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
- 「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View
- 「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View
- 「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；



## Redis

### 1.热点数据处理方法

* 存放到redis缓存中的海量数据，通过设置过期时间来保存热点数据

### 5.分布式锁redission

* 突发性热点数据：由于数据并未及时存入缓存中，因此大量服务请求将会直接转向数据库，因而可能导致数据库崩了。解决方案：通过redission.getLock获取分布式锁来使得并行访问数据变为串行，但会降低服务器性能。因此可以使用redission.tryLock(time,TimeUnit）来设置等待一段时间，若等待过程中获得了锁那么就直接往后执行，否则等完time时间后直接往下执行，由于第一个线程进来操作time时间后会将缓存更新好，因此其他线程集体等待这么长时间后会直接跳过分布式锁向下执行，从而将串行变并行，但时间time很难估计，因此能不能使用还得看具体业务场景。



### 6.Redis基本类型及应用场景

* 常见类型：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）**
* String：**用于存储图片或者序列化的对象**，存数据使用set key value，获取数据使用get key；底层实现使用SDS（simple dynamic string），其中原因之一是SDS中获取字符串长度时间复杂度是O（1）。
* Hash：**指存的数据的value值又是一个key-value键值对**，存数据使用hset key field value，获取数据使用hget key field。底层存储结构是压缩列表或哈希表。适用于缓存用户信息
* List：**用来存储多个有序的字符串**。底层实现是链表或压缩列表
* Set：**用于存储多个字符串元素，但不允许重复**。底层实现是哈希表或整数集合
* Zset：**用于已排序的字符串集合，但不允许重复**。底层实现是压缩列表或跳跃表
* 特殊数据结构：

![image-20230415171950694](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230415171950694.png)

![image-20230415172001895](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230415172001895.png)



### 7.Redis持久化(⭐)

### 8.什么是Redis？

* Redis是一个基于内存实现的Key-Value存储结构的Nosql开源数据库。它提供了5种常用的数据类型，String、Map、Set、ZSet、List。由于Redis是基于内存存储，并且在数据结构上做了大量的性能优化，因此非常适合作为应用与数据库之间分布式缓存组件。并且它是非关系型数据库，不存在表之间的关联查询等问题，所以redis可以提升应用程序的数据IO效率。同时又提供了主从复制、哨兵、集群来实现高可用，通过hash槽实现了数据分片，进一步提升了性能。



### 9.Redis更新策略

* **旁路缓存策略**（默认）：在执行写操作时先更新数据库中的数据，然后再删除缓存中的该数据，若顺序反了会出现缓存与数据库双写不一致问题。在执行读操作时，首先读取缓存，若命中则直接返回数据，若未命中，则从数据库中读取数据，然后将数据写入缓存，并返回给客户端。



### 10.Redis单线程模式

* **Redis 单线程指的是接收客户端请求到解析请求 然后进行数据读写等操作然后发送数据给客户端这个过程是由一个主线程来完成的**。由于**关闭文件、AOP刷盘、释放缓存**这些任务操作很耗时，若把这些任务都放在主线程处理，主线程就很容易发生阻塞。因此Redis将这些任务分别放在各自的任务队列，由后台线程不断轮询这些队列，拿出任务然后执行。**由于网络硬件的性能提升，Redis的性能瓶颈可能会出现在网络IO的处理上，因此Redis6.0之后引入多线程来处理网络IO，但命令的执行仍然是单线程处理**。

![image-20230416094443608](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230416094443608.png)

### 11.Redis如何实现服务高可用？

* **主从复制**：将主服务器上的数据同步到多台从服务器上，且主从服务器之间读写分离。主服务器可以进行读写操作，当发生写操作时主服务器自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令。因此所有的数据修改只在主服务器上进行，然后将最新的数据同步到从服务器。但是主从服务器之间命令复制是异步的，主服务器执行写操作，执行完后不会等待从服务器数据也更新好，而是会直接将结果返回给客户端，因此可能存在数据不一致问题。

![image-20230416155216571](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230416155216571.png)

* **哨兵模式**：当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复。因此提出了哨兵模式（**Redis Sentinel**），来监控主从服务器，并且提供**主从节点故障转移的功能**
* **切片集群模式**：当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群**（Redis Cluster ）方案，将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。切片集群方法是使用哈希槽来实现将数据映射到不同节点上的。



### 12.集群脑裂导致数据丢失怎么办？

* 原因： 如果主节点的网络突然出现问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，客户端并不知道 Redis 内部已经出现了问题，还在向这个失联的主节点写数据，此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点失联，所以这些数据无法同步给从节点的。此时，哨兵发现主节点失联了，它就认为主节点挂了，于是哨兵就会在从节点中选举出一个 leader 作为主节点，这时集群就有两个主节点，出现了脑裂。

* 解决方案：当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

  

### 13.Redis 使用的过期删除策略是什么？（惰性删除+定期删除）

* **惰性删除 **：**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key**。因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，但是会造成内存空间浪费。
* **定期删除**：**每隔一段时间随机从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。若已过期key的数量占比随机抽取key的数量大于25%那么就重复执行上述操作，否则就停止继续删除过期key**。**优点**是通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用，**缺点**是如果执行的太频繁，对 CPU 不友好；如果执行的太少，过期 key 占用的内存不会及时得到释放。

### 14.Redis 持久化时，对过期键会如何处理的？

* **RDB文件** 在**生成阶段**，会对key进行过期检查，过期的key不会被保存到新的RDB文件中。在**加载阶段**主服务器加载RDB文件时，程序会对文件中保存的key进行检查，过期的key不会被载入到数据库中，而从服务器在加载RDB文件时无论key是否过期都会载入到数据库中，但是在进行主从服务器数据同步时，从服务器会被清空。
* **AOF文件** 在**写入阶段** 如果数据库某个过期key还没有被删除，那么AOF文件会保留此过期key，当此过期key被删除时，Redis会向AOF文件追加一条DEL命令来显示删除该key。在重写阶段，会对Redis中键值对进行检查，已过期的key不会被保存到重写后的AOF文件中。



### 15.Redis 主从模式中，对过期键会如何处理？

* 当 Redis 运行在主从模式下时，**从库不会主动进行过期扫描**。即使从库中的 key 过期了，客户端依然可以访问到 key 对应的值。从库的过期键处理依靠主服务器控制，**主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库**，从库通过执行这条 del 指令来删除过期的 key。



### 16.Redis 内存满了，会发生什么？

* 当Redis的运行内存达到最大允许内存时，就会触发**内存淘汰机制**，内存淘汰机制分为不进行数据淘汰和进行数据淘汰。
  * **不进行数据淘汰**的策略是**noeviction**，不淘汰任何数据，而是不再提供服务，直接返回错误，是Redis3.0之后默认的内存淘汰策略。
  * **进行数据淘汰**又分为在**设置了过期时间的数据**中进行淘汰和在**所有数据中进行淘汰**
    * **设置了过期时间的中进行淘汰数据**：
      * **volatile-random**：随机淘汰
      * **volatile-ttl**：优先淘汰更早过期的键值。
      * **volatile-lru**：最久未使用的键值；
      * **volatile-lfu**：最少使用的键值；
    * **所有数据中进行淘汰**：
      * **allkeys-random**：随机淘汰;
      * **allkeys-lru**：最久未使用的键值；
      * **allkeys-lfu**：最少使用的键值

### 17.Redis 如何实现延迟队列？

* 延迟队列是指把当前要做的事情，往后推迟一段时间再做。如在淘宝上下单，超过一定时间未付款，订单会自动取消。使用Redis 可以使用有序集合（ZSet）来实现延迟消息队列，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。使用 zadd score1 value1 命令来生成消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可

![image-20230416214053021](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230416214053021.png)



### 18.Redis 事务支持回滚吗？

* Redis不提供回滚机制，虽然Redis提供了discard命令，但它只是主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。因此Redis并不一定保证原子性。不支持回滚的原因是出现的错误通常只会出现在开发环境，因此没有必要回滚，同时支持回滚需要复杂的功能，与Redis追求高效的设计主旨不符。



### 19.Redis与Memcached区别

* 共同点：
  * 都是基于内存的数据库，一般都用来当做缓存使用。
  * 都有过期策略。
  * 两者的性能都非常高
* 区别：
  * Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；
  * Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；
  * Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；
  * Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；

### 20.为什么用Redis作为MySQL的缓存？

* **高性能**：假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从**硬盘**上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，**操作 Redis 缓存就是直接操作内存，所以速度相当快**。但是操作数据库与缓存是异步的，所以存在双写不一致问题。
* **高并发**：单台设备的 Redis QPS 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。

# 框架

## Spring

### 1.spring bean的生命周期(⭐)

* 首先Bean 容器找到配置文件中 Spring Bean 的定义，然后利用 Java Reflection API 创建一个 Bean 的实例对象，利用set方法给涉及到的属性设值，然后检验Bean是否实现了Aware相关的接口，如BeanNameAware、BeanNameFactoryAware等，若有就调用相关方法。如果有加载与容器相关的BeanPostProcessor对象，就执行前置处理方法。如果实现了InitialingBean接口，则执行afterPropertiesSet方法。若定义了 init-method 属性，则执行指定的方法。同样地，如果有加载与容器相关的BeanPostProcessor对象，就执行后置处理方法。然后就可以使用bean对象了。使用完后销毁 Bean 时，如果 Bean 实现了 `DisposableBean` 接口，则执行 `destroy()` 方法。若定义了 destroy-method 属性，则执行指定的方法。

![image.png](https://fynotefile.oss-cn-zhangjiakou.aliyuncs.com/fynote/1462/1646114654000/cf1072694ce9496aa04c3c6fde40c38a.png)

* ### 从IOC容器里面取得一个Bean的流程

* **加载 Spring 配置文件**：首先需要加载 Spring 配置文件，这可以通过使用 ClassPathXmlApplicationContext 或 FileSystemXmlApplicationContext 等容器实现。

* **创建 BeanFactory**：容器在加载配置文件时，会解析配置文件中的 Bean 定义，并将其存储在内部的 BeanFactory 中。

* 定位 Bean 定义：当调用容器的 getBean() 方法获取 Bean 实例时，容器会根据 Bean 的 ID 或名称定位 Bean 定义。

* 创建 Bean 实例：当容器找到了 Bean 的定义后，就会根据定义创建 Bean 实例。在创建 Bean 实例之前，容器需要先判断该 Bean 是否为单例 Bean，如果是，则容器会检查该 Bean 是否已经创建过，如果已经创建过，则直接返回现有的 Bean 实例，否则会创建一个新的 Bean 实例。如果该 Bean 是多例 Bean，则容器会每次调用 getBean() 方法时都创建一个新的 Bean 实例。

* Bean 属性赋值：在 Bean 实例化之后，容器会对 Bean 的属性进行赋值，这些属性值通常来自配置文件中的  标签或 @Autowired 注解。

* Aware 回调：如果该 Bean 实现了 Aware 接口，则容器会自动调用该接口的回调方法，以便 Bean 获取容器相关的信息。\nBeanPostProcessor 处理：如果该 Bean 实现了 BeanPostProcessor 接口，则容器会在 Bean 初始化前后调用 BeanPostProcessor 的 postProcessBeforeInitialization() 和 postProcessAfterInitialization() 方法。

* 初始化 Bean：在 Bean 属性赋值和 Aware 回调之后，容器会调用 Bean 的初始化方法，包括实现了 InitializingBean 接口的 afterPropertiesSet() 方法和使用 @PostConstruct 注解标记的方法。

* 返回 Bean 实例：当 Bean 初始化完成后，容器会将其返回给调用者，调用者可以通过 Bean 实例来访问 Bean 的方法和属性。

* 销毁 Bean：当容器关闭时，会调用实现了 DisposableBean 接口的 destroy() 方法和使用 @PreDestroy 注解标记的方法，以销毁 Bean 实例并释放资源。

### 2.IOC(⭐)

* IOC是一种控制反转的思想，目的是把**创建和查找依赖对象**地控制权交给容器，由容器进行注入组合对象，所以对象与对象之间是松散耦合地，利于功能复用，使得整个体系结构都是非常灵活。比如，在类A中有属性B，在没有IOC容器的情况下，A中属性B的初始化需要手动new，在使用A的实例对象时，同样也需要手动new，但是引入IOC的思想后，可以将A与B的对象创建交给IOC容器，需要用那个对象直接向IOC容器要就可以。在Spring时代通过XML配置Bean，但由于配置较繁琐，因此在SpringBoot中使用注解进行配置。**IOC的具体实现主要表现在工厂模式**
* ![image-20230320212941210](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230320212941210.png)

### 3.AOP(⭐)

* AOP是一种面向切面编程的思想，目的是**将与业务不相关但很多业务都要调用的代码抽离出来，在不侵入原有代码的情况下对功能进行增强**。SpringAOP的实现是基于**动态代理**实现的，如果被代理类实现了某个接口SpringAOP就会采用JDK动态代理来创建代理对象，JDK动态代理是利用反射来实现的，需要调用Proxy类下newProxyInstance方法返回代理对象。如果被代理类没有实现接口，则SpringAOP会使用CgLib动态代理来创建代理对象，CgLib动态代理通过把被代理类的class文件加载进来通过修改字节码生成子类来实现创建代理类的。
* AOP常用注解：
  * **@Aspect**：：把当前类声明为切面类。
  * @**Before**：把当前方法看成是前置通知。其中属性value是用于指定切入点表达式，还可以指定切入点表达式的引用
  * @AfterReturning：把当前方法看成是后置通知。其中属性value作用与前面相同
  * @AfterThrowing：把当前方法看成是异常通知。value
  * **@After**：把当前方法看成是始终通知。value
  * @Around：把当前方法看成是环绕通知。value
  * @Pointcut：指定切入点表达式。value

### 4.设计模式(⭐⭐)

* 单例模式作用域是singleton，也就是只创建一个bean对象，所有线程共用这一个。
  * **双重校验锁实现对象单例（线程安全）**

![image-20230321113931703](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230321113931703.png)

* **工厂模式**：是IOC的一种应用，目的是将Bean的创建过程交给工厂，Spring容器管理这个工厂，实现创建和使用的分离。可以通过BeanFactory或ApplicationContext创建bean对象，其中BeanFactory仅提供最基本的依赖注入，而ApplicationContext扩展了BeanFactory的功能，它是在容器启动时一次性创建所有bean

  ```java
  import org.springframework.context.ApplicationContext;
  import org.springframework.context.support.FileSystemXmlApplicationContext;
  
  public class App {
  	public static void main(String[] args) {
  		ApplicationContext context = new FileSystemXmlApplicationContext(
  				"C:/work/IOC Containers/springframework.applicationcontext/src/main/resources/bean-factory-config.xml");
  
  		HelloApplicationContext obj = (HelloApplicationContext) context.getBean("helloApplicationContext");
  		obj.getMsg();
  	}
  }
  ```

* **代理模式**：是AOP的一种应用，将与业务不相关但很多业务都要调用的代码抽离出来，从而在不侵入原有代码的情况下对功能进行增强

### ５.什么是Spring Bean？

* Bean指的是被Ioc容器管理的对象，Bean声明方式有基于XML的、基于注解的、基于Java配置类的。



### 6.常用注解

* `@Component` ：通用的注解，可标注任意类为 `Spring` 组件。如果一个 Bean 不知道属于哪个层，可以使用`@Component` 注解标注。
* `@Controller` : 作用于Controller层，主要用于接受用户请求并调用 `Service` 层返回数据给前端页面
* `@Service` : 作用于Service层，主要涉及一些复杂的逻辑，需要用到 Dao 层。

* `@Repository` : 作用于Dao 层，主要用于数据库相关操作。



### 7.@Component 和 @Bean 的区别是什么？

- **`@Component` 注解作用于类，而`@Bean`注解作用于方法。**
- `@Component`通常是**通过类路径扫描来自动装配到 Spring 容器**中。`@Bean` 注解作用于方法，告诉方法产生一个该方法返回类型的Bean对象交给Spring管理。
- `@Bean` 注解比 `@Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现



### 8.@Autowired和@Resource 的区别是什么？（⭐)

* 共同点：两者都是做bean的注入时使用的 ，都可以写在字段或set方法上面

* 不同点：Autowired由Spring提供，注入时按照类型注入，默认情况下，依赖对象不能为空 ，但可以通过required=false来设置允许为空。而Resource由JDK提供，默认依据名称注入，若无法通过名称注入，则会依据类型进行注入，同时Resource有两个属性name和type，可以通过设置这两个属性显示注入。**当一个接口存在多个实现类的情况下，`@Autowired` 和`@Resource`都需要通过名称才能正确匹配到对应的 Bean。`Autowired` 可以通过 `@Qualifier` 注解来显式指定名称，`@Resource`可以通过 `name` 属性来显式指定名称**

  

### 9.Bean 的作用域有哪些?（⭐)

- **singleton** : IoC 容器中只有唯一的 bean 实例。 bean 默认都是单例的。
- **prototype** : 每次获取都会创建一个新的 bean 实例。
- **request** : 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。
- **session**  : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），一个session共用一个bean，在session过期后实例会消失。
- **global-session**： 每个 Web 应用在启动时创建一个 Bean（应用 Bean）。
- **websocket** ：每一次 WebSocket 会话产生一个新的 bean。

### 10.单例bean的线程安全问题

* 由于在多线程操作某个对象时，单例bean只会创建一个对象，因此多线程存在资源竞争的问题，可以通过在类中定义一个ThreadLocal来将对象变为每个线程私有，但大多数情况比如在service层，dao层中bean都是无状态的，这种情况下Bean是线程安全的。



### 11.Spring MVC 的核心组件有哪些？

- **`DispatcherServlet`** ：**核心的中央处理器**，负责接收请求、分发，并给予客户端响应。
- **`HandlerMapping`** ：**处理器映射器**，根据 uri 去匹配查找能处理的 `Handler` ，并会将请求涉及到的拦截器和 `Handler` 一起封装。
- **`HandlerAdapter`** ：**处理器适配器**，根据 `HandlerMapping` 找到的 `Handler` ，适配执行对应的 `Handler`；
- **`Handler`** ：**请求处理器**，处理实际请求的处理器。
- **`ViewResolver`** ：**视图解析器**，根据 `Handler` 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 `DispatcherServlet` 响应客户端



### 12.SpringMVC工作原理（⭐)

* 客户端发送请求， `DispatcherServlet`拦截请求。`DispatcherServlet` 根据请求信息调用 `HandlerMapping` 。`HandlerMapping` 根据 uri 去匹配查找能处理的  `Controller`  ，并会将请求涉及到的拦截器和 `Controller` 一起封装。然后`DispatcherServlet` 调用 `HandlerAdapter`适配执行 `Controller` 。`Controller` 完成对用户请求的处理后，会返回一个 `ModelAndView` 对象给`DispatcherServlet`，`ModelAndView`包含了数据模型以及相应的视图的信息。

  然后调用`ViewResolver` ，它会根据逻辑 `View` 查找出实际的 `View`。然后`DispaterServlet` 把返回的 `Model` 传给 `View`进行视图渲染。最后将渲染好的 `View` 返回给客户端

![image-20230321111228417](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230321111228417.png)



### 13.Spring MVC

* MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将数据、显示、业务逻辑分离来组织代码



### 14.Spring 管理事务的方式有几种？

- **编程式事务** 是在代码中 通过 `TransactionTemplate`或者 `TransactionManager` 手动管理事务，这种方式带来了很大的灵活性，但很难维护，实际应用中很少使用
- **声明式事务** 是将事务管理和业务代码分离，通过注解或者XML配置管理事务



### 15.事务的传播行为（⭐)

* **事务传播行为是为了解决业务层方法之间互相调用的事务问题**。当事务方法被另一个事务方法调用时，必须指定事务应该如何传播

| 事务行为                  | 说明                                                         |
| :------------------------ | :----------------------------------------------------------- |
| propagation_required      | 支持当前事务，假设当前没有事务。就新建一个事务               |
| propagation_supports      | 支持当前事务，假设当前没有事务，就以非事务方式运行           |
| propagation_mandatory     | 支持当前事务，假设当前没有事务，就抛出异常                   |
| propagation_requires_new  | 新建事务，假设当前存在事务。把当前事务挂起                   |
| propagation_not_supported | 以非事务方式运行操作。假设当前存在事务，就把当前事务挂起     |
| propagation_never         | 以非事务方式运行，假设当前存在事务，则抛出异常               |
| propagation_nested        | 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作。 |

### 16.@Transactional注解作用范围

* 一般作用于public修饰的方法上面，也可以作用于类上，表示该类所有的public方法都加上了事务注解。



### 17.循环依赖（⭐⭐)

* 首先单例模式与原型模式通过构造方法注入属性时是无法解决循环依赖的，同时原型模式通过设置属性注入是不支持循环依赖的，因此只有单例模式通过设置属性注入的方式才能被解决循环依赖问题，主要思想是通过三级缓存-提前暴露的思想。
* 由于Spring产生一个对象的主要步骤有三个阶段：一是调用构造方法实例化对象，二是填充属性，三是初始化，那么可以看出产生循环依赖的真正原因是在第二阶段填充属性时，当A有属性B，B有属性A时，填充属性将产生循环依赖。具体解决流程是，首先A调用构造方法实例化，然后将自己提前曝光到三级缓存中的第三级缓存，然后填充属性，发现需要填充B，然后get（B），发现B并未创建，然后创建B，同样B实例化后需要填充属性A，然后get（A），此时去三级缓存中寻找A，发现第三级缓存有A，然后通过BeanFactory生成半成品的A放入二级缓存，此时B可以在二级缓存拿到A，然后B成功完成阶段2，3，并将自己放入一级缓存，此时A也可以拿到B，顺利完成阶段2，3。对象A与B顺利创建。

![image-20230321155450516](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230321155450516.png)



## SpringBoot

### 1.SpringBoot的自动装配（⭐)

* 介绍SpringBoot的自动装配过程的话首先得说一下对应的启动类注解SpringBootApplication，该注解包含三个主要注解分别是@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan
* SpringBootConfiguration的的作用功能上与Configuration完全等价表示当前类是个配置类，但不同的是Configuration标注的可以有多个配置类，而SpringBootConfiguration标注的只能有一个配置类。
* EnableAutoConfiguration包含两个重要注解，其中AutoConfigurationPackage表示该注解标注的类的包名将会被记录到容器中，下次使用的时候可以直接通过BeanFactory获取到该包名。其中Import通过ImportSelector选择器导入从属配置， 作用是分离主从配置信息，保证先解析完Bean、ComponentScan等注解 信息，最后才解析Import注解导入的从属配置信息，从而降低耦合度，Import注解读取的信息固定为classpath下META-INF/spring.factories中的自动配置类
* ComponentScan注解的作用是做组件扫描的，扫描如Component、Controller、Service等，同时使用excludeFilters属性通过过滤器排除一些不希望扫描到的类

### 2.SpringBoot启动过程（⭐)

## MyBatis

微服务



## 分布式



# 中间键

## RPC

### 1.RPC**（Remote Procedure Call）**远程过程调用定义

* rpc是远程调用而非本地调用，因为不同服务器提供的方法可能不在同一个地址空间，所以需要通过网络编程来传递方法调用的参数，调用的结果也需要网络编程来接收，因为手动实现的话工作量十分巨大，需要考虑传输方式和序列化方式等，rpc出现就是希望远程调用和本地调用一样简单

### 2.RPC原理

* 首先客户端发起调用服务端方法的请求，然后客户端代理类对该请求方法、参数等信息封装成HTTP请求信息，然后应用程序调用Socket库来委托协议栈工作，协议栈对数据进行封装，添加上TCP头、IP头、MAC头等信息然后发送给网卡，网卡将数字信号转换为电信号在网络中传输，当服务端接收到电信号，网卡将电信号转化为数字信号，然后通过协议栈层层检查，通过检查的话服务端就将客户端需要的数据封装成数据包同样加上各种头部传送给客户端，客户端通过层层检查后，将请求信息返回给客户端。



![image-20230330153248254](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230330153248254.png)

### 



## 消息队列（结合项目回答）

### 1.消息队列

*  **中间件就是一类为应用软件服务的软件，应用软件是为用户服务的，用户不会接触或者使用到中间件**

### 2.消息队列作用

* **通过异步处理提高系统性能（减少响应所需时间）**，如当需要向数据库写入数据时，可以先将数据快速存入消息队列中然后立即返回，待数据真正处理完成后，返回处理成功的回复
* **削峰/限流**：**先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去处理这些消息，这样就避免直接把后端服务打垮掉**
* **降低系统耦合性**

![image-20230330171319594](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230330171319594.png)

## RabbitMQ

### 1.MQ（Message queue）概念

* MQ本质上是一个队列，遵循先进先出（FIFO），是在消息的传递过程中保存消息的容器。分布式系统通信有两种方式：**直接远程调用**和**借助第三方完成间接通信**。

![image-20230420103926043](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420103926043.png)



* 优势：应用解耦、异步提速、削峰填谷
* 劣势：
  * 系统可用性降低：由于系统引入了MQ，所以当MQ宕机时，会对业务造成影响，使得可用性降低。因此如何保证MQ的高可用
  * 复杂度提高：加入MQ增加了系统的复杂度，以前系统间是同步的远程调用，加入MQ后是异步调用，因此需要考虑如何保证消息没有被重复消费、如何处理消息丢失、如何保证消息传递的顺序性。
  * 一致性问题：如果A系统处理完业务，通过MQ给B、C、D三个系统发消息，若B失败了，C、D成功了，该如何保证数据处理的一致性。



![image-20230420152437823](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420152437823.png)



### 2.应用解耦

* **问题**：在实际应用中当订单系统要调用库存系统和支付系统时，

  * **若库存系统出现问题，那么整个系统就可能出错**，因此系统容错性很低

  ![image-20230420105737606](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420105737606.png)

  * **若订单系统需要访问的系统增多时，又需要修改订单系统代码**。因此系统可维护性低

![image-20230420105752512](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420105752512.png)

* **解决办法：使用MQ进行应用解耦**，在订单系统要访问其他子系统时，订单系统会发送消息给MQ，然后订单系统就可以操作成功的信息给用户，而其他子系统来对MQ中的消息进行消费。使得系统容错性提高。

  * 若**库存系统出现故障，订单系统也不会受到影响，因为他们是隔离的**，同时出故障的系统出现故障应该是短暂的，当系统恢复时还是可以从MQ中拿到消息进行消费的。

  * ![image-20230420110717254](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420110717254.png)
  * 若订单系统需要访问的系统增多，订单系统不需要添加其他的处理方法，新增的系统直接去MQ中拿到消息进行消费即可，使得系统可维护性高

### 3.异步提速

* 在没有加中间件的情况下，访问订单系统，系统首先会将数据写入数据库，然后再去串行执行其他每个子系统，因此整个过程是串行的，使得响应速度特别慢。

![image-20230420111840252](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420111840252.png)

* 因此可以使用中间件来进行异步提速，用户在使用订单系统时，将数据写入数据库后发送消息给中间件，之后就直接返回操作成功的信息给用户，而MQ中的消息由其他系统异步完成，从而大大提高了系统吞吐量。



![image-20230420111854245](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420111854245.png)



### 4.削峰填谷

* 当系统瞬间接收到的请求数大于最大能处理的请求数时，系统会出现崩溃，因此可以在访问系统之前使用MQ来进行流量削峰，让系统接收到的请求数不超过最大能处理请求数。从而大大提高系统稳定性

![image-20230420112551981](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420112551981.png)



### 5.RabbitMQ基本框架

* RabbitMQ是基于AMQP（高级消息队列协议）实现的，AMQP是一个类似于HTTP的网络协议

![image-20230420153107353](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420153107353.png)



* **Broker**:接收和分发消息的应用
* **Virtual host**:当多个不同的用户使用同一个Broker提供的服务时，可以划分出多个虚拟分组，每个用户在自己的分组 创建exchange /和queue等
* **Connection**: publisher 或consumer和 broker之间的TCP连接
* **Channel**:如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TCP Connection的开销将是巨大的，效率也较低。Channel是在connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通讯，AMQP method包含了channel id帮助客户端和message broker识别channel，所以channel之间是完全隔离的。
* **Exchange**: message到达 broker后，根据分发规则，匹配查询表中的 routing key，分发消息到queue 中去。
* **Binding**: exchange和queue之间的虚拟连接，binding 中可以包含 routing key。Binding信息被保存到exchange 中的查询表中，用于message 的分发依据



### 6.RabbitMQ的单队列模式

* **生产者Producer**

```java
//1.创建连接工厂
ConnectionFactory factory = new ConnectionFactory();
//2.设置参数
factory.setHost("192.168.86.128");
factory.setPort(5672);//默认值
factory.setVirtualHost("/rabbitmq-test");//虚拟机
factory.setUsername("guest");//默认guest
factory.setPassword("guest");//默认guest
//3.创建连接Connection
Connection connection = factory.newConnection();
//4.创建channel
Channel channel = connection.createChannel();
//5.创建Queue
/**
 * queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments)
 * queue：队列名称
 * durable：是否需要持久化，当mq重启之后，是否需要还存在
 * exclusive：表示是否独占，即只有一个消费者监听该队列，当Connection关闭时，是否删除队列
 * autoDelete：是否自动删除，但没有Consumer时会自动删除
 * arguments：参数
 */
//若没有hello队列则会创建该队列
channel.queueDeclare("hello", true, false, false, null);
/**
 * basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body)
 * exchange:交换机名称。简单模式默认为""
 * routingKey:路由名称
 * props：配置信息
 * body:发送的消息数据，rabbit中存放的是字节信息
 *
 */
//6.发送消息
String body = "hello rabbitmq~~";
channel.basicPublish("","hello",null,body.getBytes());

//7.释放资源，若不释放则通道或链接会一直存在
channel.close();
connection.close();
```

* **消费者Consumer**

```java
//1.创建连接工厂
ConnectionFactory factory = new ConnectionFactory();
//2.设置参数
factory.setHost("192.168.86.128");
factory.setPort(5672);//默认值
factory.setVirtualHost("/rabbitmq-test");//虚拟机
factory.setUsername("guest");//默认guest
factory.setPassword("guest");//默认guest
//3.创建连接Connection
Connection connection = factory.newConnection();
//4.创建channel
Channel channel = connection.createChannel();
//5.创建Queue
/**
 * queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map<String, Object> arguments)
 * queue：队列名称
 * durable：是否需要持久化，当mq重启之后，是否需要还存在
 * exclusive：表示是否独占，即只有一个消费者监听该队列，当Connection关闭时，是否删除队列
 * autoDelete：是否自动删除，但没有Consumer时会自动删除
 * arguments：参数
 */
//若没有hello队列则会创建该队列
channel.queueDeclare("hello", true, false, false, null);
/**
 * basicConsume(String queue, boolean autoAck, Consumer callback)
 * queue：队列名称
 * autoAck:是否自动确认收到
 * callback：回调对象
 */
//6.接收消息
Consumer consumer=new DefaultConsumer(channel){
    /**
     * 回调方法，当收到消息后，会自动执行该方法
     * @param consumerTag 标识
     * @param envelope 获取一些信息，交换机，路由key。。。
     * @param properties 配置信息
     * @param body 真实的数据
     * @throws IOException
     */
    @Override
    public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
        System.out.println(new String(body));
    }
};
channel.basicConsume("hello",true,consumer);
//消费者不要关闭资源,消费者需要一直监听消息
```

### 7.工作模式

* **单队列模式**：所有消息放在一个队列中

* **工作队列**：在一个队列中多个消费者竞争消费消息，一个消息只存在一个消费者成功消费，因此可以提高任务处理速度。

![image-20230420210900999](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420210900999.png)

```java
//生产者创建消息放入工作队列中
channel.queueDeclare("work_queues", true, false, false, null);
for (int i = 0; i < 10; i++) {
    String body = i+":hello rabbitmq~~";
    channel.basicPublish("","work_queues",null,body.getBytes());
}

//消费者消费工作队列中消息
channel.basicConsume("work_queues",true,consumer);
```



* **发布订阅（Pub/Sub）模式**（fanout）：通过设置交换机来将消息发送到不同队列中，每个消费者监听自己的队列，都可以消费自己队列里面的消息。其中交换机分发消息的方式有四种
  * direct：定向
  * fanout：广播，发送消息到每一个与之绑定的队列
  * topic：通配符的方式
  * headers：参数匹配

![image-20230420211628301](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420211628301.png)

```java
/**
 * exchangeDeclare(String exchange, BuiltinExchangeType type, boolean durable, boolean autoDelete, boolean internal, Map<String, Object> arguments)
 * exchange:交换机名称
 * type:交换机类型
 *     DIRECT("direct"),：定向
 *     FANOUT("fanout"),：广播，发送消息到每一个与之绑定的队列
 *     TOPIC("topic"),：通配符的方式
 *     HEADERS("headers");参数匹配
 *
 * durable：是否持久化
 * autoDelete：自动删除
 * internal：是否为内部使用
 * arguments：参数
 */
//5.创建交换机
String exchangeName = "test_fanout";
channel.exchangeDeclare(exchangeName, BuiltinExchangeType.FANOUT,true,false,false,null);
//6.创建队列
String queue1 = "test_fanout_queue1";
String queue2 = "test_fanout_queue2";
channel.queueDeclare(queue1,true,false,false,null);
channel.queueDeclare(queue2,true,false,false,null);
//7.绑定队列和交换机
/**
 * queueBind(String queue, String exchange, String routingKey)
 * queue:队列名称
 * exchange：交换机名称
 * routingKey：路由键，绑定规则
 *
 */
channel.queueBind(queue1,exchangeName,"");
channel.queueBind(queue2,exchangeName,"");
```



* **路由模式**（Direct）：在绑定交换机与队列时，需要指定RoutingKey，消息会转发到符合RoutingKey的队列

![image-20230420220657835](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230420220657835.png)

```java
//不同队列绑定不同RoutingKey
channel.queueBind(queue1,exchangeName,"error");

channel.queueBind(queue2,exchangeName,"info");
channel.queueBind(queue2,exchangeName,"error");
channel.queueBind(queue2,exchangeName,"warning");
channel.basicPublish(exchangeName,"info",null,body.getBytes());//将会发送到队列2
```

* **通配符模式**：在配置RoutingKey时使用通配符

  ![image-20230421100925425](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230421100925425.png)

```java
channel.exchangeDeclare(exchangeName, BuiltinExchangeType.TOPIC,true,false,false,null);//Topic标识统配符模式
channel.queueBind(queue1,exchangeName,"#.error");

channel.queueBind(queue1,exchangeName,"order.*");
channel.queueBind(queue2,exchangeName,"*.*");
```

### 8.SpringBoot整合RabbitMQ

```java
//生产者定义配置类来配置Exchange、Queue、Binding
@Configuration
public class RabbitMQConfig {
    public static final String EXCHANGE_NAME = "boot_topic_exchange";
    public static final String QUEUE_NAME = "boot_queue";

    //1.交换机
    @Bean("bootExchange")
    public Exchange bootExchange(){
        return ExchangeBuilder.topicExchange(EXCHANGE_NAME).durable(true).build();
    }

    //2.队列
    @Bean("bootQueue")
    public Queue bootQueue(){
        return QueueBuilder.durable(QUEUE_NAME).build();
    }

    //3.队列和交换机绑定
    @Bean
    public Binding bindQueueExchange(@Qualifier("bootQueue") Queue queue,@Qualifier("bootExchange") Exchange exchange){
        return BindingBuilder.bind(queue).to(exchange).with("boot.#").noargs();
    }
}

//生产者生产一条消息
rabbitTemplate.convertAndSend(RabbitMQConfig.EXCHANGE_NAME,"boot.hh","hello world!");

//消费者监听某个队列
@Component
public class RabbitMQListener {
    @RabbitListener(queues = "boot_queue")
    public void ListenerQueue(Message message){
        System.out.println(message.getBody());
    }
}
```

### 9.消息的可靠性投递（保证可靠）

* 消息的可靠性投递是为了确保信息能成功从生产端放入队列中，因此**在数据从生产者流向交换机的过程中可以使用confirm回调函数来判断数据是否成功流向交换机**，同时**在数据从交换机流向队列的过程中使用return回调函数来判断是否成功投递到队列中**。

```java
/**
 * 确认模式：
 *      1.开启确认模式：spring.rabbitmq.publisher-confirms: true
 *      2.在rabbitTemplate定义ConfirmCallBack回调函数
 */
@Test
public void testSend(){
    //定义回调
    rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
        /**
         * @param correlationData 相关配置信息
         * @param ack exchange是否成功收到消息。
         * @param cause 失败的原因
         */
        @Override
        public void confirm(CorrelationData correlationData, boolean ack, String cause) {
            System.out.println("执行回调函数");
        }
    });
    rabbitTemplate.convertAndSend(RabbitMQConfig.EXCHANGE_NAME,"confirm","message confirm!");
}


/**
 * 回退模式：Exchange路由到Queue时，失败才会执行ReturnCallBack
 *      1.开启回退模式  publisher-returns: true
 *      2.设置ReturnCallBack
 *      3.设置Exchange处理消息的模式：rabbitTemplate.setMandatory(true);
 *          1.如果消息没有路由到Queue，则丢弃消息(默认)
 *          2.如果消息没有路由到Queue，返回消息给发送方
 */
@Test
public void testReturn(){
    //设置交换机处理失败消息的模式
    rabbitTemplate.setMandatory(true);
    //定义回调
    rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {
        @Override
        public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) {
            System.out.println("执行return");
        }
    });
    rabbitTemplate.convertAndSend(RabbitMQConfig.EXCHANGE_NAME,"confirm11","message confirm!");
}
```

### 10.消费者接收到消息后的确认方式（保证可靠）

```java
@Component
public class AckListener implements ChannelAwareMessageListener {
    /**
     * Consumer ACK机制：
     *  1.设置签收模式签收：    listener.direct.acknowledge-mode: none(自动确认)manual(手动确认)
     *  2.让监听器实现ChannelAwareMessageListener
     */
    @Override
    @RabbitListener(queues = "test_queue_confirm")
    public void onMessage(Message message, Channel channel) throws Exception {
        long deliveryTag = message.getMessageProperties().getDeliveryTag();
        try {
            //1.接收转换消息
            System.out.println(new String(message.getBody()));
            //2.处理业务逻辑
            System.out.println("处理业务逻辑。。。");
            //3.手动签收
//            int i=3/0;//出现错误
            Thread.sleep(1000);
            channel.basicAck(deliveryTag,true);
        } catch (Exception e) {
            //4.出现异常，拒绝签收
            /**
             *  basicNack(long deliveryTag, boolean multiple, boolean requeue)
             *  requeue:消息重回队列，如果为true消息重新回到queue中，broker会重新发送消息给消费端
             */
            channel.basicNack(deliveryTag,true,true);
        }
    }
}
```

### 11.消费端限流

* prefetch表示消费端每次从mq拉取多少条消息来消费，直到手动确认消费完毕后，才会继续拉下一条

```java
/**
 * Consumer 限流机制
 *  1.确保ACK机制为手动确认
 *  2.配置属性：listener.direct.prefetch: 1 表示消费端每次从mq拉取一条消息来消费，直到手动确认消费完毕后，才会继续拉下一条。
 */
@Component
public class QosListener implements ChannelAwareMessageListener {
    @Override
    @RabbitListener(queues = "test_queue_confirm")
    public void onMessage(Message message, Channel channel) throws Exception {
        long deliveryTag = message.getMessageProperties().getDeliveryTag();
        try {
            //1.接收转换消息
            System.out.println(new String(message.getBody()));
            //2.处理业务逻辑
            System.out.println("处理业务逻辑。。。");
            //3.手动签收
            channel.basicAck(deliveryTag,true);
        } catch (Exception e) {
            //4.拒绝签收
            channel.basicNack(deliveryTag,true,true);
        }
    }
}
```

### 12.TTL（Time To Live）存活时间

* RabbitMQ可以对消息设置过期时间，也可以对整个队列设置过期时间，当消息达到存活时间后，还没有被消费，会被自动清除。

![image-20230421163618804](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230421163618804.png)



### 13.死信队列DLX（Dead Letter Exchange）死信交换机

* 消息成为死信的情况：
  * 当队列消息数达到限制时，新加入的消息将成为死信
  * 消费者使用basicNack或basicReject拒接消费消息，并且requeue设置为false，表示不把消息重新放回原目标队列
  * 队列中消息到达存活时间后未被消费

![image-20230421165227642](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230421165227642.png)



### 14.延迟队列（TTL+死信队列DLX）

* 在买车票时，30分钟未支付的话就需要取消订单，回滚库存。那么可以 开启一个定时器，隔一段时间查一下数据库中的订单记录，将订单记录的时间与当前时间做比对，这种方法存在两个问题，第一个是取消订单的时间存在误差，可能是29分钟也可能是31分钟，第二个是定时器的定时时间很难设定，设置太大误差就会很大，太小的话频繁查库会让数据库压力过大。**因此可以选择延迟队列来做，消息进入队列后不会立即被消费，只有到达指定时间后才会被消费**。但是RabbitMQ不直接提供延迟队列功能，因此可以选用**TTL+死信队列**来实现。当消息在正常队列中存货时间到达TTL后，该消息将成为死信进入死信队列被其他消费者消费。

```java
//生产者
// 1. 定义交换机
@Bean("DlxExchangeNormal")
public Exchange dlxExchangeNormal(){
    return ExchangeBuilder.topicExchange(DLX_EXCHANGE_NORMAL).durable(true).build();
}
@Bean("DlxExchange")
public Exchange dlxExchange(){
    return ExchangeBuilder.topicExchange(DLX_EXCHANGE).durable(true).build();
}
// 2. 定义队列
@Bean("DlxQueue")
public Queue dlxQueue(){
    return QueueBuilder.durable(DLX_QUEUE).build();
}
@Bean("DlxQueueNormal")
public Queue dlxQueueNormal(){
    // 正常队列需要绑定死信交换机
    Map<String, Object> arguments = new HashMap<>();
    arguments.put("x-dead-letter-exchange",DLX_EXCHANGE);  // 设置队列绑定的死信交换机名称
    arguments.put("x-dead-letter-routing-key","dlx.test"); // 设置队列与死信交换机的路由
    arguments.put("x-message-ttl",10000);  // 设置队列过期时间
    return QueueBuilder.durable(DLX_QUEUE_NORMAL).withArguments(arguments).build();
}
// 3. 绑定交换机与队列
@Bean
public Binding dlxBindQueueNormalAndExchange(@Qualifier("DlxQueueNormal") Queue dlxQueueNormal,@Qualifier("DlxExchangeNormal") Exchange dlxExchangeNormal){
    return BindingBuilder.bind(dlxQueueNormal).to(dlxExchangeNormal).with("dlx.normal.#").noargs();
}
@Bean
public Binding dlxBindQueueAndExchange(@Qualifier("DlxQueue") Queue dlxQueue,@Qualifier("DlxExchange") Exchange dlxExchange){
    return BindingBuilder.bind(dlxQueue).to(dlxExchange).with("dlx.#").noargs();
}

//消费者监听死信队列
@Component
public class DLXListener implements ChannelAwareMessageListener {
    @Override
    @RabbitListener(queues = "springboot_dlx_queue")
    public void onMessage(Message message, Channel channel) throws Exception {
        long deliveryTag = message.getMessageProperties().getDeliveryTag();
        try {
            System.out.println(new String(message.getBody()));
            System.out.println("逻辑业务处理完成...");
            int i = 3/0; //出错
            channel.basicAck(deliveryTag,true);
        }catch (Exception e){
            System.out.println("it is dlx message!");
            channel.basicNack(deliveryTag,true,false);
        }
    }
}

//生产一条消息 
rabbitTemplate.convertAndSend(RabbitMQConfig.DLX_EXCHANGE_NORMAL,"dlx.normal.TEST","dlx !");
```



### 15.消息可靠性保障--消息补偿

![image-20230422144514808](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230422144514808.png)



### 16.消息幂等性保障

* 消费多条相同消息与一条相同消息产生的结果相同。

![image-20230422152205930](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230422152205930.png)

## Kafka



# 场景题

## 1.大文件上传

## 2.微服务如何部署

## 3.高并发如何解决

## 4.项目性能优化（访问慢，CPU占用高都可扯到自己项目上）

* 可以使用Jmeter进行一个压力测试，一般是针对不同接口进行测，比如说我现在要测试某个接口，可以在Jmeter里面设置10w个HTTP请求，100个线程同时访问，此时就可以观察汇总报告信息，比如异常占比、接收发送字节速度还有吞吐量等性能相关信息。像如果出现异常较多可以通过查看结果树观察异常是什么，分析异常产生原因，是应用程序接口写的有问题还是其他原因。当汇总报告信息中还有其它不符合预期的话就要开始考虑问题是出自数据库、应用程序、中间件、网络还是说操作系统等。同时还应该分析该应用是CPU密集型还是IO密集型，如果在实际应用中出现CPU飙升但磁盘占用不高的情况，那么可以通过升级CPU、增加CPU数量，增加服务器进行并行处理来解决。但如果是磁盘占用较高，磁盘疯狂在进行读写，内存被挤爆了，吞吐量非常低等情况，除了可以通过加内存条、使用缓存技术来提高读写读写效率外，还应该监控JVM来观察堆内存使用情况，使用jvisualvm来监控对应进程，可以监控到该进程中线程运行状态是运行态还是阻塞态等等，以及会监控线程池运行情况。还可以看到垃圾回收实时情况，从而综上来分析性能丢失是出现在中间件信息阶段还是业务代码处理阶段还是数据库频繁读取等的问题，然后再分析是逻辑代码写的有问题时间复杂度太高还是数据库查询太慢，需要sql慢查询优化，还是说对于频繁访问的数据是否需要做缓存来解决等，定位到真正出问题的地方再去解决就不是问题了。



## 5.CPU占用很高

## 6.磁盘占用很高



## 7.系统设计题

* **先问清楚系统具体要求并转述一遍**
* **对系统进行抽象设计**,设计出基本雏形然后再优化
* **再考虑是否有需要优化的**，服务是否需要负载均衡到多台机器？是否需要缓存？数据库是否需要进行分库分表？
* **再考虑针对不同优化点如何更好设计**
* 

* 性能相关指标
  * **响应时间RT**就是用户发送请求到用户收到系统处理结果所需要的时间
  * **并发数** 服务可以供多少人访问使用
  * **QPS** 服务器每秒可以执行的查询次数
    * Nginx：30w+
    * Redis：8w+
    * MySQL：4k+
    * Tomcat：2w+
  * **TPS** 服务器每秒处理的事务数
  * **PV** 页面浏览量或点击量
  * **UV** 独立用户访问量
* 性能测试工具Jmeter
* 系统设计原则：合适优于先进>演化优于一步到位>简单优于复杂

## 8.秒杀系统（⭐）

* **高并发、高性能、高可用、一致性**
* **高并发**简单来说就是能够同时处理很多用户请求。**高性能**简单来说就是处理用户的请求速度要快。**高可用**简单来说就是我们的系统要在趋近 100% 的时间内都能正确提供服务。**一致性**就是对于大量订单不能超卖
* 秒杀肯定存在访问热点数据，热点数据又分为静态热点数据、动态热点数据
  * 对于**静态热点数据**而言可以提前知道的热点数据比如秒杀商品
  * 对于**动态热点数据**而言无法提前知道该数据是不是热点数据比如疫情期间屯什么药，然后大批量用户访问购物网站买药导致redis缓存扛不住百万并发从而某些节点瘫痪，同时web应用一般是强关联缓存的，部分节点崩了可能导致整个集群崩了，整个web服务都受影响。
* **如何定位热点数据？**
  * 可以使用一些中间件，如京东零售的hotkey中间件来专门检测热点数据，它可以毫秒级探测热点数据，毫秒级推送至服务器集群内存
* **如何处理热点数据？**
  * 热点数据一定要放在缓存中，并且最好可以写入到 jvm 内存一份（多级缓存），并设置个过期时间。需要注意写入到 jvm 的热点数据不宜过多，避免内存占用过大或OOM，一定要设置到淘汰策略。放入jvm内存的原因是jvm访问速度快不存在网络开销，并且能抗住百万qps
* **如何处理静态资源？**
  * 系统的静态资源如商品图片、CSS、JS等资源不需要每次服务请求时再去检索服务端资源返回给客户端渲染，可以将静态资源分发到多个不同的地方以实现就近访问，减轻服务器带宽负担。可以使用一些云服务器来存，我自己做项目是使用nginx来存的。
* **是否需要部署集群？**
  * 单点部署存在很多问题，如所有请求转发到同一个机器上导致并发能力不高，容错率低，一旦服务器故障，整个项目无法运行，并且计算能力低
  * 集群部署的话可以通过**负载均衡**将服务均衡分担到不同服务器上处理，同时可用性更高，并且可以使用哨兵（sentinel）来监控运行节点，当master故障时哨兵可以全自动进行故障转移。
* **是否需要限流？**
  * 当请求数太多时超过了服务器承载能力时可以使用限流技术将超过承载部分的请求拦截住，即接口限流，限流可以直接使用redis做（最好是Lua脚本），也可以使用Sentinel等流量控制组件
  * 同时还可以对同一用户、同一ip进行限流。也可以通过验证码，提前预约等方式进行限流
* 是否需要进行**流量削峰**？
  * 当请求过多时，可以将这些请求放在消息队列，然后服务端慢慢处理
* 是否需要**降级**？
  * 当请求量过大时，可以通过设置阈值来对系统非核心功能进行关闭或者将它们功能降低，从而可以将更多资源让给秒杀系统等主要功能

* 是否要进行**熔断**？
  * ​	当系统依赖的外部系统或第三方系统发生故障或访问很慢时采用熔断的方式让服务不再访问这些功能，从而避免服务被拖慢或拖死。
* 如何保证**一致性**？
  * 减库存方案，有两种一种是下单立马减少库存，即使不付款也减库存，但是需要设置一下下单到付款这个过程的过期时间，若过期未付则释放库存，也可以付款再减库存，但是可能付款失败。
* 是否要保证**接口幂等性**？
  * 当用户多次点击购买按钮的时候，如果不加处理后端将会接收到该用户多次相同的订单，结果一个人秒杀了多个商品，因此前端需要对这种情况做处理，后端同样需要做处理，比如使用Redission分布式锁，业务字段段唯一性等
* 使用**Jmeter**等工具进行性能测试

##  9.实现RPC框架

* 最基本的
* ![image-20230406110858529](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230406110858529.png)
* Dubbo
* ![image-20230406111152960](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230406111152960.png)
* 服务注册与发现可以使用ZooKeeper
* 网络传输，传统的是使用Socket，但是Socket是BIO，性能低且单一，可以使用Netty来处理网络传输，Netty是基于NIO的cilent-server框架，极大地简化了网络编程
* 数据传输过程中涉及到**序列化与反序列化**，即Java对象等数据无法在网络中传输，需要转成二进制才行，可以使用Kyro等序列化组件
* 负载均衡
  * 当系统中的某个服务的访问量特别大，可以将这个服务部署在了多台服务器上，当客户端发起请求的时候，多台服务器都可以处理这个请求。
* RPC传输协议如何设计？

## 10.JVM调优



## 11.TCP真的可靠吗？



# Linux

## 1.常用命令

```shell
## 目录切换
cd usr 	##切换到该目录下 usr 目录
cd ..   ##切换到上一层目录
cd / 	##切换到系统根目录
cd ~ 	##切换到用户主目录
cd - 	##切换到上一个操作所在目录

mkdir 目录名 ## 新建目录
touch 文件名 ##新建文件


ls##查看当前目录信息
ll ##查看当前目录下所有目录和文件的详细信息
cat 文件名称 ##查看文件信息
tail -f 文件名 ##配置nacos时，由于老出错所以通过该命令来动态监控nacos

find 目录 参数	  ##查看指定目录是否有指定参数的文件
find . 			##列出当前目录及子目录下所有文件和文件夹
find /home -name "*.txt" ##在/home目录下查找以.txt 结尾的文件名
find . -name "*.txt" -o -name "*.pdf"  ##当前目录及子目录下查找所有以.txt 和.pdf 结尾的文件

mv 原名称 新名称 ## 重命名，可以作用于目录与文件。
mv 名称 目录的新位置 ## 剪切，移动目录或文件到指定位置

cp -r 名称 目标位置 ## 拷贝目录或文件到指定位置，-r 代表递归拷贝

rm -rf 名称 ##删除目录或文件

vim 文件名 ## 进入该文件，可以通过i来进入编辑模式，需要退出时先按esc退出编辑模式，然后输入冒号wq来保存并退出

tar -zcvf 打包压缩后的文件名 要打包压缩一个或多个文件 # z是压缩，c是打包，v是显示运行过程，f是指定文件名
tar -xvf 压缩文件 -C 解压出的文件存放位置 # x是解压

pwd ##显示当前所在位置
sudo + 其他命令 ##以系统管理者的身份执行指令
grep 要搜索的字符串 要搜索的文件 --color ##去到某个文件中搜索指定字符串，并把搜索到的所有该字符串高亮表示出来，--color 代表高亮显示
ps -aux ## 查看当前系统正在运行进程
ps aux|grep redis ## 查看特定的进程
kill 进程的pid ##杀死进程 ，使用kill pid命令时系统会发送一个信号给对应程序，这个信号就是进程通信的一种方式，但程序收到时要么程序立即执行、要么释放相应的资源再停止，也有可能仍然继续执行。默认情况是-15，也可以通过-9强制终止该进程。一般先用-15再用-9

ifconfig ## 查看当前系统网卡信息，由于我很多mysql、nacos、redis等都通过docker部署在自己电脑的虚拟机上，因此连接的时候需要查看对应网卡的ip的地址来建立连接

ping ## 可以ping主机与虚拟机通信能不能ping通
netstat -an ## 查看当前系统的端口

reboot ## 重开机

# 登录命令
ssh -p 2222 root@172.26.36.188 xiaobao321@A
# 退出登录
exit

#克隆指定分支的代码
git clone --single-branch --branch feature/v1.0 http://172.26.6.172:9091/jianan/api.git

# 查询指定端口进程
netstat -nlp|grep 6030
# 查看日志
cat model_log.log
# kill进程
kill 182242
# 部署服务并生成日志
nohup python -u model_api.py > model_log.log 2>&1 &

#查看当前路径
pwd

conda create -n wust python=3.9 
```



## 2.Linux文件系统

* **在 Linux 操作系统中，所有被操作系统管理的资源，如网络接口卡、磁盘驱动器、打印机、输入输出设备、普通文件或是目录都被看作是一个文件**。一个文件若大于Linux系统一个块时将会被分成多块进行存储，同时使用**inode**来维护该文件相关信息，如被分成的几块、每一块在的地址、文件拥有者，创建时间，权限，大小等信息。（inode可以通过stat命令查看）



## 3.文件种类

* **普通文件（-）** ： 用于存储信息和数据， Linux 用户可以根据访问权限对图片、pdf等普通文件进行查看、更改和删除。
* **目录文件（d，directory file）** 是用于表示和管理系统中的文件，目录文件中包含一些文件名和子目录名。打开目录事实上就是打开目录文件。
* **符号链接文件（l，symbolic link）** ：保留了指向文件的地址而不是文件本身。
* **字符设备（c，char）** ：用来访问字符设备比如键盘。
* **设备文件（b，block）** ： 用来访问块设备比如硬盘、软盘。
* **管道文件(p,pipe)** : 一种特殊类型的文件，用于进程之间的通信。
* **套接字(s,socket)** ：用于进程间的网络通信，也可以用于本机之间的非网络通信

## 4.修改权限

* 使用chmod修改权限：chmod 777 指定目录或文件  （7=4+2+1，表示拥有rwx的权限）

![image-20230331105509399](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230331105509399.png)

![image-20230331110201447](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230331110201447.png)



## 5.用户管理

```shell
useradd 选项 用户名:添加用户账号
userdel 选项 用户名:删除用户帐号
usermod 选项 用户名:修改帐号
passwd 用户名:更改或创建用户的密码
passwd -S 用户名 :显示用户账号密码信息
passwd -d 用户名: 清除用户密码
groupadd 选项 用户组 :增加一个新的用户组
groupdel 用户组:要删除一个已有的用户组
groupmod 选项 用户组 : 修改用户组的属性
```



![image-20230401103744409](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230401103744409.png)

![image-20230401105831379](C:\Users\17822\AppData\Roaming\Typora\typora-user-images\image-20230401105831379.png)

# 数据结构

* length与size的用法
  * 字符串length() 
  * 数组length
  * 其他全部用size()

### 1.String

```java
String s="  hello world!";
int size = s.length();
String t = s.substring(size);//截取0~size-1
String t2 = s.substring(2,size);//截取2~size-1
String s1=s.trim();//去除首尾空格
String[] temp = s1.split(" ");//以空格划分，若存在多个空格则会划分出空字符串
```

### 2.StringBuilder

```java
StringBuilder sb = new StringBuilder();//有序
sb.append("a");//添加元素 
sb.deleteCharAt(sb.length()-1);//删除指定位置元素
System.out.println(sb.toString());
```

### 3.Deque

```java
Deque<Integer> queue = new ArrayDeque<>();
queue.add(1);//添加元素
```

![image-20230728142113587](e:\users\WuST02\AppData\Roaming\Typora\typora-user-images\image-20230728142113587.png)

![image-20230709084927304](E:\wust\GitCode\wust\Working\八股\img\image-20230709084927304.png)

![image-20230709084941393](E:\wust\GitCode\wust\Working\八股\img\image-20230709084941393.png)

### 4.PriorityQueue 优先级队列

* 默认小顶堆，元素单调递增排序

![image-20230801085021850](E:\wust\GitCode\wust\Working\八股\img\image-20230801085021850.png)

```java
// PriorityQueue默认小顶堆，在元素add进来时会调整堆结构、，使其变为小顶堆。该类也实现了Queue接口，因此在堆排序完成后，会层序遍历整个堆，将元素放入队列中。
PriorityQueue<Integer> menu = new PriorityQueue<>();//默认小顶堆
PriorityQueue<Integer> menu2 = new PriorityQueue<>((o1,o2)->o2-o1);//修改为大顶堆
menu.add(5);//添加元素
menu.contains(5);//判断是否包含指定元素
menu.isEmpty();//判断队列是否为空
menu.size();//获取队列中元素个数
menu.poll();//弹出优先级最高元素
menu.peek();//获取优先级最高元素
menu.remove(12);//根据value删除指定元素
```



### 5.与&、或|、异或^、取反~

```txt
与&：运算规则：0&0=0;  0&1=0;   1&0=0;    1&1=1;负数按补码形式参加按位与运算
3&5 
  0000 0011
& 0000 0101 
= 0000 0001  因此，3&5的值得1
取一个数中指定位
方法：找一个数，对应X要取的位，该数的对应位为1，其余位为零，此数与X进行“与运算”可以得到X中的指定位。
例：设X=10101110，
   取X的低4位，用 X & 0000 1111 = 00001110 即可得到；
   还可用来取X的2、4、6位


或|：运算规则：0|0=0；  0|1=1；  1|0=1；   1|1=1；负数按补码形式参加按位或运算
3|5　
  0000 0011 
| 0000 0101 
= 0000 0111  因此，3|5的值得7

异或^:运算规则：0^0=0；  0^1=1；  1^0=1；   1^1=0；
与0相异或，保留原值 ，1010 1110 ^ 00000000 = 1010 1110

取反运算符（~）
参加运算的一个数据，按二进制位进行“取反”运算
~1的值为1111111111111110
```

### 

## boolean默认赋值为false

# 算法

## 1.二叉树（不用在乎其他点，只用在乎当前节点）

* 遍历一遍二叉树能得出答案的用回溯算法

  ```java
  // 记录最大深度
  int res = 0;
  // 记录遍历到的节点的深度
  int depth = 0;
  
  // 主函数
  int maxDepth(TreeNode root) {
  	traverse(root);
  	return res;
  }
  
  // 二叉树遍历框架
  void traverse(TreeNode root) {
  	if (root == null) {
  		return;
  	}
  	// 前序位置,进入节点
  	depth++;
      if (root.left == null && root.right == null) {
          // 到达叶子节点，更新最大深度
  		res = Math.max(res, depth);
      }
  	traverse(root.left);
  	traverse(root.right);
  	// 后序位置，离开节点
  	depth--;
  }
  ```

  

* 通过分解问题计算出结果的使用动态规划

  ```java
  // 定义：输入根节点，返回这棵二叉树的最大深度
  int maxDepth(TreeNode root) {
  	if (root == null) {
  		return 0;
  	}
  	// 利用定义，计算左右子树的最大深度
  	int leftMax = maxDepth(root.left);
  	int rightMax = maxDepth(root.right);
  	// 整棵树的最大深度等于左右子树的最大深度取最大值，
      // 然后再加上根节点自己
  	int res = Math.max(leftMax, rightMax) + 1;
  
  	return res;
  }
  ```

  

## 2.动态规划

```java
//根据coins凑出amount
int coinChange(int[] coins, int amount) {
    int[] dp = new int[amount + 1];
    // 数组大小为 amount + 1，初始值也为 amount + 1
    Arrays.fill(dp, amount + 1);

    // base case
    dp[0] = 0;
    // 外层 for 循环在遍历所有状态的所有取值
    for (int i = 0; i < dp.length; i++) {
        // 内层 for 循环在求所有选择的最小值
        for (int coin : coins) {
            // 子问题无解，跳过
            if (i - coin < 0) {
                continue;
            }
            dp[i] = Math.min(dp[i], 1 + dp[i - coin]);
        }
    }
    return (dp[amount] == amount + 1) ? -1 : dp[amount];
}
```

## 3.二分查找

* 思想：依次比较数组中相邻两个元素大小，若前一个大于后一个，则交换两个元素，两两比较一遍称为一轮冒泡，结果是让最大的元素排至最后，重复以上步骤，直到整个数组有序
* 优化：每轮冒泡最后一次交换索引可以作为下一轮冒泡的比较次数，如果这个值为零，表示整个数组有序，直接退出外层循环即可

```java
private static int binarySearch(int[] array,int target) {
    int left=0,right=array.length-1;
    while(left<right){
        int mid = (left+right)>>>1;
        if (array[mid]<target) {
            left=mid+1;
        }else if(array[mid]>target){
            right=mid-1;
        }else{
            return mid;
        }
    }
    return -1;
}
```

## 4.排序算法（⭐）

* 稳定：排序后相同元素先后顺序还是不是原来的先后顺序

### 4.1冒泡排序

* 思想：从数组起始位置向后遍历，比较相邻的元素，如果前一个比后一个大，就交换他们，这样就完成了一次冒泡，然后重复上面步骤。同时有可能存在数组已经有序但仍然还会执行冒泡的过程，因此需要记住是否发生过交换，若没有就说明已经有序，结束冒泡。
* 时间复杂度：数组有序时为O(n)，其他情况为O(n^2^)
* 稳定性：稳定

```java
public void bubbleSort(int[] arr) {
    int temp = 0;
    boolean swap;
    for (int i = arr.length - 1; i > 0; i--) { // 每次需要排序的长度
        swap=false;
        for (int j = 0; j < i; j++) { // 从第一个元素到第i个元素
            if (arr[j] > arr[j + 1]) {
                temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
                swap=true;
            }
        }
        if (!swap){
            break;
        }
    }
}
```

### 4.2 选择排序

* 思想：从未排序序列中选择最小元素与第一个位置元素交换，然后第二个位置重复执行上述操作，直到所有元素均排序完毕
* 时间复杂度：数组有序时为O(n)，其他情况为O(n^2^)
* 稳定性：由于存在交换，所以如{2，2，1}就有可能使得元素相对位置改变，所以是稳定的

```java
public void selectionSort(int[] arr) {
    int temp, min = 0;
    for (int i = 0; i < arr.length - 1; i++) {
        min = i;
        // 循环查找最小值
        for (int j = i + 1; j < arr.length; j++) {
            if (arr[min] > arr[j]) {
                min = j;
            }
        }
        if (min != i) {
            temp = arr[i];
            arr[i] = arr[min];
            arr[min] = temp;
        }
    }
}
```

### 4.3插入排序

* 思想：从第二个元素开始将该元素插入前面已排好序的数组中，使得该子数组有序，插入的过程需要遍历子数组找到不大于指定元素的位置，重复以上过程
* 时间复杂度：数组有序时为O(n)，其他情况为O(n^2^)
* 稳定性：由于只需要找到不大于当前数的位置且并不需要交换，因此直接插入排序是稳定的

```java
public void insertionSort(int[] arr){
    for (int i=1; i<arr.length; ++i){
        int value = arr[i];
        int position=i;
        while (position>0 && arr[position-1]>value){
            arr[position] = arr[position-1];
            position--;
        }
        arr[position] = value;
    }//loop i
}
```

### 4.4快速排序

* 思想：选定pivot中心轴，将大于pivot的放在pivot右边，将小于pivot的放在左边，然后分表对左右子序列重复上述操作。（可以看作二叉树的前序遍历）
* 时间复杂度：O（nlogn）
* 稳定性：不稳定

```java
void QuickSort(int[] arr, int L, int R)
{
	//只有一个数或区间不存在
	if (L >= R)
		return;
	int left = L;
	int right = R;
	//选左边为key
	int pivot = arr[left];
	while (left < right)
	{
		//右边选小   等号防止和key值相等    防止顺序begin和end越界
		while (left<right && arr[right] >= pivot)
		{
			right--;
		}
        if(left<right){
            arr[left]=arr[right];
        }
		//左边选大
		while (left<right && arr[left] <= pivot)
		{
			left++;
		}
        if(left<right){
            arr[right]=arr[left];
        }
		if(left>=right){
            arr[left]=pivot;
        }
	}
	QuickSort(arr, L, right - 1);
	QuickSort(arr,right + 1,R);
}

```

## 5.单调栈

* 用于解决NGE（Next Greater Element）问题的，即找到下一个比自己大的元素

* 重点在于是单调递增还是单调递减的栈

# 实习项目经历

## 解决的问题

### 1.模型跑不起来

* 通过debug排查从前端传数据到模型这整个链路过程，来定位问题所在
  * 针对直流内阻模型切换至循环寿命，排查出前端出现数据不一致问题，即传给后端的数据并不是预期的模型参数信息。总结：问题出现在前端，修改前端数据赋值过程。
  * 流程第一步前端就出现问题，因此选择postman手动修改接口传入参数至预期来debug后续流程
  * 针对数据流进入后端这部分，通过debug发现数据校验并未通过，其中部分属性值为数值型数据但数据库标注数据属性为字符串，导致数据校验不通过。总结：问题出现在数据整理人员，修改对应指导手册数据及通知数据库维护人员修改数据即可
  * 针对后端通过web方式调python模型这部分，通过debug Python模型发现后端传过来的数据类型及顺序与模型的并不匹配。总结：针对数据顺序不一致问题，通过debug发现，加载模型后，模型有个属性feature_names_in属性，因此可以通过该属性来重新排序后端传过来的数据；针对数据类型不一致，排查出后端传入参数与模型输入参数有三个不一致，问题出现在模型训练人员并未完全按照开发文档开发，通过与mentor沟通，选择修改数据库中数据属性来匹配模型输入。
  * 以上全部解决，debug显示接口参数请求正常。

### 2.部署模型遇到的各种问题

* 部署模型到指定服务器一脸懵，思考流程：
  * py模型应该会部署到一个服务器上，然后后端访问的模型路径应该指定到这个服务器对应服务端口上
  * 然后前端界面访问的url指定后端接口，因此链路就是前端-后端-模型
  * 前端的部署已经由前端人员部署完成，后端服务已经上传至git，我没有权限部署，通知mentor使用DevOps部署下我的git代码，好，后端已经部署，那么模型所放的服务器IP是多少捏，询问后知道了，ok，通过ssh命令连接上服务器，创建文件夹，拉取代码，完了，拉取的代码并不是我上传的最新代码，咋办，对了，这个不是我上传的分支代码是master代码，百度搜怎么拉分支代码呗，ok，拉取成功，查看指定端口是否被占用，杀死原来进程，重新挂载我的代码，查看日志，挂载失败，代码报错，什么？？？加载的包不存在，ok，反正这个包也没啥主要作用，注释掉相应代码就行，ok，没有报错，打开网页测试功能，模型一功能测试通过，模型二测试未通过，查看日志，什么，读取模型成功，调用模型的方法显示方法不存在，为啥本地代码测试都通过捏，并且模型一与模型二的接口代码相同，唯一不同的是模型，模型。。。，难道说模型由不同人编写，环境不一样导致的，之前测试模型二时就显示过scikit-learn包的版本需要使用1.2.2，模型一没有显示。那么猜测是由模型开发人员环境不一致引起的，那么我要怎么解决捏，服务器上不太敢自己创建个conda环境来部署，哦对了查看下有哪些conda环境，原来给我模型的两个大佬在这个服务器上都有各自的环境呀，来测测他们的环境，ok，测出来了，一个人的环境缺包，且部分包的环境过低，但是另外一个人的环境可以。ok，切换conda环境，挂载服务，测试接口，okok，全通关
  * 由于没有一个部署手册指示我快速完成部署，因此开发完后编写了python模型部署手册供后续开发人员使用，其中添加了部署时遇到的各种问题，以及相关的命令

### 3.为什么不用@RequestBody

* **@RequestPart("file") MultipartFile file,SdeBarcodeData barcodeData**
* 在实现文件上传功能中，需要传入文件流以及相应的参数然后进行拼装存入数据，其中传进来的数据流采用MultipartFile来接收，注解@RequestPart会将请求content-type转换为form-data,此时传进来的其他参数无需加注解，若给参数加上@RequestBody则会报错。原因是@RequestBody是的Content-type是json的因此会产生冲突。

### 4.真就CRUD？

* 在预测模型部署完成后接到mentor分配的新任务-两个界面所有接口的设计，在开发初期以为只是简单地crud，但是随着开发的进行发现前面写的接口有很多情况并未考虑。
* 比如批量删除功能：由于该表的数据比较珍贵，因此不能使用直接删除的方法，应该改为**软删**，即通过状态位来表示该数据被删除，但数据库中仍然存在，同时该表还会关联其他表，因此删除该表的同时需要去到其他表中软删掉相应的数据。
* 比如Hzero框架中封装的PageHelper.doPageAndSort方法不能在sql中添加orderby来排序，需要在pageRequest中指定对应的排序字段。同时针对模糊查询而言，当模糊查询字段为空时并不会检索出所有数据，因此选择采用Hzero中的andLikeLeft方法即该方法会在对应字段不为空的情况下在左边加%，同时对模糊查询字段右边添加%来保证传入字符串不可能为空，使得能查询出所有数据。
* 比如按要求生成指定编号时，**如何保证同一个用户当天新增编号从1开始自增，且该编号在同一用户范围内唯一**。我采用的方式是redis中的increment方法来实现自增的效果，即根据key去redis中加减value，因此对于key的封装使用用户编号加上特殊符号加上当天时间作为key，然后实现自增的效果。其中increment方法的效果是若有则value加一，若没有则创建。从而实现了自增的效果。但是存在一个问题是若用户点击新增后并未提交自己的这些记录，然后点取消了，虽然数据库并未写入这条数据，但是redis中修改了这条记录，因此还需要写对应的取消接口，来保证编号的唯一性。**取消接口**采用delete方法，若redis中有该key且value为1时则删除该key-value，若value不为1时则value减一。
* 比如某个表的信息生成，如何才能保证用户来回点不会生成过多空白记录，此时的解决方案就是在数据库中新增加一个字段来表示该条信息的状态，若用户完整地操作完整个工艺，那么此时会刷新数据库中该条记录的信息状态，表示该工艺已经分析完成且报表生成成功。从而在新建时就根据该状态来判断该类工艺是否需要新建，若之前有操作过的记录且为完整操作整个工艺就不新建。从而保证了数据的有效性。

### 5.@Transactional不能同时作用于MySQL与PostgreSQL



### 6.断言与异常处理的关系

* 断言产生的是一个断言错误（AssertError），当断言作用与try中时，该错误不会被try-catch中的catch捕获。同时try-catch-finally中的finally还是会执行的



### 7.summaryDetail相关细节

* 针对**创建接口**，由于用户点击清单明细不同跳转按钮时都会生成一条历史记录，记录当前用户执行了那些操作。因此存在用户并未按照完整流程点击下去，生成一系列报表看，因此需要管控当前用户生成记录的操作。采用的方式是数据库对应表格新增一个字段-**流程状态**，当用户点击跳转时新增一条记录写入数据库且其流程状态改为**创建0**，当在其他界面进行数据分析时，流程状态被更新为**分析中1**并记录相关数据，当整个流程走完，用户点击保存，将会生成对应的报表及相关数据分析预测结果，此时流程状态被改为而**分析完成2**。同时在清单明细界面还有关闭和编辑按钮，当用户认为某条历史记录操作完成不需要再编辑时，点击关闭按钮，流程状态改为**关闭3**。只有当前流程号summaryNo与用户点击的不同分析界面dataType下**最新那条记录的流程状态**为分析完成或关闭时才能新增，从而成功实现**防重效果**。
* 针对**获取最新package接口**，该接口目的是保证工程师在上一个分析界面分析了某些packageInfo，同时在下一个界面也想分析它们。该接口的设计不难，难的是由于有几个设计界面是集成自其他部门人员编写，因此存在跨平台的问题。第一个解决方案是将该接口注册到eurake上，调用方通过openFeign的方式调用该接口就行，但出于不同部门存在权限限制与服务上线不同步等问题，因此并未采用该方案。第二种方案是将服务注册到IPaaS，通过代理的方式访问该接口，调用方只需要知道被调用部门的授权码就行。**设计界面只需要访问IPaaS上的代理地址**，就可以将对应packageInfo持久化到我们这边的数据库，当用户跳转到其他界面时就可以访问数据库获取上一次的packageInfo。由于没有一个完整的指导手册指示我快速完成接口注册，因此开发完后编写了**IPaaS联调手册**，供项目组后续开发人员使用
* 针对**导出接口**，该接口的功能是用户选择多个不同的报表分析类型来进行数据导出，导出的数据需要合并至一个pdf，同时不同分析类型的pdf文件保存在Minio上，因此该接口存在数据拉取与数据合并的操作。首先通过前端传入字段进行对应分析类型的pdf文件名检索，然后通过MinioClient来获取对应文件即可。由于考虑到多个地方需要用到MinioClient来建立客户端连接，因此首先编写配置类，作用是通过@Bean注解生成单例MinioClient连接对象，将其交给IOC容器管理，在不同地方使用时只需要使用@Autowired注解进行自动注入即可，从而避免了用户在不同地方都手动创建客户端连接的操作，同时避免了一个后台服务建立多个客户端连接，浪费资源的情况。通过遍历获取到文件之后，选择itextpdf包下的工具类PdfCopy来进行pdf文件合并，同时将数据流写入response中返回给前端。**其中导出设计界面的分析结果**，存在跨平台的问题，同样将设计界面需要被我们这边调用的接口代理到IPaaS平台。此时存在一个问题是**为什么不让设计界面将分析结果生成文件通过MinioClient保存到Minio上，我们这样就直接去Minio上拿数据就行？**原因：1.我们这边是集成别人的服务，当后续需要迭代升级时，需要修改文件导出格式或者其他问题时，有需要找到对应负责人修改他们的后端，这样会导致交互成本过高；2.在他们界面做数据上传可能影响到他们业务流程性能；3.由于设计界面相关数据的变动特别大，是采用定时任务拉取其他库的最新数据，若采用Minio来持久化分析结果的话，可能存在数据库数据与pdf文件数据不一致等问题；4。由于设计界面相关数据库的保密性，我们这边也不能直接进行crud。因此选择我们这边主动调用他们的接口来实时获取最新数据，我们这边来负责数据拼装。

### 8.公共接口相关细节

* 针对**文件上传接口**，该接口功能是将用户上传的文件流及相关其他信息进行不同逻辑组装，插入到不同表中。**难点一**：文件流和实体类同时作为入参，注解该怎么使用？最终发现使用@**RequestPart**作为注解可以接受文件流和实体类，@RequestBody不行，会出现文件流格式不对等问题，前端出入实体类时，需要指定其contentType为application/json，否则会报流异常等问题。**难点二**：该接口存在查**PostgreSQL**数据库以及往MySQL中不同表插入数据的操作，那么如何利用事务保证数据安全性？实际上针对查postgreSQL数据库而言，会将每一条sql语句当作一个事务来处理，而@Transactional注解是专门作用于MySQL的，因此可以将涉及到MySQL数据库的操作放在一个方法中加上注解即可。**难点三**：对上传的文件进行合法性校验，由于合法性校验会遍历整个文件流中，同时文件中数据较多，因此采用多线程的方式进行并行校验，每5000条数据分配一个线程，最终阻塞式获取遍历后的结果，该遍历会将哪一个数据出现什么错误存入**StringBuffer**中，当StringBuffer为空时，可以继续后续流程，否则直接通过断言结束该请求，并抛出**AssertError**，前端显示该错误

## 学习到的新技术

### swagger

* Swagger就是一个用来定义接口标准，接口规范，同时能根据你的代码自动生成接口说明文档的一个工具
* 使用相关注解，如@Api、@ApiOperation等进行类与方法等的提示，前端人员可以通过Swagger平台查看接口相关参数等信息
* @ApiModel(name)：对实体类进行分组，若name相同则会出现不同实体类出现swagger显示入参相同，该bug会严重影响前端接口入参设计

### Jenkins

* 教程：https://blog.csdn.net/zhishidi/article/details/118082509

### redis

* 针对需求Summary编号是依据同一天内同一租户Id开始从0001开始自增，为什么要使用redis的List数据结构？

### Minio

### IPAAS

https://www.restcloud.cn/restcloud/mycms/index.html

* 通过统一集成平台，建设基于API的开放能力中心，基于API进行快速构建组合式应用，提高IT交付效率。
* iPaaS平台提供企业异构系统间的多种集成手段，合理规划iPaaS平台中实现的系统间的集成需求，有利于保障iPaaS平台的容纳能力、可扩展能力，并提高iPaaS平台的稳定性及运维质量。
* 是否需要接入iPaaS平台，主要从以下三个方面综合考虑：
  * 属于跨系统之间数据集成与共享：基础数据、业务数据；
  * 考虑集成的实时性&数据量要求，实时性要求越高，单次交易数据量越少，则适合接入iPaaS平台；反之，单次交易数据量大且实时性要求不高，则建议可以通过大数据平台或ETL工具从数据层面进行集成；
  * 对于大数据平台采集其它系统的数据，这部分由大数据平台自身系统提供的ETL工具实现；
* 系统调用方接入平台规范：
  * 调用方系统访问IPaaS平台服务，内网调用接口时必须**加上安全认证**
  * 处理集成发出的请求时间不能超过3分钟，超过3分钟可以采用异步来处理请求

## Stream流操作

* filter：返回一个Boolearn类型的值，true为保留，false为舍弃

```java
//获取list中元素名字为张三的对象，输出其名字
list.stream().filter(e->StringUtils.equals("张三",e.getName()))
    .forEach(e->System.out.println(e.getName()));
```

* map：收集元素中指定属性

```java
//打印list中所有元素的属性名
list.stream().map(e->{
    return e.getName();
}).forEach(name->System.out.println(name));
```

* flatMap：将一个流中的每一个元素转换成一个新的流，然后将这些流合并成一个流。这样做的好处是可以对每一个元素进行独立的操作，并且可以减少冗余的数据

```java
Stream.of(Arrays.asList(1, 2), Arrays.asList(3, 4), Arrays.asList(5,6)).flatMap(Collection::stream).forEach(System.out::println);
```

* Stream.of(a,b,...)：返回由元素a,b,...组成的有限流
* limit(n)：用于限制流中元素的个数，即取前n个元素，若n大于流中数据总量，则取出其中所有元素，若n小于0则抛异常，等于0则返回空流

```java
// 打印数组中前3个元素
Stream.of(1,2,3,4,5).limit(3).forEach(System.out::println);
```

* skip(n)：跳过前面n个元素，然后返回新流

```java
// 打印数组中前3个元素
Stream.of(1,2,3,4,5).skip(3).forEach(System.out::println);
```

* distinct：去重

* sorted：排序

```java
// 按照元素薪水降序排列
list.stream().sorted((e1,e2)->
(int)(e2.getSalary()-e1.getSalary())).forEach(System.out::println);
```

* peek：在流上完成自己的操作之后，将操作顺承到流水线的下一个操作，即将中间变量输出，适用于debug

```java
List<Integer> collect = list.stream()
    .peek(x -> System.out.println("原始x:" + x))
    .map(x -> x + 2)
    .peek(x -> System.out.println("加2后的x:" + x))
    .collect(Collectors.toList());
```

* groupingBy：对数据进行分组，规则在groupingBy中书写，最后输出的规则作为键，原数组中被划分出的数据作为值

```java
Map<Integer, List<Integer>> map = 
Stream.of(1, 2, 2, 3, 3, 3, 3, 3, 3, 4, 5, 6).collect(Collectors.groupingBy(e -> e));
System.out.println(map);
//{1=[1], 2=[2, 2], 3=[3, 3, 3, 3, 3, 3], 4=[4], 5=[5], 6=[6]}
```

* counting：元素计数

```java
Long count = 
    Stream.of(1, 2, 2, 3, 3, 3, 3, 3, 3, 4, 5, 6).collect(Collectors.counting());
//等价于Stream.of(1, 2, 2, 3, 3, 3, 3, 3, 3, 4, 5, 6).count()
System.out.println(count);//12
```

* toSet：去重，将流转换为一个Set1集合

```java
Set<Integer> set = list.stream().collect(Collectors.toSet());
System.out.println(set);
// [1, 2, 3, 4, 5, 6]
```

* toMap：将指定元素转换为key-value

```java
Map<String,String> map = list.stream().collect(Collectors.toMap(Employee::getName,Employee::getAge));
```

* averagingDouble：求平均值，在计算时将元素值看作Double

```
list.stream().collect(Collectors.averagingDouble(Employee:getSalary));
```

* averagingInt：求平均，在计算时将元素值看作int
* mapping：收集元素属性

```
String s = list.stream().collect(Collectors.mapping(Employee::getName,Collectors.joining(",")));
```

* MapToInt：转为数组

```java
ArrayList<Integer> ans = new ArrayList<>();
int[] a = ans.stream().mapToInt(e -> e).toArray();
```

# 快捷键

```shell
Ctrl+Alt+M 快速抽取代码形成方法
```

